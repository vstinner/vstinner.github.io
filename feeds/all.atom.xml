<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Haypo blog 2</title><link href="https://haypo.github.io/" rel="alternate"></link><link href="https://haypo.github.io/feeds/all.atom.xml" rel="self"></link><id>https://haypo.github.io/</id><updated>2017-02-24T22:00:00+01:00</updated><entry><title>FASTCALL microbenchmarks</title><link href="https://haypo.github.io/fastcall-microbenchmarks.html" rel="alternate"></link><published>2017-02-24T22:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-24:fastcall-microbenchmarks.html</id><summary type="html">&lt;p&gt;For my FASTCALL project (CPython optimization avoiding temporary tuples and
dictionaries to pass arguments), I wrote many short microbenchmarks. I grouped
them into a new Git repository: &lt;a class="reference external" href="https://github.com/haypo/pymicrobench"&gt;pymicrobench&lt;/a&gt;.  Benchmark results are required by
CPython developers to prove that an optimization is worth it. It's not uncommon
that I abandon a change because the speedup is not significant, makes CPython
slower, or because the change is too complex. Last 12 months, I counted that I
abandonned 9 optimization issues, rejected for different reasons, on a total of
46 optimization issues.&lt;/p&gt;
&lt;p&gt;This article gives Python 3.7 results of these microbenchmarks compared to
Python 3.5 (before FASTCALL). I ignored 3 microbenchmarks which are between 2%
and 5% slower: the code was not optimized and the result is not signifiant
(less than 10% on a &lt;em&gt;microbenchmark&lt;/em&gt; is not significant).&lt;/p&gt;
&lt;p&gt;On results below, the speedup is between 1.11x faster (-10%) and 1.92x faster
(-48%). It's not easy to isolate the speedup of only FASTCALL. Since Python
3.5, Python 3.7 got many other optimizations.&lt;/p&gt;
&lt;p&gt;Using FASTCALL gives a speedup around 20 ns: measured on a patch to use
FASTCALL.  It's not a lot, but many builtin functions take less than 100 ns, so
20 ns is significant in practice! Avoiding a tuple to pass positional arguments
is interesting, but FASTCALL also allows further internal optimizations.&lt;/p&gt;
&lt;p&gt;Microbenchmark on calling builtin functions:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="53%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="36%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;th class="head"&gt;3.5&lt;/th&gt;
&lt;th class="head"&gt;3.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;struct.pack(&amp;quot;i&amp;quot;, 1)&lt;/td&gt;
&lt;td&gt;105 ns&lt;/td&gt;
&lt;td&gt;77.6 ns: 1.36x faster (-26%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;getattr(1, &amp;quot;real&amp;quot;)&lt;/td&gt;
&lt;td&gt;79.4 ns&lt;/td&gt;
&lt;td&gt;64.4 ns: 1.23x faster (-19%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Microbenchmark on calling methods of builtin types:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="53%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="36%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;th class="head"&gt;3.5&lt;/th&gt;
&lt;th class="head"&gt;3.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;{1: 2}.get(7, None)&lt;/td&gt;
&lt;td&gt;84.9 ns&lt;/td&gt;
&lt;td&gt;61.6 ns: 1.38x faster (-27%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;collections.deque([None]).index(None)&lt;/td&gt;
&lt;td&gt;116 ns&lt;/td&gt;
&lt;td&gt;87.0 ns: 1.33x faster (-25%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;{1: 2}.get(1)&lt;/td&gt;
&lt;td&gt;79.4 ns&lt;/td&gt;
&lt;td&gt;59.6 ns: 1.33x faster (-25%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;quot;a&amp;quot;.replace(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)&lt;/td&gt;
&lt;td&gt;134 ns&lt;/td&gt;
&lt;td&gt;101 ns: 1.33x faster (-25%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;b&amp;quot;&amp;quot;.decode()&lt;/td&gt;
&lt;td&gt;71.5 ns&lt;/td&gt;
&lt;td&gt;54.5 ns: 1.31x faster (-24%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;b&amp;quot;&amp;quot;.decode(&amp;quot;ascii&amp;quot;)&lt;/td&gt;
&lt;td&gt;99.1 ns&lt;/td&gt;
&lt;td&gt;75.7 ns: 1.31x faster (-24%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;collections.deque.rotate(1)&lt;/td&gt;
&lt;td&gt;106 ns&lt;/td&gt;
&lt;td&gt;82.8 ns: 1.28x faster (-22%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;collections.deque.insert()&lt;/td&gt;
&lt;td&gt;778 ns&lt;/td&gt;
&lt;td&gt;608 ns: 1.28x faster (-22%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;b&amp;quot;&amp;quot;.join((b&amp;quot;hello&amp;quot;, b&amp;quot;world&amp;quot;) * 100)&lt;/td&gt;
&lt;td&gt;4.02 us&lt;/td&gt;
&lt;td&gt;3.32 us: 1.21x faster (-17%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[0].count(0)&lt;/td&gt;
&lt;td&gt;53.9 ns&lt;/td&gt;
&lt;td&gt;46.3 ns: 1.16x faster (-14%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;collections.deque.rotate()&lt;/td&gt;
&lt;td&gt;72.6 ns&lt;/td&gt;
&lt;td&gt;63.1 ns: 1.15x faster (-13%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;b&amp;quot;&amp;quot;.join((b&amp;quot;hello&amp;quot;, b&amp;quot;world&amp;quot;))&lt;/td&gt;
&lt;td&gt;102 ns&lt;/td&gt;
&lt;td&gt;89.8 ns: 1.13x faster (-12%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Microbenchmark on builtin functions calling Python functions (callbacks):&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="53%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="36%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;th class="head"&gt;3.5&lt;/th&gt;
&lt;th class="head"&gt;3.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;map(lambda x: x, list(range(1000)))&lt;/td&gt;
&lt;td&gt;76.1 us&lt;/td&gt;
&lt;td&gt;61.1 us: 1.25x faster (-20%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sorted(list(range(1000)), key=lambda x: x)&lt;/td&gt;
&lt;td&gt;90.2 us&lt;/td&gt;
&lt;td&gt;78.2 us: 1.15x faster (-13%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;filter(lambda x: x, list(range(1000)))&lt;/td&gt;
&lt;td&gt;81.8 us&lt;/td&gt;
&lt;td&gt;73.4 us: 1.11x faster (-10%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Microbenchmark on calling slots (&lt;tt class="docutils literal"&gt;__getitem__&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;__init__&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;__int__&lt;/tt&gt;)
implemented in Python:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="53%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="36%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;th class="head"&gt;3.5&lt;/th&gt;
&lt;th class="head"&gt;3.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Python __getitem__: obj[0]&lt;/td&gt;
&lt;td&gt;167 ns&lt;/td&gt;
&lt;td&gt;87.0 ns: 1.92x faster (-48%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;call_pyinit_kw1&lt;/td&gt;
&lt;td&gt;348 ns&lt;/td&gt;
&lt;td&gt;240 ns: 1.45x faster (-31%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;call_pyinit_kw5&lt;/td&gt;
&lt;td&gt;564 ns&lt;/td&gt;
&lt;td&gt;401 ns: 1.41x faster (-29%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;call_pyinit_kw10&lt;/td&gt;
&lt;td&gt;960 ns&lt;/td&gt;
&lt;td&gt;734 ns: 1.31x faster (-24%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Python __int__: int(obj)&lt;/td&gt;
&lt;td&gt;241 ns&lt;/td&gt;
&lt;td&gt;207 ns: 1.16x faster (-14%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Microbenchmark on calling a method descriptor (static method):&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="53%" /&gt;
&lt;col width="11%" /&gt;
&lt;col width="36%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;th class="head"&gt;3.5&lt;/th&gt;
&lt;th class="head"&gt;3.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;int.to_bytes(1, 4, &amp;quot;little&amp;quot;)&lt;/td&gt;
&lt;td&gt;177 ns&lt;/td&gt;
&lt;td&gt;103 ns: 1.72x faster (-42%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Benchmarks were run on &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;speed-python&lt;/span&gt;&lt;/tt&gt;, server used to run CPython benchmarks.&lt;/p&gt;
</summary><category term="fastcall"></category><category term="optimization"></category><category term="cpython"></category></entry><entry><title>The start of the FASTCALL project</title><link href="https://haypo.github.io/start-fastcall-project.html" rel="alternate"></link><published>2017-02-16T17:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-16:start-fastcall-project.html</id><summary type="html">&lt;div class="section" id="false-start"&gt;
&lt;h2&gt;False start&lt;/h2&gt;
&lt;p&gt;In April 2016, I experimented a Python change to avoid temporary tuple to call
functions. Builtin functions were between 20 and 50% faster!&lt;/p&gt;
&lt;p&gt;Sadly, some benchmarks were randomy slower. It will take me four months to
understand why!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="work-on-benchmarks"&gt;
&lt;h2&gt;Work on benchmarks&lt;/h2&gt;
&lt;p&gt;During four months, I worked on making benchmarks more stable. See my previous
blog posts:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-system.html"&gt;My journey to stable benchmark, part 1 (system)&lt;/a&gt; (May 21, 2016)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-deadcode.html"&gt;My journey to stable benchmark, part 2 (deadcode)&lt;/a&gt; (May 22, 2016)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-average.html"&gt;My journey to stable benchmark, part 3 (average)&lt;/a&gt; (May 23, 2016)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/perf-visualize-system-noise-with-cpu-isolation.html"&gt;Visualize the system noise using perf and CPU isolation&lt;/a&gt; (June 16, 2016)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/intel-cpus.html"&gt;Intel CPUs: P-state, C-state, Turbo Boost, CPU frequency, etc.&lt;/a&gt; (July 15, 2015)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/intel-cpus-part2.html"&gt;Intel CPUs (part 2): Turbo Boost, temperature, frequency and Pstate C0 bug&lt;/a&gt;
(September 23, 2016)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://haypo.github.io/analysis-python-performance-issue.html"&gt;Analysis of a Python performance issue&lt;/a&gt;
(November 19, 2016)&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See my talk &lt;a class="reference external" href="https://fosdem.org/2017/schedule/event/python_stable_benchmark/"&gt;How to run a stable benchmark&lt;/a&gt; that I gave
at FOSDEM 2017 (Brussels, Belgium): slides + video. I listed all the issues
that I had to get reliable benchmarks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ask-for-permission"&gt;
&lt;h2&gt;Ask for permission&lt;/h2&gt;
&lt;p&gt;August 2016, I
confirmed that my change didn't introduce any slowndown. So I asked for the
permission on the python-dev mailing list to start pushing changes: &lt;a class="reference external" href="https://mail.python.org/pipermail/python-dev/2016-August/145793.html"&gt;New
calling convention to avoid temporarily tuples when calling functions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Guido van Rossum asked me for benchmark results:&lt;/p&gt;
&lt;blockquote&gt;
But is there a performance improvement?&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmark-results"&gt;
&lt;h2&gt;Benchmark results&lt;/h2&gt;
&lt;p&gt;On micro-benchmarks, FASTCALL is much faster:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;getattr(1, &amp;quot;real&amp;quot;)&lt;/tt&gt; becomes &lt;strong&gt;44%&lt;/strong&gt; faster&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;list(filter(lambda x: x, &lt;span class="pre"&gt;list(range(1000))))&lt;/span&gt;&lt;/tt&gt; becomes &lt;strong&gt;31%&lt;/strong&gt; faster&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;namedtuple.attr&lt;/tt&gt; (read the attribute) becomes &lt;strong&gt;23%&lt;/strong&gt; faster&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Full results:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bugs.python.org/issue26814#msg263999"&gt;FASTCALL compared to Python 3.6 (default branch)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bugs.python.org/issue26814#msg264003"&gt;2.7 / 3.4 / 3.5 / 3.6 / 3.6 FASTCALL comparison&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On the &lt;a class="reference external" href="https://bugs.python.org/issue26814#msg266359"&gt;CPython benchmark suite&lt;/a&gt;, I also saw many faster
benchmarks:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;pickle_list: &lt;strong&gt;1.29x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;etree_generate: &lt;strong&gt;1.22x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;pickle_dict: &lt;strong&gt;1.19x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;etree_process: &lt;strong&gt;1.16x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;mako_v2: &lt;strong&gt;1.13x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;telco: &lt;strong&gt;1.09x faster&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="replies-to-my-email"&gt;
&lt;h2&gt;Replies to my email&lt;/h2&gt;
&lt;p&gt;I got two very positive replies, so I understood that it was ok.&lt;/p&gt;
&lt;p&gt;Brett Canon:&lt;/p&gt;
&lt;blockquote&gt;
I just wanted to say I'm excited about this and I'm glad someone is taking
advantage of what Argument Clinic allows for and what I know Larry had
initially hoped AC would make happen!&lt;/blockquote&gt;
&lt;p&gt;Yury Selivanov:&lt;/p&gt;
&lt;blockquote&gt;
Exceptional results, congrats Victor. Will be happy to help with code
review.&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="real-start"&gt;
&lt;h2&gt;Real start&lt;/h2&gt;
&lt;p&gt;That's how the FASTCALL began for real! I started to push a long serie of
patches adding new private functions and then modify code to call these new
functions.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="fastcall"></category><category term="optimization"></category><category term="cpython"></category></entry><entry><title>My contributions to CPython during 2016 Q4</title><link href="https://haypo.github.io/contrib-cpython-2016q4.html" rel="alternate"></link><published>2017-02-16T11:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-16:contrib-cpython-2016q4.html</id><summary type="html">&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2016 Q4
(october, november, december):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2016-10-01&amp;quot;):date(&amp;quot;2016-12-31&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 105 non-merge commits + 31 merge commits (total: 136 commits).&lt;/p&gt;
&lt;p&gt;Previous report: &lt;a class="reference external" href="https://haypo.github.io/contrib-cpython-2016q3.html"&gt;My contributions to CPython during 2016 Q3&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python startup performance regression&lt;/li&gt;
&lt;li&gt;Optimizations&lt;/li&gt;
&lt;li&gt;Code placement and __attribute__((hot))&lt;/li&gt;
&lt;li&gt;Interesting bug: duplicated filters when tests reload the warnings module&lt;/li&gt;
&lt;li&gt;Contributions&lt;/li&gt;
&lt;li&gt;regrtest&lt;/li&gt;
&lt;li&gt;Other changes&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="python-startup-performance-regression"&gt;
&lt;h2&gt;Python startup performance regression&lt;/h2&gt;
&lt;div class="section" id="regresion"&gt;
&lt;h3&gt;Regresion&lt;/h3&gt;
&lt;p&gt;My work on tracking Python performances started to become useful :-) I
identified a performance slowdown on the &lt;tt class="docutils literal"&gt;bm_python_startup&lt;/tt&gt; benchmark
(average time to start Python).&lt;/p&gt;
&lt;p&gt;Before September 2016, the start took around &lt;strong&gt;17.9 ms&lt;/strong&gt;. At September 15,
after the  &lt;a class="reference external" href="https://haypo.github.io/cpython-sprint-2016.html"&gt;CPython sprint&lt;/a&gt;, it was
better: &lt;strong&gt;13.4 ms&lt;/strong&gt;. But suddenly, at september 19, it became much worse:
&lt;strong&gt;22.8 ms&lt;/strong&gt;. What happened?&lt;/p&gt;
&lt;p&gt;Timeline of Python startup performance on speed.python.org:&lt;/p&gt;
&lt;a class="reference external image-reference" href="https://speed.python.org/timeline/#/?exe=5&amp;amp;ben=python_startup&amp;amp;env=1&amp;amp;revs=50&amp;amp;equid=off&amp;amp;quarts=on&amp;amp;extr=on"&gt;&lt;img alt="Timeline of Python startup performance" src="https://haypo.github.io/images/python_startup_regression.png" /&gt;&lt;/a&gt;
&lt;p&gt;I looked at commits between September 15 and September 19, and I quickly
identified the commit of the &lt;a class="reference external" href="http://bugs.python.org/issue28082"&gt;convert re flags to (much
friendlier) IntFlag constants (issue #28082)&lt;/a&gt;. The &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; module now imports the
&lt;tt class="docutils literal"&gt;enum&lt;/tt&gt; module to get a better representation for their flags.  Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ ./python
Python 3.7.0a0
&amp;gt;&amp;gt;&amp;gt; import re; re.M
&amp;lt;RegexFlag.MULTILINE: 8&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="revert"&gt;
&lt;h3&gt;Revert&lt;/h3&gt;
&lt;p&gt;At November 7, I opened the issue #28637 to propose to revert the commit to get
back better Python startup performance. The revert was approved by Guido van
Rossum, so I pushed it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="better-fix"&gt;
&lt;h3&gt;Better fix&lt;/h3&gt;
&lt;p&gt;I also noticed that the &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; module is not imported by default if Python is
installed or if Python is run from its source code directory. The &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; module
is only imported by default if Python is installed in a virtual environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Serhiy Storchaka&lt;/strong&gt; proposed a change to not import &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; anymore in the
&lt;tt class="docutils literal"&gt;site&lt;/tt&gt; module when Python runs into a virutal environment. Since the benefit
was obvious (avoid an import at startup) and simple, it was quickly merged.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="restore-reverted-enum-change"&gt;
&lt;h3&gt;Restore reverted enum change&lt;/h3&gt;
&lt;p&gt;Since using &lt;tt class="docutils literal"&gt;enum&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; has no more impact on Python startup
performance by default, the &lt;tt class="docutils literal"&gt;enum&lt;/tt&gt; change was restored at November 14.&lt;/p&gt;
&lt;p&gt;Sadly, the &lt;tt class="docutils literal"&gt;enum&lt;/tt&gt; change still have an impact on performance:
&lt;tt class="docutils literal"&gt;re.compile()&lt;/tt&gt; became 1.2x slower (312 ms =&amp;gt; 376 ms: +20%).&lt;/p&gt;
&lt;a class="reference external image-reference" href="https://speed.python.org/timeline/#/?exe=5&amp;amp;ben=regex_compile&amp;amp;env=1&amp;amp;revs=50&amp;amp;equid=off&amp;amp;quarts=on&amp;amp;extr=on"&gt;&lt;img alt="Timeline of re.compile() performance" src="https://haypo.github.io/images/regex_compile_perf.png" /&gt;&lt;/a&gt;
&lt;p&gt;I think that it's ok since it is very easy to use precompiled regular
expressions in an application: store and reuse the result of &lt;tt class="docutils literal"&gt;re.compile()&lt;/tt&gt;,
instead of calling directly &lt;tt class="docutils literal"&gt;re.match()&lt;/tt&gt; for example.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="optimizations"&gt;
&lt;h2&gt;Optimizations&lt;/h2&gt;
&lt;div class="section" id="fastcall"&gt;
&lt;h3&gt;FASTCALL&lt;/h3&gt;
&lt;p&gt;Same than 2016 Q3: I pushed a &lt;em&gt;lot&lt;/em&gt; of changes for FASTCALL optimizations, but
I will write a dedicated article later.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="no-int-int-micro-optimization-thank-you"&gt;
&lt;h3&gt;No int+int micro-optimization, thank you&lt;/h3&gt;
&lt;p&gt;After 2 years of benchmarking and a huge effort of making Python benchmarks more
reliable and stable, I decided to close the issue #21955 &amp;quot;ceval.c: implement
fast path for integers with a single digit&amp;quot; as REJECTED. It became clear to me
that such micro-optimization has no effect on non-trivial code, but only on
specially crafted micro-benchmarks. I added a comment in the C code to prevent
further optimizations attempts:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* NOTE(haypo): Please don't try to micro-optimize int+int on
   CPython using bytecode, it is simply worthless.
   See http://bugs.python.org/issue21955 and
   http://bugs.python.org/issue10044 for the discussion. In short,
   no patch shown any impact on a realistic benchmark, only a minor
   speedup on microbenchmarks. */
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="timeit"&gt;
&lt;h3&gt;timeit&lt;/h3&gt;
&lt;p&gt;I enhanced the &lt;tt class="docutils literal"&gt;timeit&lt;/tt&gt; benchmark module to make it more reliable (issue
#28240):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Autorange now starts with a single loop iteration instead of 10. For example,
&lt;tt class="docutils literal"&gt;python3 &lt;span class="pre"&gt;-m&lt;/span&gt; timeit &lt;span class="pre"&gt;-s&lt;/span&gt; 'import time' 'time.sleep(1)'&lt;/tt&gt; now only takes 4
seconds instead of 40 seconds.&lt;/li&gt;
&lt;li&gt;Repeat the benchmarks 5 times by default, instead of only 3, to make
benchmarks more reliable.&lt;/li&gt;
&lt;li&gt;Remove &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-c/--clock&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-t/--time&lt;/span&gt;&lt;/tt&gt; command line options which were
deprecated since Python 3.3.&lt;/li&gt;
&lt;li&gt;Add &lt;tt class="docutils literal"&gt;nsec&lt;/tt&gt; (nanosecond) unit to format timings&lt;/li&gt;
&lt;li&gt;Enhance formatting of raw timings in verbose mode. Add newlines to the output
for readability.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="micro-optimizations"&gt;
&lt;h3&gt;Micro-optimizations&lt;/h3&gt;
&lt;p&gt;I also pushed two minor micro-optimizations:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use &lt;tt class="docutils literal"&gt;PyThreadState_GET()&lt;/tt&gt; macro in performance critical code.
&lt;tt class="docutils literal"&gt;_PyThreadState_UncheckedGet()&lt;/tt&gt; calls are not inlined as expected, even
when using &lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-O3&lt;/span&gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Modify &lt;tt class="docutils literal"&gt;type_setattro()&lt;/tt&gt; to call directly
&lt;tt class="docutils literal"&gt;_PyObject_GenericSetAttrWithDict()&lt;/tt&gt; instead of
&lt;tt class="docutils literal"&gt;PyObject_GenericSetAttr()&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;PyObject_GenericSetAttr()&lt;/tt&gt; is a thin
wrapper to &lt;tt class="docutils literal"&gt;_PyObject_GenericSetAttrWithDict()&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="code-placement-and-attribute-hot"&gt;
&lt;h2&gt;Code placement and __attribute__((hot))&lt;/h2&gt;
&lt;p&gt;On &lt;a class="reference external" href="https://speed.python.org/"&gt;speed.python.org&lt;/a&gt;, I still noticed random
performance slowdowns on the evil &lt;tt class="docutils literal"&gt;call_simple&lt;/tt&gt; benchmark. This benchmark is
a &lt;em&gt;micro&lt;/em&gt;-benchmark measuring the performance of a single Python function call,
it is CPU-bound and very small and so impact by CPU caches. I was bitten again
by significant performance slowdown only caused by code placement.&lt;/p&gt;
&lt;p&gt;It wasn't possible to use &lt;em&gt;Profiled Guided Optimization&lt;/em&gt; (PGO) on the benchmark
runner, since it used Ubuntu 14.04 and GCC crashed with an &amp;quot;internal error&amp;quot;.&lt;/p&gt;
&lt;p&gt;So I tried something different: mark &amp;quot;hot functions&amp;quot; with
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((hot))&lt;/span&gt;&lt;/tt&gt;. It's a GCC and Clang attribute helping code
placements: &amp;quot;hot functions&amp;quot; are moved to a dedicated ELF section and so are
closer in memory, and the compiler tries to optimize these functions even more.&lt;/p&gt;
&lt;p&gt;The following functions are considered as hot according to statistics collected
by Linux &lt;tt class="docutils literal"&gt;perf record&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;perf report&lt;/tt&gt; commands:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;_PyEval_EvalFrameDefault()&lt;/li&gt;
&lt;li&gt;call_function()&lt;/li&gt;
&lt;li&gt;_PyFunction_FastCall()&lt;/li&gt;
&lt;li&gt;PyFrame_New()&lt;/li&gt;
&lt;li&gt;frame_dealloc()&lt;/li&gt;
&lt;li&gt;PyErr_Occurred()&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I added a &lt;tt class="docutils literal"&gt;_Py_HOT_FUNCTION&lt;/tt&gt; macro which uses &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((hot))&lt;/span&gt;&lt;/tt&gt; and
used &lt;tt class="docutils literal"&gt;_Py_HOT_FUNCTION&lt;/tt&gt; on these functions (issue #28618).&lt;/p&gt;
&lt;p&gt;Read also my previous blog article &lt;a class="reference external" href="https://haypo.github.io/analysis-python-performance-issue.html"&gt;Analysis of a Python performance issue&lt;/a&gt; for a deeper analysis.&lt;/p&gt;
&lt;p&gt;Sadly, after I wrote this blog post and after more analysis of &lt;tt class="docutils literal"&gt;call_simple&lt;/tt&gt;
benchmark results, I saw that &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((hot))&lt;/span&gt;&lt;/tt&gt; wasn't enough. I still
had random major performance slowdown.&lt;/p&gt;
&lt;p&gt;I dediced to upgrade the performance runner to Ubuntu 16.04. It was dangerous
because nobody has access to the physical server, so it may takes weeks to
repair it if I did a mistake. Hopefully, the upgrade gone smoothly and I was
able to run again all benchmarks using PGO. As expected, using PGO+LTO,
benchmark results are more stable!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="interesting-bug-duplicated-filters-when-tests-reload-the-warnings-module"&gt;
&lt;h2&gt;Interesting bug: duplicated filters when tests reload the warnings module&lt;/h2&gt;
&lt;p&gt;Python test suite has an old bug: the issue #18383 opened in July 2013.
Sometimes, the test suite emits the following warning:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[247/375] test_warnings
Warning -- warnings.filters was modified by test_warnings
&lt;/pre&gt;
&lt;p&gt;Since it's only a warning and it only occurs in the Python test suite, it was a
low priority and took 3 years to be fixed! It also took time to find the right
design to fix the root cause.&lt;/p&gt;
&lt;div class="section" id="duplicated-filters"&gt;
&lt;h3&gt;Duplicated filters&lt;/h3&gt;
&lt;p&gt;test_warnings imports the &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; module 3 times:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import warnings as original_warnings   # Python
py_warnings = support.import_fresh_module('warnings', blocked=['_warnings'])  # Python
c_warnings = support.import_fresh_module('warnings', fresh=['_warnings'])   # C
&lt;/pre&gt;
&lt;p&gt;The Python &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; module (&lt;tt class="docutils literal"&gt;Lib/warnings.py&lt;/tt&gt;) installs warning filters
when the module is loaded:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
_processoptions(sys.warnoptions)
&lt;/pre&gt;
&lt;p&gt;where &lt;tt class="docutils literal"&gt;sys.warnoptions&lt;/tt&gt; contains the value of the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-W&lt;/span&gt;&lt;/tt&gt; command line option.&lt;/p&gt;
&lt;p&gt;If the Python module is loaded more than once, filters are duplicated.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="first-fix-use-the-right-module"&gt;
&lt;h3&gt;First fix: use the right module&lt;/h3&gt;
&lt;p&gt;I pushed a first fix in september 2015.&lt;/p&gt;
&lt;p&gt;Fix test_warnings: don't modify warnings.filters. BaseTest now ensures that
unittest.TestCase.assertWarns() uses the same warnings module than
warnings.catch_warnings(). Otherwise, warnings.catch_warnings() will be unable
to remove the added filter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="second-fix-don-t-add-duplicated-filters"&gt;
&lt;h3&gt;Second fix: don't add duplicated filters&lt;/h3&gt;
&lt;p&gt;Issue #18383: the first patch was proposed by &lt;strong&gt;Florent Xicluna&lt;/strong&gt; in 2013: save
the length of filters, and remove newly added filters after &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt;
modules are reloaded by &lt;tt class="docutils literal"&gt;test_warnings&lt;/tt&gt;. December 2014, &lt;strong&gt;Serhiy Storchaka&lt;/strong&gt;
reviewed the patch: he didn't like this &lt;em&gt;workaround&lt;/em&gt;, he would like to fix the
&lt;em&gt;root cause&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;March 2015, &lt;strong&gt;Alex Shkop&lt;/strong&gt; proposed a patch which avoids to add duplicated
filters.&lt;/p&gt;
&lt;p&gt;September 2015, &lt;strong&gt;Martin Panter&lt;/strong&gt; proposed to try to save/restore filters on
the C warnings module. I proposed something similar in the issue #26742. But
this solution has the same flaw that Florent's idea: it's only a workaround.&lt;/p&gt;
&lt;p&gt;Martin also proposed add a private flag to say that filters were already set to
not try to add again same filters.&lt;/p&gt;
&lt;p&gt;Finally, in may 2016, Martin updated Alex's patch avoiding duplicated filters
and pushed it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="third-fix"&gt;
&lt;h3&gt;Third fix&lt;/h3&gt;
&lt;p&gt;The filter comparisons wasn't perfect. A filter can be made of a precompiled
regular expression, whereas these objects don't implement comparison.&lt;/p&gt;
&lt;p&gt;November 2016, I opened the issue #28727 to propose to implement rich
comparison for &lt;tt class="docutils literal"&gt;_sre.SRE_Pattern&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;My first patch didn't implement &lt;tt class="docutils literal"&gt;hash()&lt;/tt&gt; and had different bugs. It took me
almost one week and 6 versions to write complete unit tests and handle all
cases: support bytes and Unicode and handle regular expression flags.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Serhiy Storchaka&lt;/strong&gt; found bugs and helps me to write the implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="contributions"&gt;
&lt;h2&gt;Contributions&lt;/h2&gt;
&lt;p&gt;As usual, I reviewed and pushed changes written by other contributors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27896: Allow passing sphinx options to Doc/Makefile. Patch written by
&lt;strong&gt;Julien Palard&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28476: Reuse math.factorial() in test_random.
Patch written by &lt;strong&gt;Francisco Couzo&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28479: Fix reST syntax in windows.rst. Patch written by &lt;strong&gt;Julien Palard&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26273: Add new constants: &lt;tt class="docutils literal"&gt;socket.TCP_CONGESTION&lt;/tt&gt; (Linux 2.6.13) and
&lt;tt class="docutils literal"&gt;socket.TCP_USER_TIMEOUT&lt;/tt&gt; (Linux 2.6.37).
Patch written by &lt;strong&gt;Omar Sandoval&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28979: Fix What's New in Python 3.6: compact dict is not faster, but
only more compact. Patch written by &lt;strong&gt;Brendan Donegan&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28147: Fix a memory leak in split-table dictionaries: &lt;tt class="docutils literal"&gt;setattr()&lt;/tt&gt;
must not convert combined table into split table.
Patch written by &lt;strong&gt;INADA Naoki&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #29109: Enhance tracemalloc documentation:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Wrong parameter name, 'group_by' instead of 'key_type'&lt;/li&gt;
&lt;li&gt;Don't round up numbers when explaining the examples. If they exactly match
what can be read in the script output, it is to easier to understand
(4.8 MiB vs 4855 KiB)&lt;/li&gt;
&lt;li&gt;Fix incorrect method link that was pointing to another module&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Patch written by &lt;strong&gt;Loic Pefferkorn&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="regrtest"&gt;
&lt;h2&gt;regrtest&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;regrtest &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--fromfile&lt;/span&gt;&lt;/tt&gt; now accepts a list of filenames, not only a list of
&lt;em&gt;test&lt;/em&gt; names.&lt;/li&gt;
&lt;li&gt;Issue #28409: regrtest: fix the parser of command line arguments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="other-changes"&gt;
&lt;h2&gt;Other changes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Fix &lt;tt class="docutils literal"&gt;_Py_normalize_encoding()&lt;/tt&gt; function: It was not exactly the same than
Python &lt;tt class="docutils literal"&gt;encodings.normalize_encoding()&lt;/tt&gt;: the C function now also converts
to lowercase.&lt;/li&gt;
&lt;li&gt;Issue #28256: Cleanup &lt;tt class="docutils literal"&gt;_math.c&lt;/tt&gt;: only define fallback implementations when
needed. It avoids producing deadcode when the system provides required math
functions, and so enhance the code coverage.&lt;/li&gt;
&lt;li&gt;_csv: use &lt;tt class="docutils literal"&gt;_PyLong_AsInt()&lt;/tt&gt; to simplify the code, the function checks for
the limits of the C &lt;tt class="docutils literal"&gt;int&lt;/tt&gt; type.&lt;/li&gt;
&lt;li&gt;Issue #28544: Fix &lt;tt class="docutils literal"&gt;_asynciomodule.c&lt;/tt&gt; on Windows. &lt;tt class="docutils literal"&gt;PyType_Ready()&lt;/tt&gt; sets
the reference to &lt;tt class="docutils literal"&gt;&amp;amp;PyType_Type&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;&amp;amp;PyType_Type&lt;/tt&gt; address cannot be
resolved at compilation time (not on Windows?).&lt;/li&gt;
&lt;li&gt;Issue #28082: Add basic unit tests on the new &lt;tt class="docutils literal"&gt;re&lt;/tt&gt; enums.&lt;/li&gt;
&lt;li&gt;Issue #28691: Fix &lt;tt class="docutils literal"&gt;warn_invalid_escape_sequence()&lt;/tt&gt;: handle correctly
&lt;tt class="docutils literal"&gt;DeprecationWarning&lt;/tt&gt; raised as an exception. First clear the current
exception to replace the &lt;tt class="docutils literal"&gt;DeprecationWarning&lt;/tt&gt; exception with a
&lt;tt class="docutils literal"&gt;SyntaxError&lt;/tt&gt; exception. Unit test written by &lt;strong&gt;Serhiy Storchaka&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #28023: Fix python-gdb.py on old GDB versions. Replace
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;int(value.address)+offset&lt;/span&gt;&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;value.cast(unsigned &lt;span class="pre"&gt;char*)+offset&lt;/span&gt;&lt;/tt&gt;.
It seems like &lt;tt class="docutils literal"&gt;int(value.address)&lt;/tt&gt; fails on old GDB versions.&lt;/li&gt;
&lt;li&gt;Issue #28765: &lt;tt class="docutils literal"&gt;_sre.compile()&lt;/tt&gt; now checks the type of &lt;tt class="docutils literal"&gt;groupindex&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;indexgroup&lt;/tt&gt; arguments. &lt;tt class="docutils literal"&gt;groupindex&lt;/tt&gt; must a dictionary and &lt;tt class="docutils literal"&gt;indexgroup&lt;/tt&gt;
must be a tuple.  Previously, &lt;tt class="docutils literal"&gt;indexgroup&lt;/tt&gt; was a list. Use a tuple to
reduce the memory usage.&lt;/li&gt;
&lt;li&gt;Issue #28782: Fix a bug in the implementation &lt;tt class="docutils literal"&gt;yield from&lt;/tt&gt;
(fix &lt;tt class="docutils literal"&gt;_PyGen_yf()&lt;/tt&gt; function). Fix the test checking if the next instruction
is &lt;tt class="docutils literal"&gt;YIELD_FROM&lt;/tt&gt;.  Regression introduced by the new &amp;quot;WordCode&amp;quot; bytecode
(issue #26647). Fix reviewed by &lt;strong&gt;Serhiy Storchaka&lt;/strong&gt; and &lt;strong&gt;Yury Selivanov&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #28792: Remove aliases from &lt;tt class="docutils literal"&gt;_bisect&lt;/tt&gt;. Remove aliases from the C
module.  Always implement &lt;tt class="docutils literal"&gt;bisect()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;insort()&lt;/tt&gt; aliases in
&lt;tt class="docutils literal"&gt;bisect.py&lt;/tt&gt;.  Remove also the &lt;tt class="docutils literal"&gt;# backward compatibility&lt;/tt&gt; comment: there
is no plan to deprecate nor remove these aliases. When keys are equal, it
makes sense to use &lt;tt class="docutils literal"&gt;bisect.bisect()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;bisect.insort()&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Fix a &lt;tt class="docutils literal"&gt;ResourceWarning&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;generate_opcode_h.py&lt;/tt&gt;. Use a context manager
to close the Python file. Replace also &lt;tt class="docutils literal"&gt;open()&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;tokenize.open()&lt;/tt&gt; to
handle coding cookie of &lt;tt class="docutils literal"&gt;Lib/opcode.py&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Issue #28740: Add &lt;tt class="docutils literal"&gt;sys.getandroidapilevel()&lt;/tt&gt; function: return the build
time API version of Android as an integer. Function only available on
Android. The availability of this function can be tested to check if Python
is running on Android.&lt;/li&gt;
&lt;li&gt;Issue #28152: Fix &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-Wunreachable-code&lt;/span&gt;&lt;/tt&gt; warnings on Clang.&lt;ul&gt;
&lt;li&gt;Don't declare dead code when the code is compiled with Clang.&lt;/li&gt;
&lt;li&gt;Replace C &lt;tt class="docutils literal"&gt;if()&lt;/tt&gt; with precompiler &lt;tt class="docutils literal"&gt;#if&lt;/tt&gt; to fix a warning on dead code
when using Clang.&lt;/li&gt;
&lt;li&gt;Replace &lt;tt class="docutils literal"&gt;0&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;(0)&lt;/tt&gt; to ignore a compiler warning about dead code on
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;((int)(SEM_VALUE_MAX)&lt;/span&gt; &amp;lt; 0)&lt;/tt&gt;: &lt;tt class="docutils literal"&gt;SEM_VALUE_MAX&lt;/tt&gt; is not negative on Linux.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Issue #28835: Fix a regression introduced in &lt;tt class="docutils literal"&gt;warnings.catch_warnings()&lt;/tt&gt;:
call &lt;tt class="docutils literal"&gt;warnings.showwarning()&lt;/tt&gt; if it was overriden inside the context
manager.&lt;/li&gt;
&lt;li&gt;Issue #28915: Replace &lt;tt class="docutils literal"&gt;int&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;modsupport&lt;/tt&gt;.
&lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; type is better for indexes. The compiler might emit more
efficient code for &lt;tt class="docutils literal"&gt;i++&lt;/tt&gt;. &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; is the type of a PyTuple index for
example. Replace also &lt;tt class="docutils literal"&gt;int endchar&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;char endchar&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Initialize variables to fix compiler warnings. Warnings seen on the &amp;quot;AMD64
Debian PGO 3.x&amp;quot; buildbot. Warnings are false positive, but variable
initialization should not harm performances.&lt;/li&gt;
&lt;li&gt;Remove useless variable initialization. Don't initialize variables which are
not used before they are assigned.&lt;/li&gt;
&lt;li&gt;Issue #28838: Cleanup &lt;tt class="docutils literal"&gt;abstract.h&lt;/tt&gt;. Rewrite all comments to use the same style
than other Python header files: comment functions &lt;em&gt;before&lt;/em&gt; their declaration,
no newline between the comment and the declaration. Reformat some comments,
add newlines, to make them easier to read. Quote argument like 'arg' to
mention an argument in a comment.&lt;/li&gt;
&lt;li&gt;Issue #28838: &lt;tt class="docutils literal"&gt;abstract.h&lt;/tt&gt;: remove long outdated comment. The documentation
of the Python C API is more complete and more up to date than this old
comment. Removal suggested by &lt;strong&gt;Antoine Pitrou&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;python-gdb.py: catch &lt;tt class="docutils literal"&gt;gdb.error&lt;/tt&gt; on &lt;tt class="docutils literal"&gt;gdb.selected_frame()&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Issue #28383: &lt;tt class="docutils literal"&gt;__hash__&lt;/tt&gt; documentation recommends naive XOR to combine, but
this is suboptimal. Update the documentation to suggest to reuse the
&lt;tt class="docutils literal"&gt;hash()&lt;/tt&gt; function on a tuple, with an example.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>My contributions to CPython during 2016 Q3</title><link href="https://haypo.github.io/contrib-cpython-2016q3.html" rel="alternate"></link><published>2017-02-14T19:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-14:contrib-cpython-2016q3.html</id><summary type="html">&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2016 Q3
(july, august, september):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2016-07-01&amp;quot;):date(&amp;quot;2016-09-30&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 161 non-merge commits + 29 merge commits (total: 190 commits).&lt;/p&gt;
&lt;p&gt;Previous report: &lt;a class="reference external" href="https://haypo.github.io/contrib-cpython-2016q2.html"&gt;My contributions to CPython during 2016 Q2&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Two new core developers&lt;/li&gt;
&lt;li&gt;CPython sprint, September, in California&lt;/li&gt;
&lt;li&gt;PEP 524: Make os.urandom() blocking on Linux&lt;/li&gt;
&lt;li&gt;PEP 509: private dictionary version&lt;/li&gt;
&lt;li&gt;FASTCALL: optimization avoiding temporary tuple to call functions&lt;/li&gt;
&lt;li&gt;More efficient CALL_FUNCTION bytecode&lt;/li&gt;
&lt;li&gt;Work on optimization&lt;/li&gt;
&lt;li&gt;Interesting bug: hidden resource warnings&lt;/li&gt;
&lt;li&gt;Contributions&lt;/li&gt;
&lt;li&gt;Bugfixes&lt;/li&gt;
&lt;li&gt;regrtest changes&lt;/li&gt;
&lt;li&gt;Tests changes&lt;/li&gt;
&lt;li&gt;Other changes&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="two-new-core-developers"&gt;
&lt;h2&gt;Two new core developers&lt;/h2&gt;
&lt;p&gt;New core developers is the result of the productive third 2016 quarter.&lt;/p&gt;
&lt;p&gt;At september 25, 2016, Yury Selivanov proposed to give &lt;a class="reference external" href="https://mail.python.org/pipermail/python-committers/2016-September/004013.html"&gt;commit privileges for
INADA Naoki&lt;/a&gt;.
Naoki became a core developer the day after!&lt;/p&gt;
&lt;p&gt;At november 14, 2016, I proposed to &lt;a class="reference external" href="https://mail.python.org/pipermail/python-committers/2016-November/004045.html"&gt;promote Xiang Zhang as a core developer&lt;/a&gt;.
One week later, he also became a core developer! I mentored him during one
month, and later let him push directly changes.&lt;/p&gt;
&lt;p&gt;Most Python core developers are men coming from North America and Europe.
INADA Naoki comes from Japan and Xiang Zhang comes from China: more core
developers from Asia, we increased the diversity of Python core developers!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cpython-sprint-september-in-california"&gt;
&lt;h2&gt;CPython sprint, September, in California&lt;/h2&gt;
&lt;p&gt;I was invited at my first CPython sprint in September! Five days, September
5-9, at Instagram office in California, USA. I reviewed a lot of changes and
pushed many new features! Read my previous blog post: &lt;a class="reference external" href="https://haypo.github.io/cpython-sprint-2016.html"&gt;CPython sprint,
september 2016&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pep-524-make-os-urandom-blocking-on-linux"&gt;
&lt;h2&gt;PEP 524: Make os.urandom() blocking on Linux&lt;/h2&gt;
&lt;p&gt;I pushed the implementation my PEP 524: read my previous blog post: &lt;a class="reference external" href="https://haypo.github.io/pep-524-os-urandom-blocking.html"&gt;PEP 524:
os.urandom() now blocks on Linux in Python 3.6&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pep-509-private-dictionary-version"&gt;
&lt;h2&gt;PEP 509: private dictionary version&lt;/h2&gt;
&lt;p&gt;Another enhancement from my &lt;a class="reference external" href="http://faster-cpython.readthedocs.io/fat_python.html"&gt;FAT Python&lt;/a&gt; project: my &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0509/"&gt;PEP 509:
Add a private version to dict&lt;/a&gt; was
approved at the CPython sprint by Guido van Rossum.&lt;/p&gt;
&lt;p&gt;The dictionary version is used by FAT Python to check quickly if a variable was
modified in a Python namespace. Technically, a Python namespace is a regular
dictionary.&lt;/p&gt;
&lt;p&gt;Using the feedback from the python-ideas mailing list on the first version of
my PEP, I made further changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use 64-bit unsigned integers on 32-bit system: &amp;quot;A risk of an integer overflow
every 584 years is acceptable.&amp;quot; Using 32-bit, an overflow occurs every 4
seconds!&lt;/li&gt;
&lt;li&gt;Don't expose the version at Python level to prevent users writing
optimizations based on it in Python. Reading the dictionary version in Python
is as slow as a dictionary lookup, wheras the version is usually used to
avoid a &amp;quot;slow&amp;quot; dictionary lookup. The version is only accessible at the C
level.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While my experimental FAT Python static optimizer didn't convince Guido, Yury
Selivanov wrote yet another cache for global variables using the dictionary
version: &lt;a class="reference external" href="http://bugs.python.org/issue28158"&gt;Implement LOAD_GLOBAL opcode cache&lt;/a&gt; (sadly, not merged yet).&lt;/p&gt;
&lt;p&gt;I added the private version to the builtin dict type with the issue #26058. The
global dictionary version is incremented at each dictionary creation and at
each dictionary change, and each dictionary has its own version as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fastcall-optimization-avoiding-temporary-tuple-to-call-functions"&gt;
&lt;h2&gt;FASTCALL: optimization avoiding temporary tuple to call functions&lt;/h2&gt;
&lt;p&gt;Thanks to my work on making Python benchmarks more stable, I confirmed that my
FASTCALL patches don't introduce performance regressions, and make Python
faster in some specific cases.&lt;/p&gt;
&lt;p&gt;I started to push FASTCALL changes. It will take me 6 months to push most
changes to enable fully FASTCALL &amp;quot;everywhere&amp;quot; in the code base and to finish
the implementation.&lt;/p&gt;
&lt;p&gt;Following blog posts will describe FASTCALL changes, its history and
performance enhancements. Spoiler: Python 3.6 is fast!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="more-efficient-call-function-bytecode"&gt;
&lt;h2&gt;More efficient CALL_FUNCTION bytecode&lt;/h2&gt;
&lt;p&gt;I reviewed and merged Demur Rumed's patch to make the CALL_FUNCTION opcodes
more efficient. Demur implemented the design proposed by Serhiy Storchaka.
Serhiy Storchaka also reviewied the implementation with me.&lt;/p&gt;
&lt;p&gt;Issue #27213: Rework CALL_FUNCTION* opcodes to produce shorter and more
efficient bytecode:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;CALL_FUNCTION&lt;/tt&gt; now only accepts positional arguments&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;CALL_FUNCTION_KW&lt;/tt&gt; accepts positional arguments and keyword arguments,
keys of keyword arguments are packed into a constant tuple.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;CALL_FUNCTION_EX&lt;/tt&gt; is the most generic opcode: it expects a tuple and a
dict for positional and keyword arguments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;CALL_FUNCTION_VAR&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;CALL_FUNCTION_VAR_KW&lt;/tt&gt; opcodes have been removed.&lt;/p&gt;
&lt;p&gt;Demur Rumed also implemented &amp;quot;Wordcode&amp;quot;, a new bytecode format using fixed
units of 16-bit: 8-bit opcode with 8-bit argument. Wordcode was merged in May
2016, see &lt;a class="reference external" href="http://bugs.python.org/issue26647"&gt;issue #26647: ceval: use Wordcode, 16-bit bytecode&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All instructions have an argument: opcodes without argument use the argument
&lt;tt class="docutils literal"&gt;0&lt;/tt&gt;. It allowed to remove the following conditional code in the very hot code
of &lt;tt class="docutils literal"&gt;Python/ceval.c&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if (HAS_ARG(opcode))
    oparg = NEXTARG();
&lt;/pre&gt;
&lt;p&gt;The bytecode is now fetched using 16-bit words, instead of loading one or two
8-bit words per instruction.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="work-on-optimization"&gt;
&lt;h2&gt;Work on optimization&lt;/h2&gt;
&lt;p&gt;I continued with work on the &lt;a class="reference external" href="https://github.com/python/performance"&gt;performance&lt;/a&gt; Python benchmark suite. The suite
works on CPython and PyPy, but it's maybe not fine tuned for PyPy yet.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #27938: Add a fast-path for us-ascii encoding&lt;/li&gt;
&lt;li&gt;Issue #15369: Remove the (old version of) pybench microbenchmark. Please use
the new &amp;quot;performance&amp;quot; benchmark suite which includes a more recent version of
pybench.&lt;/li&gt;
&lt;li&gt;Issue #15369. Remove old and unreliable pystone microbenchmark. Please use
the new &amp;quot;performance&amp;quot; benchmark suite which is much more reliable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="interesting-bug-hidden-resource-warnings"&gt;
&lt;h2&gt;Interesting bug: hidden resource warnings&lt;/h2&gt;
&lt;p&gt;At 2016-08-22, I started to investigate why &amp;quot;Warning -- xxx was modfied by
test_xxx&amp;quot; warnings were not logged on some buildbots (issue #27829).&lt;/p&gt;
&lt;p&gt;I modified the code logging the warning to flush immediatly stderr:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;print(...,&lt;/span&gt; flush=True)&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;19 days later, I tried to remove a quiet flag &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-q&lt;/span&gt;&lt;/tt&gt; on the Windows build...
but it was a mistake, this flag doesn't mean quiet in the modified batch script
:-)&lt;/p&gt;
&lt;p&gt;13 days later, I finally understood that the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-W&lt;/span&gt;&lt;/tt&gt; option of regrtest was
eating stderr if the test pass but the environment was modified.&lt;/p&gt;
&lt;p&gt;I fixed regrtest to log stderr in all cases, except if the test pass! It should
now be easier to fix &amp;quot;environment changed&amp;quot; warnings emitted by regrtest.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="contributions"&gt;
&lt;h2&gt;Contributions&lt;/h2&gt;
&lt;p&gt;As usual, I reviewed and pushed changes written by other contributors:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #27350: I reviewed and pushed the implementation of compact
dictionaries preserving insertion order. This resulted in dictionaries using
20% to 25% less memory when compared to Python 3.5. The implementation was
written by &lt;strong&gt;INADA Naoki&lt;/strong&gt;, based on the PyPy implementation, with a design
by Raymond Hettinger.&lt;/li&gt;
&lt;li&gt;&amp;quot;make tags&amp;quot;: remove &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-t&lt;/span&gt;&lt;/tt&gt; option of &lt;tt class="docutils literal"&gt;ctags&lt;/tt&gt;. The option was kept for
backward compatibility, but it was completly removed recently. Patch written
by &lt;strong&gt;Stphane Wirtel&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #27558: Fix a &lt;tt class="docutils literal"&gt;SystemError&lt;/tt&gt; in the implementation of &amp;quot;raise&amp;quot; statement.
In a brand new thread, raise a RuntimeError since there is no active
exception to reraise. Patch written by &lt;strong&gt;Xiang Zhang&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #28120: Fix &lt;tt class="docutils literal"&gt;dict.pop()&lt;/tt&gt; for splitted dictionary when trying to remove a
&amp;quot;pending key&amp;quot;: a key not yet inserted in split-table. Patch by &lt;strong&gt;Xiang
Zhang&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="bugfixes"&gt;
&lt;h2&gt;Bugfixes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;socket: Fix &lt;tt class="docutils literal"&gt;internal_select()&lt;/tt&gt; function. Bug found by &lt;strong&gt;Pavel Belikov&lt;/strong&gt;
(&amp;quot;Fragment N1&amp;quot;): &lt;a class="reference external" href="http://www.viva64.com/en/b/0414/#ID0ECDAE"&gt;http://www.viva64.com/en/b/0414/#ID0ECDAE&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;socket: use INVALID_SOCKET.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Replace &lt;tt class="docutils literal"&gt;fd = &lt;span class="pre"&gt;-1&lt;/span&gt;&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;fd = INVALID_SOCKET&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Replace &lt;tt class="docutils literal"&gt;fd &amp;lt; 0&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;fd == INVALID_SOCKET&lt;/tt&gt;:
SOCKET_T is unsigned on Windows&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bug found by Pavel Belikov (&amp;quot;Fragment N1&amp;quot;):
&lt;a class="reference external" href="http://www.viva64.com/en/b/0414/#ID0ECDAE"&gt;http://www.viva64.com/en/b/0414/#ID0ECDAE&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #11048: ctypes, fix &lt;tt class="docutils literal"&gt;CThunkObject_new()&lt;/tt&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Initialize restype and flags fields to fix a crash when Python runs on a
read-only file system&lt;/li&gt;
&lt;li&gt;Use &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; type rather than &lt;tt class="docutils literal"&gt;int&lt;/tt&gt; for the &lt;tt class="docutils literal"&gt;i&lt;/tt&gt; iterator variable&lt;/li&gt;
&lt;li&gt;Reorder assignements to be able to more easily check if all fields are
initialized&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Initial patch written by &lt;strong&gt;Marcin Bachry&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27744: socket: Fix memory leak in &lt;tt class="docutils literal"&gt;sendmsg()&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;sendmsg_afalg()&lt;/tt&gt;.  Release &lt;tt class="docutils literal"&gt;msg.msg_iov&lt;/tt&gt; memory block. Release memory
on &lt;tt class="docutils literal"&gt;PyMem_Malloc(controllen)&lt;/tt&gt; failure&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27866: ssl: Fix refleak in &lt;tt class="docutils literal"&gt;cipher_to_dict()&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28077: Fix dict type, &lt;tt class="docutils literal"&gt;find_empty_slot()&lt;/tt&gt; only supports combined
dictionaries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28200: Fix memory leak in &lt;tt class="docutils literal"&gt;path_converter()&lt;/tt&gt;. Replace
&lt;tt class="docutils literal"&gt;PyUnicode_AsWideCharString()&lt;/tt&gt; &lt;tt class="docutils literal"&gt;with PyUnicode_AsUnicodeAndSize()&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27955: Catch permission error (&lt;tt class="docutils literal"&gt;EPERM&lt;/tt&gt;) in &lt;tt class="docutils literal"&gt;py_getrandom()&lt;/tt&gt;.
Fallback on reading from the &lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt; device when the &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt;
syscall fails with &lt;tt class="docutils literal"&gt;EPERM&lt;/tt&gt;, for example if blocked by SECCOMP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27778: Fix a memory leak in &lt;tt class="docutils literal"&gt;os.getrandom()&lt;/tt&gt; when the
&lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; is interrupted by a signal and a signal handler raises a
Python exception.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28233: Fix &lt;tt class="docutils literal"&gt;PyUnicode_FromFormatV()&lt;/tt&gt; error handling. Fix a memory
leak if the format string contains a non-ASCII character: destroy the unicode
writer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="regrtest-changes"&gt;
&lt;h2&gt;regrtest changes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;regrtest: rename &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--slow&lt;/span&gt;&lt;/tt&gt; option to &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--slowest&lt;/span&gt;&lt;/tt&gt; (to get same option name
than the &lt;tt class="docutils literal"&gt;testr&lt;/tt&gt; tool). Thanks to optparse, --slow syntax still works ;-)
Add --slowest option to buildbots. Display the top 10 slowest tests.&lt;/li&gt;
&lt;li&gt;regrtest: nicer output for durations. Use milliseconds and minutes units, not
only seconds.&lt;/li&gt;
&lt;li&gt;regrtest: Add a summary of the tests at the end of tests output:
&amp;quot;Tests result: xxx&amp;quot;. It was sometimes hard to check quickly if tests
succeeded, failed or something bad happened.&lt;/li&gt;
&lt;li&gt;regrtest: accept options after test names. For example, &lt;tt class="docutils literal"&gt;./python &lt;span class="pre"&gt;-m&lt;/span&gt; test
test_os &lt;span class="pre"&gt;-v&lt;/span&gt;&lt;/tt&gt; runs &lt;tt class="docutils literal"&gt;test_os&lt;/tt&gt; in verbose mode. Before, regrtest tried to run
a test called &amp;quot;-v&amp;quot;!&lt;/li&gt;
&lt;li&gt;Issue #28195: Fix &lt;tt class="docutils literal"&gt;test_huntrleaks_fd_leak()&lt;/tt&gt; of test_regrtest. Don't expect
the fd leak message to be on a specific line number, just make sure that the
line is present in the output.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example of a recent (2017-02-15) successful test run, truncated output:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
...
0:08:20 [403/404] test_codecs passed
0:08:21 [404/404] test_threading passed
391 tests OK.

10 slowest tests:
- test_multiprocessing_spawn: 1 min 24 sec
- test_concurrent_futures: 1 min 3 sec
- test_multiprocessing_forkserver: 60 sec
...

13 tests skipped:
    test_devpoll test_ioctl test_kqueue ...

Total duration: 8 min 22 sec
Tests result: SUCCESS
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="tests-changes"&gt;
&lt;h2&gt;Tests changes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;script_helper: kill the subprocess on error. If Popen.communicate() raises an
exception, kill the child process to not leave a running child process in
background and maybe create a zombi process. This change fixes a
ResourceWarning in Python 3.6 when unit tests are interrupted by CTRL+c.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27181: Skip test_statistics tests known to fail until a fix is found.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #18401: Fix test_pdb if $HOME is not set. HOME is not set on Windows
for example.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;test_eintr: Fix &lt;tt class="docutils literal"&gt;ResourceWarning&lt;/tt&gt; warnings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Buildbot: give 20 minute per test file. It seems like at least 2 buildbots
need more than 15 minutes per test file.  Example with &amp;quot;AMD64 Snow Leop 3.x&amp;quot;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
10 slowest tests:
- test_tools: 14 min 40 sec
- test_tokenize: 11 min 57 sec
- test_datetime: 11 min 25 sec
- ...
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #28176: test_asynico: fix test_sock_connect_sock_write_race(), increase
the timeout from 10 seconds to 60 seconds.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="other-changes"&gt;
&lt;h2&gt;Other changes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #22624: Python 3 now requires the &lt;tt class="docutils literal"&gt;clock()&lt;/tt&gt; function to build to
simplify the C code.&lt;/li&gt;
&lt;li&gt;Issue #27404: tag security related changes with the &amp;quot;[Security]&amp;quot; prefix in
the changelog Misc/NEWS.&lt;/li&gt;
&lt;li&gt;Issue #27776: &lt;tt class="docutils literal"&gt;dev_urandom(raise=0)&lt;/tt&gt; now closes the file descriptor on error&lt;/li&gt;
&lt;li&gt;Issue #27128, #18295: Use &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; in &lt;tt class="docutils literal"&gt;_PyEval_EvalCodeWithName()&lt;/tt&gt;.
Replace &lt;tt class="docutils literal"&gt;int&lt;/tt&gt; type with &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; for index variables used for
positional arguments.  It should help to avoid integer overflow and help to
emit better machine code for &lt;tt class="docutils literal"&gt;i++&lt;/tt&gt; (no trap needed for overflow). Make also
the &lt;tt class="docutils literal"&gt;total_args&lt;/tt&gt; variable constant.&lt;/li&gt;
&lt;li&gt;Fix &amp;quot;make tags&amp;quot;: set locale to C to call sort. vim expects that the tags file
is sorted using english collation, so it fails if the locale is french for
example. Use LC_ALL=C to force english sorting order. Issue #27726.&lt;/li&gt;
&lt;li&gt;Issue #27698: Add &lt;tt class="docutils literal"&gt;socketpair&lt;/tt&gt; function to &lt;tt class="docutils literal"&gt;socket.__all__&lt;/tt&gt; on Windows&lt;/li&gt;
&lt;li&gt;Issue #27786: Simplify (optimize?) PyLongObject private function &lt;tt class="docutils literal"&gt;x_sub()&lt;/tt&gt;:
the &lt;tt class="docutils literal"&gt;z&lt;/tt&gt; variable is known to be a new object which cannot be shared,
&lt;tt class="docutils literal"&gt;Py_SIZE()&lt;/tt&gt; can be used directly to negate the number.&lt;/li&gt;
&lt;li&gt;Fix a clang warning in grammar.c. Clang is smarter than GCC and emits a
warning for dead code on a function declared with
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((__noreturn__))&lt;/span&gt;&lt;/tt&gt; (the &lt;tt class="docutils literal"&gt;Py_FatalError()&lt;/tt&gt; function in this
case).&lt;/li&gt;
&lt;li&gt;Issue #28114: Add unit tests on &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;os.spawn*()&lt;/span&gt;&lt;/tt&gt; to prepare to fix a crash
with bytes environment.&lt;/li&gt;
&lt;li&gt;Issue #28127: Add &lt;tt class="docutils literal"&gt;_PyDict_CheckConsistency()&lt;/tt&gt;: function checking that a
dictionary remains consistent after any change. By default, only basic
attributes are tested, table content is not checked because the impact on
Python performance is too important. &lt;tt class="docutils literal"&gt;DEBUG_PYDICT&lt;/tt&gt; must be defined (ex:
&lt;tt class="docutils literal"&gt;gcc &lt;span class="pre"&gt;-D&lt;/span&gt; DEBUG_PYDICT&lt;/tt&gt;) to check also dictionaries content.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>CPython sprint, september 2016</title><link href="https://haypo.github.io/cpython-sprint-2016.html" rel="alternate"></link><published>2017-02-14T18:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-14:cpython-sprint-2016.html</id><summary type="html">&lt;p&gt;I was invited at my first CPython sprint in September! Five days, September
5-9, at Instagram office in California, USA. The sprint was sponsored by
Instagram, Microsoft, and the PSF.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First little game:&lt;/strong&gt; Many happy faces, but &lt;em&gt;Where is Victor?&lt;/em&gt;&lt;/p&gt;
&lt;a class="reference external image-reference" href="http://blog.python.org/2016/09/python-core-development-sprint-2016-36.html"&gt;&lt;img alt="CPython developers at the Facebook sprint" src="https://haypo.github.io/images/cpython_sprint_2016_photo.jpg" /&gt;&lt;/a&gt;
&lt;p&gt;IMHO it was the most productive CPython week ever :-) Having Guido van Rossum
in a room helped to get many PEPs accepted. Having a lot of highly skilled
reviewers in the same room helped to get many new features and many PEP
implementations merged much faster than usual.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Second little game:&lt;/strong&gt; try to spot the sprint on the CPython commit statistics of
the last 12 months (Feb, 2016-Feb, 2017) ;-)&lt;/p&gt;
&lt;a class="reference external image-reference" href="https://github.com/python/cpython/graphs/commit-activity"&gt;&lt;img alt="CPython commits statistics" src="https://haypo.github.io/images/cpython_sprint_2016_commits.png" /&gt;&lt;/a&gt;
&lt;div class="section" id="compact-dict"&gt;
&lt;h2&gt;Compact dict&lt;/h2&gt;
&lt;p&gt;Issue #27350: I reviewed and pushed the &amp;quot;compact dict&amp;quot; implementation which
makes Python dictionaries ordered (by insertion order) by default. It reduces
the memory usage of dictionaries betwen 20% and 25%.&lt;/p&gt;
&lt;p&gt;The implementation was written by INADA Naoki, based on the PyPy
implementation, with a design by Raymond Hettinger.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fastcall"&gt;
&lt;h2&gt;FASTCALL&lt;/h2&gt;
&lt;p&gt;&amp;quot;Fast calls&amp;quot;: Python 3.6 has a new private C API and a new METH_FASTCALL
calling convention which avoids temporary tuple for positional arguments and
avoids temporary dictionary for keyword arguments. Changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Add a new C calling convention: METH_FASTCALL&lt;/li&gt;
&lt;li&gt;Add _PyArg_ParseStack() function&lt;/li&gt;
&lt;li&gt;Add _PyCFunction_FastCallKeywords() function: issue #27810&lt;/li&gt;
&lt;li&gt;Add _PyObject_FastCallKeywords() function: issue #27830&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="more-efficient-call-function-bytecode"&gt;
&lt;h2&gt;More efficient CALL_FUNCTION bytecode&lt;/h2&gt;
&lt;p&gt;I reviewed and pushed: &amp;quot;Rework CALL_FUNCTION* opcodes to produce shorter and
more efficient bytecode&amp;quot; (issue #27213).&lt;/p&gt;
&lt;p&gt;Patch writen by Demur Rumed, design by Serhiy Storchaka, reviewed by Serhiy
Storchaka and me.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pep-509-add-a-private-version-to-dict"&gt;
&lt;h2&gt;PEP 509: Add a private version to dict&lt;/h2&gt;
&lt;p&gt;Guido approved my PEP 509 &amp;quot;Add a new private version to the builtin dict type&amp;quot;.&lt;/p&gt;
&lt;p&gt;I pushed the implementation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pep-524-make-os-urandom-blocking-on-linux"&gt;
&lt;h2&gt;PEP 524: Make os.urandom() blocking on Linux&lt;/h2&gt;
&lt;p&gt;I pushed the implementation of my PEP 524: &amp;quot;Make os.urandom() blocking on
Linux&amp;quot;.&lt;/p&gt;
&lt;p&gt;Issue #27776: The os.urandom() function does now block on Linux 3.17 and newer
until the system urandom entropy pool is initialized to increase the security.&lt;/p&gt;
&lt;p&gt;Read my previous blog post for the painful story behind the PEP:
&lt;a class="reference external" href="https://haypo.github.io/pep-524-os-urandom-blocking.html"&gt;PEP 524: os.urandom() now blocks on Linux&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="asynchronous-pep-525-and-530"&gt;
&lt;h2&gt;Asynchronous PEP 525 and 530&lt;/h2&gt;
&lt;p&gt;Guido van Rossum approved two PEPs of Yury Selivanov:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;PEP 525: Asynchronous Generators&lt;/li&gt;
&lt;li&gt;PEP 530: Asynchronous Comprehensions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I reviewed the huge C implementation with Yury on my side :-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="unicode-escape-codec-optimization"&gt;
&lt;h2&gt;unicode_escape codec optimization&lt;/h2&gt;
&lt;p&gt;I reviewed and pushed &amp;quot;Optimize unicode_escape and raw_unicode_escape&amp;quot; (the
isue #16334), patch written by Serhiy Storchaka.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-6-bugfixes"&gt;
&lt;h2&gt;Python 3.6 bugfixes&lt;/h2&gt;
&lt;p&gt;I happily found many issues including a major one: regular list-comprehension
were completely broken :-)&lt;/p&gt;
&lt;p&gt;Another minor issue: SyntaxError didn't reported the correct line number in a
specific case.&lt;/p&gt;
&lt;p&gt;Don't worry, Yury fixed both ;-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="official-sprint-report"&gt;
&lt;h2&gt;Official sprint report&lt;/h2&gt;
&lt;p&gt;Read also the official report: &lt;a class="reference external" href="http://blog.python.org/2016/09/python-core-development-sprint-2016-36.html"&gt;Python Core Development Sprint 2016: 3.6 and
beyond!&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>PEP 524: os.urandom() now blocks on Linux in Python 3.6</title><link href="https://haypo.github.io/pep-524-os-urandom-blocking.html" rel="alternate"></link><published>2017-02-14T12:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-14:pep-524-os-urandom-blocking.html</id><summary type="html">&lt;div class="section" id="getrandom-avoids-file-descriptors"&gt;
&lt;h2&gt;getrandom() avoids file descriptors&lt;/h2&gt;
&lt;p&gt;Last years, I'm making sometimes enhancements in the Python code used to
generate random numbers, the C implementation of &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt;. My main two
changes were to use the new &lt;tt class="docutils literal"&gt;getentropy()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; functions when
available on Linux, Solaris, OpenBSD, etc.&lt;/p&gt;
&lt;p&gt;In 2013, &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; opened a file descriptor to read from
&lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt; and then closed it. It was decided to use a single private
file descriptor and keep it open to prevent &lt;tt class="docutils literal"&gt;EMFILE&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;ENFILE&lt;/tt&gt; errors
(too many open files) under high system loads with many threads: see the issue
#18756.&lt;/p&gt;
&lt;p&gt;The private file descriptor introduced a backward incompatible change in badly
written programs. The code was modified to call &lt;tt class="docutils literal"&gt;fstat()&lt;/tt&gt; to check if the
file descriptor was closed and then replaced with a different file descriptor
(but same number): check if &lt;tt class="docutils literal"&gt;st_dev&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;st_ino&lt;/tt&gt; attributes changed.&lt;/p&gt;
&lt;p&gt;In 2014, the new Linux kernel 3.17 added a new &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; syscall which
gives access to random bytes without having to handle a file descriptor. I
modified &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; to call &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; to avoid file descriptors,
but a different issue appeared.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="getrandom-hangs-at-system-startup"&gt;
&lt;h2&gt;getrandom() hangs at system startup&lt;/h2&gt;
&lt;p&gt;On embedded devices and virtual machines, Python 3.5 started to hang at
startup.&lt;/p&gt;
&lt;p&gt;On Debian, a systemd script used Python to compute a MD5 checksum, but Python
was blocked during its initialization. Other users reported that Python blocked
on importing the &lt;tt class="docutils literal"&gt;random&lt;/tt&gt; module, sometimes imported indirectly by a
different module.&lt;/p&gt;
&lt;p&gt;Python was blocked on the &lt;tt class="docutils literal"&gt;getrandom(0)&lt;/tt&gt; syscall, waiting until the system
collected enough entropy to initialize the urandom pool. It took longer than 90
seconds, so systemd killed the service with a timeout. As a consequence, the
system boot takes longer than 90 seconds or can even fail!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fix-python-startup"&gt;
&lt;h2&gt;Fix Python startup&lt;/h2&gt;
&lt;p&gt;The fix was obvious: call &lt;tt class="docutils literal"&gt;getrandom(GRND_NONBLOCK)&lt;/tt&gt; which fails immediately
if the call would block, and fall back on reading from &lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt; which
doesn't block even if the entropy pool is not initialized yet.&lt;/p&gt;
&lt;p&gt;Quickly, our security experts complained that falling back on &lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt;
makes Python less secure. When the fall back path is taken, &lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt;
returns random number not suitable for security purpose (initialized with low
entropy), wheras &lt;a class="reference external" href="https://docs.python.org/dev/library/os.html#os.urandom"&gt;os.urandom() documenation&lt;/a&gt; says: &amp;quot;The returned
data should be unpredictable enough for cryptographic applications&amp;quot; (and
&amp;quot;though its exact quality depends on the OS implementation.&amp;quot;).&lt;/p&gt;
&lt;p&gt;Calling &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; in blocking mode for &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; makes Python more
secure, but it doesn't fix the startup bug.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="discussion-storm"&gt;
&lt;h2&gt;Discussion storm&lt;/h2&gt;
&lt;p&gt;The proposed change started a huge rain of messages. More than 200 messages,
maybe even more than 500 messages, on the bug tracker and python-dev mailing
list. Everyone became a security expert and wanted to give his/her very
important opinion, without listening to other arguments.&lt;/p&gt;
&lt;p&gt;Two Python security experts left the discussion.&lt;/p&gt;
&lt;p&gt;I also ignored new messages. I simply had not enough time to read all of them,
and the discussion tone made me angry.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="new-mailing-list-and-two-new-peps"&gt;
&lt;h2&gt;New mailing list and two new PEPs&lt;/h2&gt;
&lt;p&gt;A new &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;security-sig&lt;/span&gt;&lt;/tt&gt; mailing list, subtitled &amp;quot;os.urandom rehab clinic&amp;quot;, was
created just to take a decision on &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt;!&lt;/p&gt;
&lt;p&gt;Nick Coghlan wrote the &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0522/"&gt;PEP 522: Allow BlockingIOError in security sensitive
APIs&lt;/a&gt;. Basically: he considers
that there is no good default behaviour when &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; would block, so
raise an exception to let users decide.&lt;/p&gt;
&lt;p&gt;I wrote  &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0524/"&gt;PEP 524: Make os.urandom() blocking on Linux&lt;/a&gt;. My PEP proposes to make
&lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; blocking, &lt;em&gt;but&lt;/em&gt; also modify Python startup to fall back on
non-blocking RNG to initialize the secret hash seed and the &lt;tt class="docutils literal"&gt;random&lt;/tt&gt; module
(which is &lt;em&gt;not&lt;/em&gt; sensitive for security, except of &lt;tt class="docutils literal"&gt;random.SystemRandom&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;Nick's PEP describes an important use case: be able to check if
&lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; would block. Instead of adding a flag to &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt;,
I chose to expose the low-level C
&lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; function as a new Python &lt;tt class="docutils literal"&gt;os.getrandom()&lt;/tt&gt; function. Calling
&lt;tt class="docutils literal"&gt;os.getrandom(1, os.GRND_NONBLOCK)&lt;/tt&gt; raises a &lt;tt class="docutils literal"&gt;BlockingIOError&lt;/tt&gt; exception,
as Nick proposed for &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt;, so it's possible to decide what to do in
this case.&lt;/p&gt;
&lt;p&gt;While both PEPs are valid, IMHO my PEP was &lt;em&gt;less&lt;/em&gt; backward incompatible,
simpler and maybe closer to what users &lt;em&gt;expect&lt;/em&gt;. The &amp;quot;os.urandom() would block&amp;quot;
case is a special case with my PEP, but my PEP allows to decide what to do in
that case (thanks to &lt;tt class="docutils literal"&gt;os.getrandom()&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;Guido van Rossum approved my PEP and rejected Nick's PEP. I worked with Nick to
implement my PEP.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-6-changes"&gt;
&lt;h2&gt;Python 3.6 changes&lt;/h2&gt;
&lt;p&gt;I added a new &lt;tt class="docutils literal"&gt;os.getrandom()&lt;/tt&gt; function: expose the Linux
&lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; syscall (issue #27778). I also added the two getrandom() flags:
&lt;tt class="docutils literal"&gt;os.GRND_NONBLOCK&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;os.GRND_RANDOM&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;I modified &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; to block on Linux: call &lt;tt class="docutils literal"&gt;getrandom(0)&lt;/tt&gt;
instead of &lt;tt class="docutils literal"&gt;getrandom(GRND_NONBLOCK)&lt;/tt&gt; (issue #27776).&lt;/p&gt;
&lt;p&gt;I also added a private &lt;tt class="docutils literal"&gt;_PyOS_URandomNonblock()&lt;/tt&gt; function used to initialize
the hash secret and used by &lt;tt class="docutils literal"&gt;random.Random.seed()&lt;/tt&gt; (used to initialize the
&lt;tt class="docutils literal"&gt;random&lt;/tt&gt; module).&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; function now blocks in Python 3.6 on Linux 3.17 and newer
until the system urandom entropy pool is initialized to increase the security.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="read-also-lwn-articles"&gt;
&lt;h2&gt;Read also LWN articles&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://lwn.net/Articles/606141/"&gt;A system call for random numbers: getrandom()&lt;/a&gt; (July 2014)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://lwn.net/Articles/693189/"&gt;Python's os.urandom() in the absence of entropy&lt;/a&gt; (July 2016) -- this story&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://lwn.net/Articles/711013/"&gt;The long road to getrandom() in glibc&lt;/a&gt; (January 2017)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category><category term="security"></category></entry><entry><title>My contributions to CPython during 2016 Q2</title><link href="https://haypo.github.io/contrib-cpython-2016q2.html" rel="alternate"></link><published>2017-02-12T18:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-12:contrib-cpython-2016q2.html</id><summary type="html">&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2016 Q2
(april, may, june):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2016-04-01&amp;quot;):date(&amp;quot;2016-06-30&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 52 non-merge commits + 22 merge commits (total: 74 commits).&lt;/p&gt;
&lt;p&gt;Previous report: &lt;a class="reference external" href="https://haypo.github.io/contrib-cpython-2016q1.html"&gt;My contributions to CPython during 2016 Q1&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="start-of-my-work-on-optimization"&gt;
&lt;h2&gt;Start of my work on optimization&lt;/h2&gt;
&lt;p&gt;During 2016 Q2, I started to spend more time on optimizing CPython.&lt;/p&gt;
&lt;p&gt;I experimented a change on CPython: a new FASTCALL calling convention to avoid
the creation of a temporary tuple to pass positional argulments: &lt;a class="reference external" href="http://bugs.python.org/issue26814"&gt;issue26814&lt;/a&gt;. Early results were really good: calling
builtin functions became between 20% and 50% faster!&lt;/p&gt;
&lt;p&gt;Quickly, my optimization work was blocked by unreliable benchmarks. I spent the
rest of the year 2016 analyzing benchmarks and making benchmarks more stable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="subprocess-now-emits-resourcewarning"&gt;
&lt;h2&gt;subprocess now emits ResourceWarning&lt;/h2&gt;
&lt;p&gt;subprocess.Popen destructor now emits a ResourceWarning warning if the child
process is still running (issue #26741). The warning helps to track and fix
zombi processes. I updated asyncio to prevent a false ResourceWarning (warning
whereas the child process completed): asyncio now copies the child process exit
status to the internal Popen object.&lt;/p&gt;
&lt;p&gt;I also fixed the POSIX implementation of subprocess.Popen._execute_child(): it
now sets the returncode attribute from the child process exit status when exec
failed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="security-fix-potential-shell-injections-in-ctypes-util"&gt;
&lt;h2&gt;Security: fix potential shell injections in ctypes.util&lt;/h2&gt;
&lt;p&gt;I rewrote methods of the ctypes.util module using &lt;tt class="docutils literal"&gt;os.popen()&lt;/tt&gt;. I replaced
&lt;tt class="docutils literal"&gt;os.popen()&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;subprocess.Popen&lt;/tt&gt; without shell (issue #22636) to fix a
class of security vulneratiblity, &amp;quot;shell injection&amp;quot; (inject arbitrary shell
commands to take the control of a computer).&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;os.popen()&lt;/tt&gt; function uses a shell, so there is a risk if the command
line arguments are not properly escaped for shell. Using &lt;tt class="docutils literal"&gt;subproces.Popen&lt;/tt&gt;
without shell fixes completely the risk.&lt;/p&gt;
&lt;p&gt;Note: the &lt;tt class="docutils literal"&gt;ctypes&lt;/tt&gt; is generally not considered as &amp;quot;safe&amp;quot;, but it doesn't harm
to make it more secure ;-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimization-pymem-malloc-now-uses-pymalloc"&gt;
&lt;h2&gt;Optimization: PyMem_Malloc() now uses pymalloc&lt;/h2&gt;
&lt;p&gt;PyMem_Malloc() now uses the fast Python &amp;quot;pymalloc&amp;quot; memory allocator which is
optimized for small objects with a short lifetime (issue #26249). The change
makes some benchmarks up to 4% faster.&lt;/p&gt;
&lt;p&gt;This change was possible thanks to the whole preparation work I did in the 2016
Q1, especially the new GIL check in memory allocator debug hooks and the new
&lt;tt class="docutils literal"&gt;PYTHONMALLOC=debug&lt;/tt&gt; environment variable enabling these hooks on a Python
compiled in released mode.&lt;/p&gt;
&lt;p&gt;I tested lxml, Pillow, cryptography and numpy before pushing the change,
as asked by Marc-Andre Lemburg. All these projects work with the change, except
of numpy. I wrote a fix for numpy: &lt;a class="reference external" href="https://github.com/numpy/numpy/pull/7404"&gt;Use PyMem_RawMalloc on Python 3.4 and newer&lt;/a&gt;, merged one month later (my first
contribution to numy!).&lt;/p&gt;
&lt;p&gt;The change indirectly helped to identify and fix a memory leak in the
&lt;tt class="docutils literal"&gt;formatfloat()&lt;/tt&gt; function used to format bytes strings: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;b&amp;quot;%f&amp;quot;&lt;/span&gt; % 1.2&lt;/tt&gt; (issue
#25349, #26249).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimization"&gt;
&lt;h2&gt;Optimization&lt;/h2&gt;
&lt;p&gt;Issue #27056: Optimize pickle.load() and pickle.loads(), up to 10% faster to
deserialize a lot of small objects. I found this optimization using Linux perf
on Python compiled with PGO. My change implements manually the optimization if
Python is not compiled with PGO.&lt;/p&gt;
&lt;p&gt;Issue #26770: When &lt;tt class="docutils literal"&gt;set_inheritable()&lt;/tt&gt; is implemented with &lt;tt class="docutils literal"&gt;fcntl()&lt;/tt&gt;, don't
call &lt;tt class="docutils literal"&gt;fcntl()&lt;/tt&gt; twice if the &lt;tt class="docutils literal"&gt;FD_CLOEXEC&lt;/tt&gt; flag is already set to the
requested value. Linux uses &lt;tt class="docutils literal"&gt;ioctl()&lt;/tt&gt; and so always only need a single
syscall.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="changes"&gt;
&lt;h2&gt;Changes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26716: Replace IOError with OSError in fcntl documentation, IOError is
a deprecated alias to OSError since Python 3.3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26639: Replace the deprecated &lt;tt class="docutils literal"&gt;imp&lt;/tt&gt; module with the &lt;tt class="docutils literal"&gt;importlib&lt;/tt&gt;
module in &lt;tt class="docutils literal"&gt;Tools/i18n/pygettext.py&lt;/tt&gt;. Remove &lt;tt class="docutils literal"&gt;_get_modpkg_path()&lt;/tt&gt;,
replaced with &lt;tt class="docutils literal"&gt;importlib.util.find_spec()&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26735: Fix os.urandom() on Solaris 11.3 and newer when reading more
than 1024 bytes: call getrandom() multiple times with a limit of 1024 bytes
per call.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;configure: fix &lt;tt class="docutils literal"&gt;HAVE_GETRANDOM_SYSCALL&lt;/tt&gt; check, syscall() function requires
&lt;tt class="docutils literal"&gt;#include &amp;lt;unistd.h&amp;gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26766: Fix _PyBytesWriter_Finish(). Return a bytearray object when
bytearray is requested and when the small buffer is used. Fix also
test_bytes: bytearray%args must return a bytearray type.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #26777: Fix random failure of test_asyncio.test_timeout_disable() on
the &amp;quot;AMD64 FreeBSD 9.x 3.5&amp;quot; buildbot:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
File &amp;quot;.../Lib/test/test_asyncio/test_tasks.py&amp;quot;, line 2398, in go
  self.assertTrue(0.09 &amp;lt; dt &amp;lt; 0.11, dt)
AssertionError: False is not true : 0.11902812402695417
&lt;/pre&gt;
&lt;p&gt;Replace &lt;tt class="docutils literal"&gt;&amp;lt; 0.11&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;&amp;lt; 0.15&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Backport test_gdb fix for s390x buildbots to Python 3.5.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Cleanup import.c: replace &lt;tt class="docutils literal"&gt;PyUnicode_RPartition()&lt;/tt&gt; with
&lt;tt class="docutils literal"&gt;PyUnicode_FindChar()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;PyUnicode_Substring()&lt;/tt&gt; to avoid the creation
of a temporary tuple. Use &lt;tt class="docutils literal"&gt;PyUnicode_FromFormat()&lt;/tt&gt; to build a string and
avoid the single_dot ('.') singleton.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;regrtest now uses subprocesses when the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-j1&lt;/span&gt;&lt;/tt&gt; command line option is used:
each test file runs in a fresh child process. Before, the -j1 option was
ignored. &lt;tt class="docutils literal"&gt;Tools/buildbot/test.bat&lt;/tt&gt; script now uses -j1 by default to run
each test file in fresh child process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;regrtest: display test result (passed, failed, ...) after each test
completion. In multiprocessing mode: always display the result. In sequential
mode: only display the result if the test did not pass&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Issue #27278: Fix &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; implementation using &lt;tt class="docutils literal"&gt;getrandom()&lt;/tt&gt; on
Linux. Truncate size to &lt;tt class="docutils literal"&gt;INT_MAX&lt;/tt&gt; and loop until we collected enough random
bytes, instead of casting a directly &lt;tt class="docutils literal"&gt;Py_ssize_t&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;int&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="contributions"&gt;
&lt;h2&gt;Contributions&lt;/h2&gt;
&lt;p&gt;I also pushed a few changes written by other contributors.&lt;/p&gt;
&lt;p&gt;Issue #26839: &lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; doesn't block on Linux anymore. On Linux,
&lt;tt class="docutils literal"&gt;os.urandom()&lt;/tt&gt; now calls getrandom() with &lt;tt class="docutils literal"&gt;GRND_NONBLOCK&lt;/tt&gt; to fall back on
reading &lt;tt class="docutils literal"&gt;/dev/urandom&lt;/tt&gt; if the urandom entropy pool is not initialized yet.
Patch written by &lt;strong&gt;Colm Buckley&lt;/strong&gt;. This issue started a huge annoying discussion
around random number generation on the bug tracker and the python-dev mailing
list.  I later wrote the &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0524/"&gt;PEP 524: Make os.urandom() blocking on Linux&lt;/a&gt; to fix the issue!&lt;/p&gt;
&lt;p&gt;Other changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26647: Cleanup opcode: simplify code to build &lt;tt class="docutils literal"&gt;opcode.opname&lt;/tt&gt;. Patch
written by &lt;strong&gt;Demur Rumed&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26647: Cleanup modulefinder: use &lt;tt class="docutils literal"&gt;dis.opmap[name]&lt;/tt&gt; rather than
&lt;tt class="docutils literal"&gt;dis.opname.index(name)&lt;/tt&gt;. Patch written by &lt;strong&gt;Demur Rumed&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26801: Fix error handling in &lt;tt class="docutils literal"&gt;shutil.get_terminal_size()&lt;/tt&gt;: catch
AttributeError instead of NameError. Skip the functional test of test_shutil
using the &lt;tt class="docutils literal"&gt;stty size&lt;/tt&gt; command if the &lt;tt class="docutils literal"&gt;os.get_terminal_size()&lt;/tt&gt; function is
missing. Patch written by &lt;strong&gt;Emanuel Barry&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26802: Optimize function calls only using unpacking like
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;func(*tuple)&lt;/span&gt;&lt;/tt&gt; (no other positional argument, no keyword argument): avoid
copying the tuple. Patch written by &lt;strong&gt;Joe Jevnik&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #21668: Add missing libm dependency in setup.py: link audioop,
_datetime, _ctypes_test modules to libm, except on Mac OS X. Patch written by
&lt;strong&gt;Chi Hsuan Yen&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26799: Fix python-gdb.py: don't get C types at startup, only on
demand. The C types can change if python-gdb.py is loaded before loading the
Python executable in gdb. Patch written by &lt;strong&gt;Thomas Ilsche&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #27057: Fix os.set_inheritable() on Android, ioctl() is blocked by
SELinux and fails with EACCESS. The function now falls back to fcntl(). Patch
written by &lt;strong&gt;Micha Bednarski&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26647: Fix typo in test_grammar. Patch written by &lt;strong&gt;Demur Rumed&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>My contributions to CPython during 2016 Q1</title><link href="https://haypo.github.io/contrib-cpython-2016q1.html" rel="alternate"></link><published>2017-02-09T17:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2017-02-09:contrib-cpython-2016q1.html</id><summary type="html">&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2016 Q1
(january, februrary, march):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2016-01-01&amp;quot;):date(&amp;quot;2016-03-31&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 196 non-merge commits + 33 merge commits (total: 229 commits).&lt;/p&gt;
&lt;p&gt;Previous report: &lt;a class="reference external" href="https://haypo.github.io/contrib-cpython-2015q4.html"&gt;My contributions to CPython during 2015 Q4&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Since this report is much longer than I expected, here are the highlights:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 8: no pep8, no chocolate!&lt;/li&gt;
&lt;li&gt;AST enhancements coming from FAT Python&lt;/li&gt;
&lt;li&gt;faulthandler now catchs Windows fatal exceptions&lt;/li&gt;
&lt;li&gt;New PYTHONMALLOC environment variable&lt;/li&gt;
&lt;li&gt;tracemalloc: new C API and support multiple address spaces&lt;/li&gt;
&lt;li&gt;ResourceWarning warnings now come with a traceback&lt;/li&gt;
&lt;li&gt;PyMem_Malloc() now fails if the GIL is not held&lt;/li&gt;
&lt;li&gt;Interesting bug: reentrant flag in tracemalloc&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="python-8-no-pep8-no-chocolate"&gt;
&lt;h2&gt;Python 8: no pep8, no chocolate!&lt;/h2&gt;
&lt;p&gt;I prepared an April Fool: &lt;a class="reference external" href="https://mail.python.org/pipermail/python-dev/2016-March/143603.html"&gt;[Python-Dev] The next major Python version will be
Python 8&lt;/a&gt; :-)&lt;/p&gt;
&lt;p&gt;I increased Python version to 8, added the &lt;tt class="docutils literal"&gt;pep8&lt;/tt&gt; module and modified
&lt;tt class="docutils literal"&gt;importlib&lt;/tt&gt; to raise an &lt;tt class="docutils literal"&gt;ImportError&lt;/tt&gt; if a module is not PEP8-compliant!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ast-enhancements-coming-from-fat-python"&gt;
&lt;h2&gt;AST enhancements coming from FAT Python&lt;/h2&gt;
&lt;p&gt;Changes coming from my &lt;a class="reference external" href="http://faster-cpython.readthedocs.io/fat_python.html"&gt;FAT Python&lt;/a&gt; (AST optimizer, run
ahead of time):&lt;/p&gt;
&lt;p&gt;The compiler now ignores constant statements like &lt;tt class="docutils literal"&gt;b'bytes'&lt;/tt&gt; (issue #26204).
I had to replace constant statement with expressions to prepare the change (ex:
replace &lt;tt class="docutils literal"&gt;b'bytes'&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;x = b'bytes'&lt;/tt&gt;). First, the compiler emited a
&lt;tt class="docutils literal"&gt;SyntaxWarning&lt;/tt&gt;, but it was quickly decided to let linters to emit such
warnings to not annoy users: &lt;a class="reference external" href="https://mail.python.org/pipermail/python-dev/2016-February/143163.html"&gt;read the thread on python-dev&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Example, Python 3.5:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; def f():
...  b'bytes'
...
&amp;gt;&amp;gt;&amp;gt; import dis; dis.dis(f)
  2           0 LOAD_CONST               1 (b'bytes')
              3 POP_TOP
              4 LOAD_CONST               0 (None)
              7 RETURN_VALUE
&lt;/pre&gt;
&lt;p&gt;Python 3.6:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; def f():
...  b'bytes'
...
&amp;gt;&amp;gt;&amp;gt; import dis; dis.dis(f)
  1           0 LOAD_CONST               0 (None)
              2 RETURN_VALUE
&lt;/pre&gt;
&lt;p&gt;Other changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26107: The format of the co_lnotab attribute of code objects changes
to support negative line number delta. It allows AST optimizers to move
instructions without breaking Python tracebacks. Change needed by the loop
unrolling optimization of FAT Python.&lt;/li&gt;
&lt;li&gt;Issue #26146: Add a new kind of AST node: &lt;tt class="docutils literal"&gt;ast.Constant&lt;/tt&gt;. It can be used by
external AST optimizers like FAT Python, but the compiler does not emit
directly such node. Update code to accept ast.Constant instead of ast.Num
and/or ast.Str.&lt;/li&gt;
&lt;li&gt;Issue #26146: &lt;tt class="docutils literal"&gt;marshal.loads()&lt;/tt&gt; now uses the empty frozenset singleton. It
fixes a test failure in FAT Python and reduces the memory footprint.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="faulthandler-now-catchs-windows-fatal-exceptions"&gt;
&lt;h2&gt;faulthandler now catchs Windows fatal exceptions&lt;/h2&gt;
&lt;p&gt;I enhanced the faulthandler.enable() function on Windows to set a
handler for Windows fatal exceptions using &lt;tt class="docutils literal"&gt;AddVectoredExceptionHandler()&lt;/tt&gt;
(issue #23848).&lt;/p&gt;
&lt;p&gt;Windows exceptions are the native way to handle fatal errors on Windows,
whereas UNIX signals SIGSEGV, SIGFPE and SIGABRT are &amp;quot;emulated&amp;quot; on top of that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="new-pythonmalloc-environment-variable"&gt;
&lt;h2&gt;New PYTHONMALLOC environment variable&lt;/h2&gt;
&lt;p&gt;I added a new &lt;tt class="docutils literal"&gt;PYTHONMALLOC&lt;/tt&gt; environment variable (issue #26516) to set the
Python memory allocators.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;PYTHONMALLOC=debug&lt;/tt&gt; enables debug hooks on a Python compiled in release
mode, whereas Python 3.5 requires to recompile Python in debug mode. These
hooks implements various checks:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Detect &lt;strong&gt;buffer underflow&lt;/strong&gt;: write before the start of the buffer&lt;/li&gt;
&lt;li&gt;Detect &lt;strong&gt;buffer overflow&lt;/strong&gt;: write after the end of the buffer&lt;/li&gt;
&lt;li&gt;Detect API violations, ex: &lt;tt class="docutils literal"&gt;PyObject_Free()&lt;/tt&gt; called on a buffer
allocated by &lt;tt class="docutils literal"&gt;PyMem_Malloc()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Check if the GIL is held when allocator functions of PYMEM_DOMAIN_OBJ (ex:
&lt;tt class="docutils literal"&gt;PyObject_Malloc()&lt;/tt&gt;) and PYMEM_DOMAIN_MEM (ex: &lt;tt class="docutils literal"&gt;PyMem_Malloc()&lt;/tt&gt;) domains
are called&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Moreover, logging a fatal memory error now uses the tracemalloc module to get
the traceback where a memory block was allocated. Example of a buffer overflow
using &lt;tt class="docutils literal"&gt;python3.6 &lt;span class="pre"&gt;-X&lt;/span&gt; tracemalloc=5&lt;/tt&gt; (store 5 frames in traces):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Debug memory block at address p=0x7fbcd41666f8: API 'o'
    4 bytes originally requested
    The 7 pad bytes at p-7 are FORBIDDENBYTE, as expected.
    The 8 pad bytes at tail=0x7fbcd41666fc are not all FORBIDDENBYTE (0xfb):
        at tail+0: 0x02 *** OUCH
        at tail+1: 0xfb
        at tail+2: 0xfb
        ...
    The block was made by call #1233329 to debug malloc/realloc.
    Data at p: 1a 2b 30 00

Memory block allocated at (most recent call first):
  File &amp;quot;test/test_bytes.py&amp;quot;, line 323
  File &amp;quot;unittest/case.py&amp;quot;, line 600
  ...

Fatal Python error: bad trailing pad byte

Current thread 0x00007fbcdbd32700 (most recent call first):
  File &amp;quot;test/test_bytes.py&amp;quot;, line 323 in test_hex
  File &amp;quot;unittest/case.py&amp;quot;, line 600 in run
  ...
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;PYTHONMALLOC=malloc&lt;/tt&gt; forces the usage of the system &lt;tt class="docutils literal"&gt;malloc()&lt;/tt&gt; allocator.
This option can be used with Valgrind. Without this option, Valgrind emits tons
of false alarms in the Python &lt;tt class="docutils literal"&gt;pymalloc&lt;/tt&gt; memory allocator.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tracemalloc-new-c-api-and-support-multiple-address-spaces"&gt;
&lt;h2&gt;tracemalloc: new C API and support multiple address spaces&lt;/h2&gt;
&lt;p&gt;Antoine Pitrou and Nathaniel Smith asked me to enhance the tracemalloc module:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Add a C API to be able to manually track/untrack memory blocks, to track
the memory allocated by custom memory allocators. For example, numpy uses
allocators with a specific memory alignment for SIMD instructions.&lt;/li&gt;
&lt;li&gt;Support tracking memory of different address spaces. For example, central
(CPU) memory and GPU memory for numpy.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="support-multiple-address-spaces"&gt;
&lt;h3&gt;Support multiple address spaces&lt;/h3&gt;
&lt;p&gt;I made deep changes in the &lt;tt class="docutils literal"&gt;hashtable.c&lt;/tt&gt; code (simple C implementation of an
hash table used by &lt;tt class="docutils literal"&gt;_tracemalloc&lt;/tt&gt;) to support keys of a variable size (issue
#26588), instead of using an hardcoded &lt;tt class="docutils literal"&gt;void *&lt;/tt&gt; size. It allows to support
keys larger than &lt;tt class="docutils literal"&gt;sizeof(void*)&lt;/tt&gt;, but also to use &lt;em&gt;less&lt;/em&gt; memory for keys
smaller than &lt;tt class="docutils literal"&gt;sizeof(void*)&lt;/tt&gt; (ex: &lt;tt class="docutils literal"&gt;int&lt;/tt&gt; keys).&lt;/p&gt;
&lt;p&gt;Then I extended the C &lt;tt class="docutils literal"&gt;_tracemalloc&lt;/tt&gt; module and the Python &lt;tt class="docutils literal"&gt;tracemalloc&lt;/tt&gt; to
add a new &lt;tt class="docutils literal"&gt;domain&lt;/tt&gt; attribute to traces: add &lt;tt class="docutils literal"&gt;Trace.domain&lt;/tt&gt; attribute and
&lt;tt class="docutils literal"&gt;tracemalloc.DomainFilter&lt;/tt&gt; class.&lt;/p&gt;
&lt;p&gt;The final step was to optimize the memory footprint of _tracemalloc. Start with
compact keys (&lt;tt class="docutils literal"&gt;Py_uintptr_t&lt;/tt&gt; type) and only switch to &lt;tt class="docutils literal"&gt;pointer_t&lt;/tt&gt; keys when
the first memory block with a non-zero domain is tracked (when one more one
address space is used). So the &lt;tt class="docutils literal"&gt;_tracemalloc&lt;/tt&gt; memory usage doesn't change by
default in Python 3.6!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="c-api"&gt;
&lt;h3&gt;C API&lt;/h3&gt;
&lt;p&gt;I added a private C API (issue #26530):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
int _PyTraceMalloc_Track(_PyTraceMalloc_domain_t domain, Py_uintptr_t ptr, size_t size);
int _PyTraceMalloc_Untrack(_PyTraceMalloc_domain_t domain, Py_uintptr_t ptr);
&lt;/pre&gt;
&lt;p&gt;I waited for Antoine and Nathaniel feedback on this API, but the API remains
private in Python 3.6 since none reviewed it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="resourcewarning-warnings-now-come-with-a-traceback"&gt;
&lt;h2&gt;ResourceWarning warnings now come with a traceback&lt;/h2&gt;
&lt;div class="section" id="final-result"&gt;
&lt;h3&gt;Final result&lt;/h3&gt;
&lt;p&gt;Before going to explain the long development of the feature, let's see an
example of the final result! Example with the script &lt;tt class="docutils literal"&gt;example.py&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import warnings

def func():
    return open(__file__)

f = func()
f = None
&lt;/pre&gt;
&lt;p&gt;Output of the command &lt;tt class="docutils literal"&gt;python3.6 &lt;span class="pre"&gt;-Wd&lt;/span&gt; &lt;span class="pre"&gt;-X&lt;/span&gt; tracemalloc=5 example.py&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
example.py:7: ResourceWarning: unclosed file &amp;lt;_io.TextIOWrapper name='example.py' mode='r' encoding='UTF-8'&amp;gt;
  f = None
Object allocated at (most recent call first):
  File &amp;quot;example.py&amp;quot;, lineno 4
    return open(__file__)
  File &amp;quot;example.py&amp;quot;, lineno 6
    f = func()
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;Object allocated at &lt;span class="pre"&gt;(...)&lt;/span&gt;&lt;/tt&gt; part is the new feature ;-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="add-source-parameter-to-warnings"&gt;
&lt;h3&gt;Add source parameter to warnings&lt;/h3&gt;
&lt;p&gt;Python 3 logs &lt;tt class="docutils literal"&gt;ResourceWarning&lt;/tt&gt; warnings when a resource is not closed
properly to help developers to handle resources correctly. The problem is that
the warning is only logged when the object is destroy, which can occur far from
the object creation and can occur on a line unrelated to the object because of
the garbage collector.&lt;/p&gt;
&lt;p&gt;I added a new &lt;tt class="docutils literal"&gt;tracemalloc&lt;/tt&gt; module to Python 3.4 which has an interesting
&lt;tt class="docutils literal"&gt;tracemalloc.get_object_traceback()&lt;/tt&gt; function. If tracemalloc traced the
allocation of an object, it is able to provide later the traceback where the
object was allocated.&lt;/p&gt;
&lt;p&gt;I wanted to modify the &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; module to call
&lt;tt class="docutils literal"&gt;get_object_traceback()&lt;/tt&gt;, but I noticed that it wasn't possible
to easily extend the &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; API because this module allows to override
&lt;tt class="docutils literal"&gt;showwarning()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;formatwarning()&lt;/tt&gt; functions and these
functions have a fixed number of parameters. Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def showwarning(message, category, filename, lineno, file=None, line=None):
    ...
&lt;/pre&gt;
&lt;p&gt;With the issue #26568, I added new  &lt;tt class="docutils literal"&gt;_showwarnmsg()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;_formatwarnmsg()&lt;/tt&gt;
functions to the warnings module which get a &lt;tt class="docutils literal"&gt;warnings.WarningMessage&lt;/tt&gt; object
instead of a list of parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def _showwarnmsg(msg):
    ...
&lt;/pre&gt;
&lt;p&gt;I added a &lt;tt class="docutils literal"&gt;source&lt;/tt&gt; attribute to &lt;tt class="docutils literal"&gt;warnings.WarningMessage&lt;/tt&gt; (issue #26567)
and a new optional &lt;tt class="docutils literal"&gt;source&lt;/tt&gt; parameter to &lt;tt class="docutils literal"&gt;warnings.warn()&lt;/tt&gt; (issue #26604):
the leaked resource object. I modified &lt;tt class="docutils literal"&gt;_formatwarnmsg()&lt;/tt&gt; to log the
traceback where resource was allocated, if available.&lt;/p&gt;
&lt;p&gt;The tricky part was to fix corner cases when the following functions of the
&lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; module are overriden:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;formatwarning()&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;showwarning()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;_formatwarnmsg()&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;_showwarnmsg()&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="set-the-source-parameter"&gt;
&lt;h3&gt;Set the source parameter&lt;/h3&gt;
&lt;p&gt;I started to modify modules to set the source parameter when logging
&lt;tt class="docutils literal"&gt;ResourceWarning&lt;/tt&gt; warnings.&lt;/p&gt;
&lt;p&gt;The easy part was to modify &lt;tt class="docutils literal"&gt;asyncore&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;_pyio&lt;/tt&gt; modules to
set the &lt;tt class="docutils literal"&gt;source&lt;/tt&gt; parameter. These modules are implemented in Python, the
change was just to add &lt;tt class="docutils literal"&gt;source=self&lt;/tt&gt;. Example of &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; destructor:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def __del__(self):
    if not self.is_closed():
        warnings.warn(&amp;quot;unclosed event loop %r&amp;quot; % self, ResourceWarning,
                      source=self)
        if not self.is_running():
            self.close()
&lt;/pre&gt;
&lt;p&gt;Note: The warning is logged before the resource is closed to provide more
information in &lt;tt class="docutils literal"&gt;repr()&lt;/tt&gt;. Many objects clear most information in their
&lt;tt class="docutils literal"&gt;close()&lt;/tt&gt; method.&lt;/p&gt;
&lt;p&gt;Modifying C modules was more tricky than expected. I had to implement
&amp;quot;finalizers&amp;quot; (&lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0442/"&gt;PEP 432: Safe object finalization&lt;/a&gt;) for the &lt;tt class="docutils literal"&gt;_socket.socket&lt;/tt&gt; type
(issue #26590) and for the &lt;tt class="docutils literal"&gt;os.scandir()&lt;/tt&gt; iterator (issue #26603).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="more-reliable-warnings"&gt;
&lt;h3&gt;More reliable warnings&lt;/h3&gt;
&lt;p&gt;The Python shutdown process is complex, and some Python functions are broken
during the shutdown. I enhanced the warnings module to handle nicely these
failures and try to log warnings anyway.&lt;/p&gt;
&lt;p&gt;I modified &lt;tt class="docutils literal"&gt;warnings.formatwarning()&lt;/tt&gt; to catch &lt;tt class="docutils literal"&gt;linecache.getline()&lt;/tt&gt;
failures on formatting the traceback.&lt;/p&gt;
&lt;p&gt;Logging the resource traceback is complex, so I only implemented it in Python.
Python tries to use the Python &lt;tt class="docutils literal"&gt;warnings&lt;/tt&gt; module if it was imported, or falls
back on the C &lt;tt class="docutils literal"&gt;_warnings&lt;/tt&gt; module. To get the resource traceback at Python
shutdown, I modified the C module to try to import the Python warning:
&lt;tt class="docutils literal"&gt;_warnings.warn_explicit()&lt;/tt&gt; now tries to import the Python warnings module if
the source parameter is set to be able to log the traceback where the source
was allocated (issue #26592).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fix-resourcewarning-warnings"&gt;
&lt;h3&gt;Fix ResourceWarning warnings&lt;/h3&gt;
&lt;p&gt;Since it became easy to debug these warnings, I fixed some of them in the
Python test suite:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26620: Fix ResourceWarning in test_urllib2_localnet. Use context
manager on urllib objects and use self.addCleanup() to cleanup resources even
if a test is interrupted with CTRL+c&lt;/li&gt;
&lt;li&gt;Issue #25654: multiprocessing: open file with &lt;tt class="docutils literal"&gt;closefd=False&lt;/tt&gt; to avoid
ResourceWarning. _test_multiprocessing: open file with &lt;tt class="docutils literal"&gt;O_EXCL&lt;/tt&gt; to detect
bugs in tests (if a previous test forgot to remove TESTFN).
&lt;tt class="docutils literal"&gt;test_sys_exit()&lt;/tt&gt;: remove TESTFN after each loop iteration&lt;/li&gt;
&lt;li&gt;Fix &lt;tt class="docutils literal"&gt;ResourceWarning&lt;/tt&gt; in test_unittest when interrupted&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="pymem-malloc-now-fails-if-the-gil-is-not-held"&gt;
&lt;h2&gt;PyMem_Malloc() now fails if the GIL is not held&lt;/h2&gt;
&lt;p&gt;Since using the mall object allocator (&lt;tt class="docutils literal"&gt;pymalloc)&lt;/tt&gt;) for dictionary key
storage showed speedup for the dict type (issue #23601), I proposed to
generalize the change, use &lt;tt class="docutils literal"&gt;pymalloc&lt;/tt&gt; for &lt;tt class="docutils literal"&gt;PyMem_Malloc()&lt;/tt&gt;: &lt;a class="reference external" href="https://mail.python.org/pipermail/python-dev/2016-February/143084.html"&gt;[Python-Dev]
Modify PyMem_Malloc to use pymalloc for performance&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main issue was that the change means that &lt;tt class="docutils literal"&gt;PyMem_Malloc()&lt;/tt&gt; now requires
to hold the GIL, whereas it didn't before since it called directly
&lt;tt class="docutils literal"&gt;malloc()&lt;/tt&gt;.&lt;/p&gt;
&lt;div class="section" id="check-if-the-gil-is-held"&gt;
&lt;h3&gt;Check if the GIL is held&lt;/h3&gt;
&lt;p&gt;CPython has a &lt;tt class="docutils literal"&gt;PyGILState_Check()&lt;/tt&gt; function to check if the GIL is held.
Problem: the function doesn't work with subinterpreters: see issues #10915 and
#15751.&lt;/p&gt;
&lt;p&gt;I added an internal flag to &lt;tt class="docutils literal"&gt;PyGILState_Check()&lt;/tt&gt; (issue #26558) to skip the
test. The flag value is false at startup, set to true once the GIL is fully
initialized (Python initialization), set to false again when the GIL is
destroyed (Python finalization). The flag is also set to false when the first
subinterpreter is created.&lt;/p&gt;
&lt;p&gt;This hack works around &lt;tt class="docutils literal"&gt;PyGILState_Check()&lt;/tt&gt; limitations allowing to call
&lt;cite&gt;PyGILState_Check()`&lt;/cite&gt; anytime to debug more bugs earlier.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;_Py_dup()&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;_Py_fstat()&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;_Py_read()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;_Py_write()&lt;/tt&gt; are
low-level helper functions for system functions, but these functions require
the GIL to be held.  Thanks to the &lt;tt class="docutils literal"&gt;PyGILState_Check()&lt;/tt&gt; enhancement, it
became possible to check the GIL using an assertion.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pymem-malloc-and-gil"&gt;
&lt;h3&gt;PyMem_Malloc() and GIL&lt;/h3&gt;
&lt;p&gt;Issue #26563: Debug hooks on Python memory allocators now raise a fatal error
if memory allocator functions like PyMem_Malloc() and PyMem_Malloc() are called
without holding the GIL.&lt;/p&gt;
&lt;p&gt;The change spotted two bugs which I fixed:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26563: Replace PyMem_Malloc() with PyMem_RawMalloc() in the Windows
implementation of os.stat(), the code is called without holding the
GIL.&lt;/li&gt;
&lt;li&gt;Issue #26563: Fix usage of PyMem_Malloc() in overlapped.c. Replace
PyMem_Malloc() with PyMem_RawFree() since PostToQueueCallback() calls
PyMem_Free() in a new C thread which doesn't hold the GIL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wasn't able to switch &lt;tt class="docutils literal"&gt;PyMem_Malloc()&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;pymalloc&lt;/tt&gt; in this quarter,
since it took more a lot of time to implement requested checks and test third
party modules.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fatal-error-and-faulthandler"&gt;
&lt;h3&gt;Fatal error and faulthandler&lt;/h3&gt;
&lt;p&gt;I enhanced the faulthandler module to work in non-Python threads (issue
#26563). I fixed &lt;tt class="docutils literal"&gt;Py_FatalError()&lt;/tt&gt; if called without holding the GIL: don't
try to print the current exception, nor try to flush stdout and stderr: only
dump the traceback of Python threads.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="interesting-bug-reentrant-flag-in-tracemalloc"&gt;
&lt;h2&gt;Interesting bug: reentrant flag in tracemalloc&lt;/h2&gt;
&lt;p&gt;A bug annoyed me a lot: a random assertion error related to a reentrant flag in
the _tracemalloc module.&lt;/p&gt;
&lt;p&gt;Story starting in the &lt;a class="reference external" href="http://bugs.python.org/issue26588#msg262125"&gt;middle of the issue #26588 (2016-03-21)&lt;/a&gt;. While working on issue #26588,
&amp;quot;_tracemalloc: add support for multiple address spaces (domains)&amp;quot;, I noticed an
assertion failure in set_reentrant(), a helper function to set a &lt;em&gt;Thread Local
Storage&lt;/em&gt; (TLS), on a buildbot:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
python: ./Modules/_tracemalloc.c:195: set_reentrant:
    Assertion `PyThread_get_key_value(tracemalloc_reentrant_key) == ((PyObject *) &amp;amp;_Py_TrueStruct)' failed.
&lt;/pre&gt;
&lt;p&gt;I was unable to reproduce the bug on my Fedora 23 (AMD64). After changes on my
patch, I pushed it the day after, but the assertion failed again. I added
assertions and debug informations. More failures, an interesting one on Windows
which uses a single process.&lt;/p&gt;
&lt;p&gt;I added an assertion in tracemalloc_init() to ensure that the reeentrant flag
is set at the end of the function. The reentrant flag was no more set at
tracemalloc_start() entry for an unknown reason. I changed the module
initialization to no call tracemalloc_init() anymore, it's only called on
tracemalloc.start().&lt;/p&gt;
&lt;p&gt;&amp;quot;The bug was seen on 5 buildbots yet: PPC Fedora, AMD64 Debian, s390x RHEL,
AMD64 Windows, x86 Ubuntu.&amp;quot;&lt;/p&gt;
&lt;p&gt;I finally understood and fixed the bug with the &lt;a class="reference external" href="https://hg.python.org/cpython/rev/af1c1149784a"&gt;change af1c1149784a&lt;/a&gt;: tracemalloc_start() and
tracemalloc_stop() don't clear/set the reentrant flag anymore.&lt;/p&gt;
&lt;p&gt;The problem was that I expected that tracemalloc_init() and tracemalloc_start()
functions would always be called in the same thread, whereas it occurred that
tracemalloc_init() was called in thread A when the tracemalloc module is
imported, whereas tracemalloc_start() was called in thread B.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="other-commits"&gt;
&lt;h2&gt;Other commits&lt;/h2&gt;
&lt;div class="section" id="enhancements"&gt;
&lt;h3&gt;Enhancements&lt;/h3&gt;
&lt;p&gt;The developers of the &lt;tt class="docutils literal"&gt;vmprof&lt;/tt&gt; profiler asked me to expose the atomic
variable &lt;tt class="docutils literal"&gt;_PyThreadState_Current&lt;/tt&gt;. The private variable was removed from
Python 3.5.1 API because the implementation of atomic variables depends on the
compiler, compiler options, etc. and so caused compilation issues. I added a
new private &lt;tt class="docutils literal"&gt;_PyThreadState_UncheckedGet()&lt;/tt&gt; function (issue #26154) which
gets the value of the variable without exposing its implementation.&lt;/p&gt;
&lt;p&gt;Other enhancements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26099: The site module now writes an error into stderr if
sitecustomize module can be imported but executing the module raise an
ImportError. Same change for usercustomize.&lt;/li&gt;
&lt;li&gt;Issue #26516: Enhance Python memory allocators documentation. Add link to
PYTHONMALLOCSTATS environment variable. Add parameters to PyMem macros like
PyMem_MALLOC().&lt;/li&gt;
&lt;li&gt;Issue #26569: Fix pyclbr.readmodule() and pyclbr.readmodule_ex() to support
importing packages.&lt;/li&gt;
&lt;li&gt;Issue #26564, #26516, #26563: Enhance documentation on memory allocator debug
hooks.&lt;/li&gt;
&lt;li&gt;doctest now supports packages. Issue #26641: doctest.DocFileTest and
doctest.testfile() now support packages (module splitted into multiple
directories) for the package parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="bugfixes"&gt;
&lt;h3&gt;Bugfixes&lt;/h3&gt;
&lt;p&gt;Issue #25843: When compiling code, don't merge constants if they are equal but
have a different types. For example, &lt;tt class="docutils literal"&gt;f1, f2 = lambda: 1, lambda: 1.0&lt;/tt&gt; is now
correctly compiled to two different functions: &lt;tt class="docutils literal"&gt;f1()&lt;/tt&gt; returns &lt;tt class="docutils literal"&gt;1&lt;/tt&gt; (int) and
&lt;tt class="docutils literal"&gt;f2()&lt;/tt&gt; returns &lt;tt class="docutils literal"&gt;1.0&lt;/tt&gt; (int), even if 1 and 1.0 are equal.&lt;/p&gt;
&lt;p&gt;Other fixes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26101: Fix test_compilepath() of test_compileall. Exclude Lib/test/
from sys.path in test_compilepath(). The directory contains invalid Python
files like Lib/test/badsyntax_pep3120.py, whereas the test ensures that all
files can be compiled.&lt;/li&gt;
&lt;li&gt;Issue #24520: Replace fpgetmask() with fedisableexcept(). On FreeBSD,
fpgetmask() was deprecated long time ago.  fedisableexcept() is now
preferred.&lt;/li&gt;
&lt;li&gt;Issue #26161: Use Py_uintptr_t instead of void* for atomic pointers in
pyatomic.h. Use atomic_uintptr_t when &amp;lt;stdatomic.h&amp;gt; is used. Using void*
causes compilation warnings depending on which implementation of atomic types
is used.&lt;/li&gt;
&lt;li&gt;Issue #26637: The importlib module now emits an ImportError rather than a
TypeError if __import__() is tried during the Python shutdown process but
sys.path is already cleared (set to None).&lt;/li&gt;
&lt;li&gt;doctest: fix _module_relative_path() error message. Write the module name
rather than &amp;lt;module&amp;gt; in the error message, if module has no __file__
attribute (ex: package).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="fix-type-downcasts-on-windows-64-bit"&gt;
&lt;h3&gt;Fix type downcasts on Windows 64-bit&lt;/h3&gt;
&lt;p&gt;In my spare time, I'm trying to fix a few compiler warnings on Windows 64-bit
where the C &lt;tt class="docutils literal"&gt;long&lt;/tt&gt; type is only 32-bit, whereas pointers are &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;64-bit&lt;/span&gt;&lt;/tt&gt; long:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;posix_getcwd(): limit to INT_MAX on Windows. It's more to fix a compiler
warning during compilation, I don't think that Windows support current
working directories larger than 2 GB :-)&lt;/li&gt;
&lt;li&gt;_pickle: Fix load_counted_tuple(), use Py_ssize_t for size. Fix a warning on
Windows 64-bit.&lt;/li&gt;
&lt;li&gt;getpathp.c: fix compiler warning, wcsnlen_s() result type is size_t.&lt;/li&gt;
&lt;li&gt;compiler.c: fix compiler warnings on Windows&lt;/li&gt;
&lt;li&gt;_msi.c: try to fix compiler warnings&lt;/li&gt;
&lt;li&gt;longobject.c: fix compilation warning on Windows 64-bit. We know that
Py_SIZE(b) is -1 or 1 an so fits into the sdigit type.&lt;/li&gt;
&lt;li&gt;On Windows, socket.setsockopt() now raises an OverflowError if the socket
option is larger than INT_MAX bytes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="unicode-bugfixes"&gt;
&lt;h3&gt;Unicode bugfixes&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26227: On Windows, getnameinfo(), gethostbyaddr() and
gethostbyname_ex() functions of the socket module now decode the hostname
from the ANSI code page rather than UTF-8.&lt;/li&gt;
&lt;li&gt;Issue #26217: Unicode resize_compact() must set wstr_length to 0 after
freeing the wstr string. Otherwise, an assertion fails in
_PyUnicode_CheckConsistency().&lt;/li&gt;
&lt;li&gt;Issue #26464: Fix str.translate() when string is ASCII and first replacements
removes characters, but next replacements use a non-ASCII character or a
string longer than 1 character. Regression introduced in Python 3.5.0.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="buildbot-tests"&gt;
&lt;h3&gt;Buildbot, tests&lt;/h3&gt;
&lt;p&gt;Just to give you an idea of the work required to keep a working CI, here is the
list of changes I maded in a single quarter to make tests and Python buildbots
more reliable.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #26610: Skip test_venv.test_with_pip() if ctypes miss&lt;/li&gt;
&lt;li&gt;test_asyncio: fix test_timeout_time(). Accept time delta up to 0.12 second,
instead of 0.11, for the &amp;quot;AMD64 FreeBSD 9.x&amp;quot; buildbot slave.&lt;/li&gt;
&lt;li&gt;Issue #13305: Always test datetime.datetime.strftime(&amp;quot;%4Y&amp;quot;) for years &amp;lt; 1900.
Change quickly reverted, strftime(&amp;quot;%4Y&amp;quot;) fails on most platforms.&lt;/li&gt;
&lt;li&gt;Issue #17758: Skip test_site if site.USER_SITE directory doesn't exist and
cannot be created.&lt;/li&gt;
&lt;li&gt;Fix test_venv on FreeBSD buildbot. Ignore pip warning in
test_venv.test_with_venv().&lt;/li&gt;
&lt;li&gt;Issue #26566: Rewrite test_signal.InterProcessSignalTests. Don't use
os.fork() with a subprocess to not inherit existing signal handlers or
threads: start from a fresh process. Use a timeout of 10 seconds to wait for
the signal instead of 1 second&lt;/li&gt;
&lt;li&gt;Issue #26538: regrtest: Fix module.__path__. libregrtest: Fix setup_tests()
to keep module.__path__ type (_NamespacePath), don't convert to a list.
Add _NamespacePath.__setitem__() method to importlib._bootstrap_external.&lt;/li&gt;
&lt;li&gt;regrtest: add time to output. Timestamps should help to debug slow buildbots,
and timeout and hang on buildbots.&lt;/li&gt;
&lt;li&gt;regrtest: add timeout to main process when using -jN. libregrtest: add a
watchdog to run_tests_multiprocess() using faulthandler.dump_traceback_later().&lt;/li&gt;
&lt;li&gt;Makefile: change default value of TESTTIMEOUT from 1 hour to 15 min.
The whole test suite takes 6 minutes on my laptop. It takes less than 30
minutes on most buildbots. The TESTTIMEOUT is the timeout for a single test
file.&lt;/li&gt;
&lt;li&gt;Buildbots: change also Windows timeout from 1 hour to 15 min&lt;/li&gt;
&lt;li&gt;regrtest: display test duration in sequential mode. Only display duration if
a test takes more than 30 seconds.&lt;/li&gt;
&lt;li&gt;Issue #18787: Try to fix test_spwd on OpenIndiana. Try to get the &amp;quot;root&amp;quot;
entry which should exist on all UNIX instead of &amp;quot;bin&amp;quot; which doesn't exist on
OpenIndiana.&lt;/li&gt;
&lt;li&gt;regrtest: fix --fromfile feature. Update code for the name regrtest output
format. Enhance also test_regrtest test on --fromfile&lt;/li&gt;
&lt;li&gt;regrtest: mention if tests run sequentially or in parallel&lt;/li&gt;
&lt;li&gt;regrtest: when parallel tests are interrupted, display progress&lt;/li&gt;
&lt;li&gt;support.temp_dir(): call support.rmtree() instead of shutil.rmtree(). Try
harder to remove directories on Windows.&lt;/li&gt;
&lt;li&gt;rt.bat: use -m test instead of Libtestregrtest.py&lt;/li&gt;
&lt;li&gt;Refactor regrtest.&lt;/li&gt;
&lt;li&gt;Fix test_warnings.test_improper_option(). test_warnings: only run
test_improper_option() and test_warnings_bootstrap() once. The unit test
doesn't depend on self.module.&lt;/li&gt;
&lt;li&gt;Fix test_os.test_symlink(): remove created symlink.&lt;/li&gt;
&lt;li&gt;Issue #26643: Add missing shutil resources to regrtest.py&lt;/li&gt;
&lt;li&gt;test_urllibnet: set timeout on test_fileno(). Use the default timeout of 30
seconds to avoid blocking forever.&lt;/li&gt;
&lt;li&gt;Issue #26295: When using &amp;quot;python3 -m test --testdir=TESTDIR&amp;quot;, regrtest
doesn't add &amp;quot;test.&amp;quot; prefix to test module names. regrtest also prepends
testdir to sys.path.&lt;/li&gt;
&lt;li&gt;Issue #26295: test_regrtest now uses a temporary directory&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="contributions"&gt;
&lt;h3&gt;Contributions&lt;/h3&gt;
&lt;p&gt;I also pushed a few changes written by other contributors:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #25907: Use {% trans %} tags in HTML templates to ease the translation
of the documentation. The tag comes from Jinja templating system, used by
Sphinx. Patch written by &lt;strong&gt;Julien Palard&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26248: Enhance os.scandir() doc, patch written by Ben Hoyt:&lt;/li&gt;
&lt;li&gt;Fix error message in asyncio.selector_events. Patch written by &lt;strong&gt;Carlo
Beccarini&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #16851: Fix inspect.ismethod() doc, return also True if object is an
unbound method. Patch written by &lt;strong&gt;Anna Koroliuk&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #26574: Optimize bytes.replace(b'', b'.') and bytearray.replace(b'', b'.'):
up to 80% faster. Patch written by &lt;strong&gt;Josh Snider&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>Analysis of a Python performance issue</title><link href="https://haypo.github.io/analysis-python-performance-issue.html" rel="alternate"></link><published>2016-11-19T00:30:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-11-19:analysis-python-performance-issue.html</id><summary type="html">&lt;p&gt;I am working on the CPython benchmark suite (&lt;a class="reference external" href="https://github.com/python/performance"&gt;performance&lt;/a&gt;) and I run the benchmark suite to
upload results to &lt;a class="reference external" href="http://speed.python.org/"&gt;speed.python.org&lt;/a&gt;. While
analying results, I noticed a temporary peak on the &lt;tt class="docutils literal"&gt;call_method&lt;/tt&gt;
benchmark at October 19th:&lt;/p&gt;
&lt;img alt="call_method microbenchmark" src="https://haypo.github.io/images/call_method.png" /&gt;
&lt;p&gt;The graphic shows the performance of the &lt;tt class="docutils literal"&gt;call_method&lt;/tt&gt; microbenchmark between
Feb 29, 2016 and November 17, 2016 on the &lt;tt class="docutils literal"&gt;default&lt;/tt&gt; branch of CPython. The average
is around 17.2 ms, whereas the peak is at 29.0 ms: &lt;strong&gt;68% slower&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;The server has two &amp;quot;Intel(R) Xeon(R) CPU X5680  &amp;#64; 3.33GHz&amp;quot; CPUs, total: 24
logical cores (12 physical cores with HyperThreading). This CPU was launched in
2010 and based on the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Gulftown"&gt;Westmere-EP microarchitecture&lt;/a&gt;. Westmere-EP is based on Westmere,
which is the 32 nm shrink of the Nehalem microarchitecture.&lt;/p&gt;
&lt;div class="section" id="reproduce-results"&gt;
&lt;h2&gt;Reproduce results&lt;/h2&gt;
&lt;p&gt;Before going too far, the first step is to validate that results are
reproductible: reboot the computer, recompile Python, run again the benchmark.&lt;/p&gt;
&lt;p&gt;Instead of running the full benchmark suite, install Python, ..., we will run
directly the benchmark manually using the Python freshly built in its source
code directory.&lt;/p&gt;
&lt;p&gt;Interesting dots on the graphic (can be seen at speed.python.org, not on the
screenshot):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;678fe178da0d, Oct 09, 17.0 ms: &amp;quot;Fast&amp;quot;&lt;/li&gt;
&lt;li&gt;1ce50f7027c1, Oct 19, 28.9 ms: &amp;quot;Slow&amp;quot;&lt;/li&gt;
&lt;li&gt;36af3566b67a, Nov 3, 16.9 ms: Fast again&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I use the following directories:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;~/perf: GitHub haypo/perf project&lt;/li&gt;
&lt;li&gt;~/performance: GitHub python/performance project&lt;/li&gt;
&lt;li&gt;~/cpython: Mercurial CPython repository&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tune the system for benchmarks:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo python3 -m perf system tune
&lt;/pre&gt;
&lt;p&gt;Note: all &lt;tt class="docutils literal"&gt;system&lt;/tt&gt; commands in this article are optional. They help to reduce
the operating system jitter (make benchmarks more reliablee).&lt;/p&gt;
&lt;p&gt;Fast:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r 678fe178da0d
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ mv python python-fast
$ PYTHONPATH=~/perf ./python-fast ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 17.0 ms +- 0.1 ms
&lt;/pre&gt;
&lt;p&gt;Slow:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r 1ce50f7027c1
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ mv python python-slow
$ PYTHONPATH=~/perf ./python-slow ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 29.3 ms +- 0.9 ms
&lt;/pre&gt;
&lt;p&gt;We reproduced the significant benchmark result: 17 ms =&amp;gt; 29 ms.&lt;/p&gt;
&lt;p&gt;I use &lt;tt class="docutils literal"&gt;./configure&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;make clean&lt;/tt&gt; instead of incremental compilation,
&lt;tt class="docutils literal"&gt;make&lt;/tt&gt; command, to avoid compilation errors, and to avoid potential side
effects only caused by the incremental compilation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="analysis-with-the-linux-perf-tool"&gt;
&lt;h2&gt;Analysis with the Linux perf tool&lt;/h2&gt;
&lt;p&gt;To collect perf events, we will run the benchmark with &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--worker&lt;/span&gt;&lt;/tt&gt; to run a
single process and with &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-w0&lt;/span&gt; &lt;span class="pre"&gt;-n100&lt;/span&gt;&lt;/tt&gt; to run the benchmark long enough: 100
samples means at least 10 seconds (a single sample takes at least 100 ms).&lt;/p&gt;
&lt;p&gt;First, reset the system configuration to reset the Linux perf configuration:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo python3 -m perf system reset
&lt;/pre&gt;
&lt;p&gt;Note: &lt;tt class="docutils literal"&gt;python3 &lt;span class="pre"&gt;-m&lt;/span&gt; perf system tune&lt;/tt&gt; reduces the sampling rate of Linux perf
to reduce operating system jitter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="perf-stat"&gt;
&lt;h2&gt;perf stat&lt;/h2&gt;
&lt;p&gt;Command to get general statistics on the benchmark:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ perf stat ./python-slow ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --worker -v -w0 -n100
&lt;/pre&gt;
&lt;p&gt;&amp;quot;Fast&amp;quot; results:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Performance counter stats for ./python-fast:

      3773.585194 task-clock (msec)         #    0.998 CPUs utilized
              369 context-switches          #    0.098 K/sec
                0 cpu-migrations            #    0.000 K/sec
            8,300 page-faults               #    0.002 M/sec
   12,981,234,867 cycles                    #    3.440 GHz                     [83.27%]
    1,460,980,720 stalled-cycles-frontend   #   11.25% frontend cycles idle    [83.36%]
      435,806,788 stalled-cycles-backend    #    3.36% backend  cycles idle    [66.72%]
   29,982,530,201 instructions              #    2.31  insns per cycle
                                            #    0.05  stalled cycles per insn [83.40%]
    5,613,631,616 branches                  # 1487.612 M/sec                   [83.40%]
       16,006,564 branch-misses             #    0.29% of all branches         [83.27%]

      3.780064486 seconds time elapsed
&lt;/pre&gt;
&lt;p&gt;&amp;quot;Slow&amp;quot; results:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Performance counter stats for ./python-slow:

      5906.239860 task-clock (msec)         #    0.998 CPUs utilized
              556 context-switches          #    0.094 K/sec
                0 cpu-migrations            #    0.000 K/sec
            8,393 page-faults               #    0.001 M/sec
   20,651,474,102 cycles                    #    3.497 GHz                     [83.36%]
    8,480,803,345 stalled-cycles-frontend   #   41.07% frontend cycles idle    [83.37%]
    4,247,826,420 stalled-cycles-backend    #   20.57% backend  cycles idle    [66.64%]
   30,011,465,614 instructions              #    1.45  insns per cycle
                                            #    0.28  stalled cycles per insn [83.32%]
    5,612,485,730 branches                  #  950.264 M/sec                   [83.36%]
       13,584,136 branch-misses             #    0.24% of all branches         [83.29%]

      5.915402403 seconds time elapsed
&lt;/pre&gt;
&lt;p&gt;Significant differences, Fast =&amp;gt; Slow:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Instruction per cycle: 2.31 =&amp;gt; 1.45&lt;/li&gt;
&lt;li&gt;stalled-cycles-frontend: &lt;strong&gt;11.25% =&amp;gt; 41.07%&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;stalled-cycles-backend: &lt;strong&gt;3.36% =&amp;gt; 20.57%&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The increase of stalled cycles is interesting. Since the code is supposed to be
identical, it probably means that fetching instructions is slower. It sounds
like an issue with CPU caches.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="statistics-on-the-cpu-l1-instruction-cache"&gt;
&lt;h2&gt;Statistics on the CPU L1 instruction cache&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;perf list&lt;/tt&gt; command can be used to get the name of events collecting
statistics on the CPU L1 instruction cache:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ perf list | grep L1
  L1-icache-loads                                    [Hardware cache event]
  L1-icache-load-misses                              [Hardware cache event]
  (...)
&lt;/pre&gt;
&lt;p&gt;Collect statistics on the CPU L1 instruction cache:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PYTHONPATH=~/perf perf stat -e L1-icache-loads,L1-icache-load-misses ./python-slow ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --worker -w0 -n10
&lt;/pre&gt;
&lt;p&gt;&amp;quot;Fast&amp;quot; statistics:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Performance counter stats for './python-fast (...)':

   10,134,106,571 L1-icache-loads
       10,917,606 L1-icache-load-misses     #    0.11% of all L1-icache hits

      3.775067668 seconds time elapsed
&lt;/pre&gt;
&lt;p&gt;&amp;quot;Slow&amp;quot; statistics:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Performance counter stats for './python-slow (...)':

   10,753,371,258 L1-icache-loads
      848,511,308 L1-icache-load-misses     #    7.89% of all L1-icache hits

      6.020490449 seconds time elapsed
&lt;/pre&gt;
&lt;p&gt;Cache misses on the L1 cache: &lt;strong&gt;0.1%&lt;/strong&gt; (Fast) =&amp;gt; &lt;strong&gt;8.0%&lt;/strong&gt; (Slow).&lt;/p&gt;
&lt;p&gt;The slow Python has &lt;strong&gt;71.7x more L1 cache misses&lt;/strong&gt; than the fast Python! It can
explain the significant performance drop.&lt;/p&gt;
&lt;div class="section" id="perf-report"&gt;
&lt;h3&gt;perf report&lt;/h3&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;perf record&lt;/tt&gt; command can be used to collect statistics on the functions
where the benchmark spends most of its time. Commands:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PYTHONPATH=~/perf perf record ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --worker -v -w0 -n100
perf report
&lt;/pre&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
40.27%  python  python              [.] _PyEval_EvalFrameDefault
10.30%  python  python              [.] call_function
10.21%  python  python              [.] PyFrame_New
 8.56%  python  python              [.] frame_dealloc
 5.51%  python  python              [.] PyObject_GenericGetAttr
 (...)
&lt;/pre&gt;
&lt;p&gt;More than 64% of the time is spent in these 5 functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="system-tune"&gt;
&lt;h3&gt;system tune&lt;/h3&gt;
&lt;p&gt;To run benchmark, tune again the system for benchmarks:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo python3 -m perf system tune
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="hg-bisect"&gt;
&lt;h2&gt;hg bisect&lt;/h2&gt;
&lt;p&gt;To find the revision which introduces the performance slowdown, we use a
shell script to automate the bisection of the Mercurial history.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;cmd.sh&lt;/tt&gt; script checking if a revision is fast or slow:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
set -e -x
./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
rm -f json
PYTHONPATH=~/perf ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --worker -o json -v
PYTHONPATH=~/perf python3 cmd.py json
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;cmd.sh&lt;/tt&gt; uses the following &lt;tt class="docutils literal"&gt;cmd.py&lt;/tt&gt; script which checks if the benchmark
is slow: if it takes longer than 23 ms (average between 17 ans 29 ms):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import perf, sys
bench = perf.Benchmark.load('json')
bad = (29 + 17) / 2.0
ms = bench.median() * 1e3
if ms &amp;gt;= bad:
    print(&amp;quot;BAD! %.1f ms &amp;gt;= %.1f ms&amp;quot; % (ms, bad))
    sys.exit(1)
else:
    print(&amp;quot;good: %.1f ms &amp;lt; %.1f ms&amp;quot; % (ms, bad))
&lt;/pre&gt;
&lt;p&gt;In the bisection, &amp;quot;good&amp;quot; means &amp;quot;fast&amp;quot; (17 ms), whereas &amp;quot;bad&amp;quot; means &amp;quot;slow&amp;quot; (29
ms).  The peak, revision 1ce50f7027c1, is used as the first &amp;quot;bad&amp;quot; revision. The
previous fast revision before the peak is 678fe178da0d, our first &amp;quot;good&amp;quot;
revision.&lt;/p&gt;
&lt;p&gt;Commands to identify the first revision which introduced the slowdown:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg bisect --reset
hg bisect -b 1ce50f7027c1
hg bisect -g 678fe178da0d
time hg bisect -c ./cmd.sh
&lt;/pre&gt;
&lt;p&gt;3 min 52 sec later:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
The first bad revision is:
changeset:   104531:83877018ef97
parent:      104528:ce85a1f129e3
parent:      104530:2d352bf2b228
user:        Serhiy Storchaka &amp;lt;storchaka&amp;#64;gmail.com&amp;gt;
date:        Tue Oct 18 13:27:54 2016 +0300
files:       Misc/NEWS
description:
Issue #23782: Fixed possible memory leak in _PyTraceback_Add() and exception
loss in PyTraceBack_Here().
&lt;/pre&gt;
&lt;p&gt;Thank you &lt;tt class="docutils literal"&gt;hg bisect&lt;/tt&gt;! I love this tool.&lt;/p&gt;
&lt;p&gt;Even if I trust &lt;tt class="docutils literal"&gt;hg bisect&lt;/tt&gt;, I don't trust benchmarks, so I recheck manually:&lt;/p&gt;
&lt;p&gt;Slow:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r 83877018ef97
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ PYTHONPATH=~/perf ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 29.4 ms +- 1.8 ms
&lt;/pre&gt;
&lt;p&gt;Use &lt;tt class="docutils literal"&gt;hg parents&lt;/tt&gt; to get the latest fast revision:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg parents -r 83877018ef97
changeset:   104528:ce85a1f129e3
(...)

changeset:   104530:2d352bf2b228
branch:      3.6
(...)
&lt;/pre&gt;
&lt;p&gt;Check the parent:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r ce85a1f129e3
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ PYTHONPATH=~/perf ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 17.1 ms +- 0.1 ms
&lt;/pre&gt;
&lt;p&gt;The revision ce85a1f129e3 is fast and the following revision 83877018ef97 is
slow. &lt;strong&gt;The revision 83877018ef97 introduced the slowdown&lt;/strong&gt;.  We found it!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="analysis-of-the-revision-introducing-the-slowdown"&gt;
&lt;h2&gt;Analysis of the revision introducing the slowdown&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://hg.python.org/cpython/rev/83877018ef97/"&gt;revision 83877018ef97&lt;/a&gt;
changes two files: Misc/NEWS and Python/traceback.c. The NEWS file is only
documentation and so must not impact performances.  Python/traceback.c is part
of the C code and so is more interesting.&lt;/p&gt;
&lt;p&gt;The commit only changes two C functions: &lt;tt class="docutils literal"&gt;PyTraceBack_Here()&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;_PyTraceback_Add()&lt;/tt&gt;, but &lt;tt class="docutils literal"&gt;perf report&lt;/tt&gt; didn't show these functions as &amp;quot;hot&amp;quot;.
In fact, these functions are never called by the benchmark.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The commit doesn't touch the C code used in the benchmark.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Unrelated C change impacting performances reminds me my previous &lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-deadcode.html"&gt;deadcode
horror story&lt;/a&gt;. The performance
difference is probably caused by &lt;strong&gt;&amp;quot;code placement&amp;quot;&lt;/strong&gt;: &lt;tt class="docutils literal"&gt;perf stat&lt;/tt&gt; showed a
significant increase of the cache miss rate on the L1 instruction cache.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="use-gcc-attribute-hot"&gt;
&lt;h2&gt;Use GCC __attribute__((hot))&lt;/h2&gt;
&lt;p&gt;Using PGO compilation was the solution for deadcode, but PGO doesn't work on
Ubuntu 14.04 (the OS used by the benchmark server, speed-python) and PGO seems
to make benchmarks less reliable.&lt;/p&gt;
&lt;p&gt;I wanted to try something else: mark hot functions using the GCC
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((hot))&lt;/span&gt;&lt;/tt&gt; attribute. PGO compilation does this automatically.&lt;/p&gt;
&lt;p&gt;This attribute only has an impact on the code placement: where functions are
loaded in memory. The flag declares functions in the &lt;tt class="docutils literal"&gt;.text.hot&lt;/tt&gt; ELF section
rather than the &lt;tt class="docutils literal"&gt;.text&lt;/tt&gt; ELF section. Grouping hot functions in the same
functions helps to reduce the distance between functions and so enhance the
usage of CPU caches.&lt;/p&gt;
&lt;p&gt;I wrote and then pushed a patch in the &lt;a class="reference external" href="http://bugs.python.org/issue28618"&gt;issue #28618&lt;/a&gt;: &amp;quot;Decorate hot functions using
__attribute__((hot)) to optimize Python&amp;quot;.&lt;/p&gt;
&lt;p&gt;The patch marks 6 functions as hot:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;_PyEval_EvalFrameDefault()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;call_function()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;_PyFunction_FastCall()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;PyFrame_New()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;frame_dealloc()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;PyErr_Occurred()&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's try the patch:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r 83877018ef97
$ wget https://hg.python.org/cpython/raw-rev/59b91b4e9506 -O patch
$ patch -p1 &amp;lt; patch
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ PYTHONPATH=~/perf ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 16.7 ms +- 0.3 ms
&lt;/pre&gt;
&lt;p&gt;It's easy to make mistakes and benchmarks are always suprising, so let's retry
without the patch:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ hg up -C -r 83877018ef97
$ ./configure --with-lto -C &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make
$ PYTHONPATH=~/perf ./python ~/performance/performance/benchmarks/bm_call_method.py --inherit-environ=PYTHONPATH --fast
call_method: Median +- std dev: 29.3 ms +- 0.6 ms
&lt;/pre&gt;
&lt;p&gt;The check confirms that the GCC attribute fixed the issue!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;On modern Intel CPUs, the code placement can have a major impact on the
performance of microbenchmarks.&lt;/p&gt;
&lt;p&gt;The GCC &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;__attribute__((hot))&lt;/span&gt;&lt;/tt&gt; attribute can be used manually to make &amp;quot;hot
functions&amp;quot; close in memory to enhance the usage of CPU caches.&lt;/p&gt;
&lt;p&gt;To know more about the impact of code placement, see the very good talk of Zia
Ansari (Intel) at the LLVM Developers' Meeting 2016: &lt;a class="reference external" href="https://llvmdevelopersmeetingbay2016.sched.org/event/8YzY/causes-of-performance-instability-due-to-code-placement-in-x86"&gt;Causes of Performance
Swings Due to Code Placement in IA&lt;/a&gt;.
He describes well &amp;quot;performance swings&amp;quot; like the one described in this article
and explains how CPUs work internally and how code placement impacts CPU
performances.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category></entry><entry><title>Intel CPUs (part 2): Turbo Boost, temperature, frequency and Pstate C0 bug</title><link href="https://haypo.github.io/intel-cpus-part2.html" rel="alternate"></link><published>2016-09-23T23:00:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-09-23:intel-cpus-part2.html</id><summary type="html">&lt;p&gt;My first article &lt;a class="reference external" href="https://haypo.github.io/intel-cpus.html"&gt;Intel CPUs&lt;/a&gt; is a general
introduction on modern CPU technologies having an impact on benchmarks.&lt;/p&gt;
&lt;p&gt;This second article is much more concrete with numbers and a concrete bug
having a major impact on benchmarks: a benchmark suddenly becomes 2x faster!&lt;/p&gt;
&lt;p&gt;I will tell you how I first noticed the bug, which tests I ran to analyze the
issue, how I found commands to reproduce the bug, and finally how I identified
the bug.&lt;/p&gt;
&lt;div class="section" id="glitch-in-benchmarks"&gt;
&lt;h2&gt;&amp;quot;Glitch&amp;quot; in benchmarks&lt;/h2&gt;
&lt;p&gt;Last week I ran a benchmark to check if enabling Profile Guided Optimization
(PGO) when compiling Python makes benchmark results less stable. I recompiled
Python 5 times, and after each compilation I ran a benchmark. I tested
different commands and options to compile Python. Everything was fine until
the last benchmark of the last compilation. &lt;strong&gt;The benchmark suddenly became 2
times faster.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Hopefully, my perf module collects a lot of metadata. I was able to analyze
in depth what happened.&lt;/p&gt;
&lt;p&gt;The &amp;quot;glitch&amp;quot; occurred in a benchmark having 400 runs (benchmark run in 400
different processes), between the run 105 (20.3 ms) and the run 106
(11.0 ms).&lt;/p&gt;
&lt;p&gt;I noticed that the CPU temperature was between 69C and 72C until the run 105,
and then decreased to from 69C to 58C.&lt;/p&gt;
&lt;p&gt;The system load slowly increased from 1.25 up to 1.62 around the run 108 and
then slowly decreased to 1.00.&lt;/p&gt;
&lt;p&gt;The system was not idle while the benchmark was running. I was working on the
PC too! But according to timestamps, it seems like the glitch was close to when
I stopped working. When I stopped working, I closed all applications (except of
the benchmark running in background) and turned of my two monitors.&lt;/p&gt;
&lt;p&gt;Well, at this point, it's hard to correlate for sure an event with the major
performance change.&lt;/p&gt;
&lt;p&gt;So I started to analyze different factors affecting CPUs and benchmarks: Turbo
Boost, CPU temperature and CPU frequency.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="impact-of-turbo-boost-on-benchmarks"&gt;
&lt;h2&gt;Impact of Turbo Boost on benchmarks&lt;/h2&gt;
&lt;p&gt;Without Turbo Boost, the maximum frequency of the &amp;quot;Intel(R) Core(TM) i7-3520M
CPU &amp;#64; 2.90GHz&amp;quot; of my laptop is 2.9 GHz. With Turbo Boost, the maximum
frequency is 3.6 GHz if only one core is active, or 3.4 GHz otherwise:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ sudo cpupower frequency-info
  ...
  boost state support:
    Supported: yes
    Active: yes
    3400 MHz max turbo 4 active cores
    3400 MHz max turbo 3 active cores
    3400 MHz max turbo 2 active cores
    3600 MHz max turbo 1 active cores
&lt;/pre&gt;
&lt;p&gt;I ran the bm_call_simple.py microbenchmark (CPU-bound) of performance 0.2.2.&lt;/p&gt;
&lt;p&gt;Turbo Boost disabled:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 physical CPU active: 2.9 GHz, Median +- std dev: 14.6 ms +- 0.3 ms&lt;/li&gt;
&lt;li&gt;2 physical CPU active: 2.9 GHz, Median +- std dev: 14.7 ms +- 0.5 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Turbo Boost enabled:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 physical CPU active: 3.6 GHz, Median +- std dev: 11.8 ms +- 0.3 ms&lt;/li&gt;
&lt;li&gt;2 physical CPU active: 3.4 GHz, Median +- std dev: 12.4 ms +- 0.1 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The maximum performance boost is 19% faster&lt;/strong&gt; (14.6 ms =&amp;gt; 11.8 ms), the
minimum boost if 15% faster (14.6 ms =&amp;gt; 12.4 ms).&lt;/p&gt;
&lt;p&gt;Hum, I don't think that Turbo Boost can explain the bug.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="impact-of-the-cpu-temperature-on-benchmarks"&gt;
&lt;h2&gt;Impact of the CPU temperature on benchmarks&lt;/h2&gt;
&lt;p&gt;The CPU temperature is mentionned in Intel Turbo Boost documentation as a
factor used to decide which P-state will be used. I always wanted to check how
the CPU temperature impacts its performance.&lt;/p&gt;
&lt;div class="section" id="burn-the-cpu-of-my-desktop-pc"&gt;
&lt;h3&gt;Burn the CPU of my desktop PC&lt;/h3&gt;
&lt;p&gt;CPU of my desktop PC: &amp;quot;Intel(R) Core(TM) i7-2600 CPU &amp;#64; 3.40GHz&amp;quot;.&lt;/p&gt;
&lt;p&gt;I used my &lt;a class="reference external" href="https://bitbucket.org/haypo/misc/src/tip/bin/system_load.py"&gt;system_load.py script&lt;/a&gt; to generate a
system load higher than 10.&lt;/p&gt;
&lt;p&gt;When the fan is cooling correctly the CPU, all CPU run at 3.4 GHz (Turbo Boost
was disabled) and the CPU temperature is 66C.&lt;/p&gt;
&lt;p&gt;I used a simple sheet of paper to block the fan of my CPU. Yeah, I really
wanted to &lt;a class="reference external" href="https://www.youtube.com/watch?v=Xf0VuRG7MN4"&gt;burn my CPU&lt;/a&gt;! More
seriously, I checked the CPU temperature every second using the &lt;tt class="docutils literal"&gt;sensors&lt;/tt&gt;
command and was prepared to unblock the fan if sometimes gone wrong.&lt;/p&gt;
&lt;img alt="Sheet of paper blocking the CPU fan" src="https://haypo.github.io/images/paper_blocks_cpu_fan.jpg" /&gt;
&lt;p&gt;After one minute, the CPU reached 97C. I expected a system crash, smoke or
something worse, but I was disappointed. &lt;strong&gt;At 97C, I was still able to use my
computer as everything was fine. The CPU was slowly down automatically to the
minimum CPU frequency: 1533 MHz&lt;/strong&gt; according to turbostat (the minimum frequency
of this CPU is 1.6 GHz).&lt;/p&gt;
&lt;p&gt;When I unblocked the fan, the temperature decreased quickly to go back to its
previous state (62C) and the CPU frequency quickly increased to 3.4 GHz as
well.&lt;/p&gt;
&lt;p&gt;My Intel CPU is really impressive! I didn't expect such very efficient
protection against overheating!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="burn-my-laptop-cpu"&gt;
&lt;h3&gt;Burn my laptop CPU&lt;/h3&gt;
&lt;p&gt;I used my system_load.py script to get a system load over 200. I also opened 4
tabs in Firefox playing Youtube videos to stress also the GPU which is
integrated into the CPU (IGP) on such laptop.&lt;/p&gt;
&lt;img alt="Stress test playing Youtube videos in Firefox, CPU at 102" src="https://haypo.github.io/images/burn_cpu_firefox.jpg" /&gt;
&lt;p&gt;With such crazy stress test, the CPU temperature was &amp;quot;only&amp;quot; 83C.&lt;/p&gt;
&lt;p&gt;Using a simple tissue, I closed the air hole used by the CPU fan. &lt;strong&gt;When the
CPU temperature increased from 100C to 101C, the CPU frequency started slowly
to decrease from 3391 MHz to 3077 MHz&lt;/strong&gt; (with steps between 10 MHz and 50 MHz
every second, or something like that).&lt;/p&gt;
&lt;p&gt;When pushing hard the tissue and waiting longer than 5 minutes, the CPU
temperature increased up to 102C, but the CPU frequency was only decreased
from 3.4 GHz (Turbo Mode with 4 active logical CPUs) to 3.1 GHz.&lt;/p&gt;
&lt;p&gt;The maximum frequency is 2.9 GHz. Frequencies higher than 2.9 GHz means that
the Turbo Mode was enabled! It means that &lt;strong&gt;even with overheating, the CPU is
still fine and able to &amp;quot;overclock&amp;quot; itself!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, I was disapointed. With a CPU at 102C, my laptop was still super fast
and reactive.  It seems like mobile CPUs handle even better overheating than
desktop CPUs (which is not something suprising at all).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="impact-of-the-cpu-frequency-on-benchmarks"&gt;
&lt;h2&gt;Impact of the CPU frequency on benchmarks&lt;/h2&gt;
&lt;p&gt;I ran the bm_call_simple.py microbenchmark (CPU-bound) of performance 0.2.2
on my desktop PC.&lt;/p&gt;
&lt;p&gt;Command to set the frequency of CPU 0 to the minimum frequency (1.6 GHz):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_min_freq|sudo tee  /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq
1600000
&lt;/pre&gt;
&lt;p&gt;Command to set the frequency of CPU 0 to the maximum frequency (3.4 GHz):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_max_freq|sudo tee  /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq
3400000
&lt;/pre&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;CPU running at 1.6 GHz (min freq): Median +- std dev: 27.7 ms +- 0.7 ms&lt;/li&gt;
&lt;li&gt;CPU running at 3.4 GHz (min freq): Median +- std dev: 12.9 ms +- 0.2 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The impact of the CPU frequency is quite obvious: &lt;strong&gt;when the CPU frequency is
doubled, the performance is also doubled&lt;/strong&gt;. The benchmark is 53% faster (27.7
ms =&amp;gt; 12.9 ms).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bug-reproduced-and-then-identified-in-the-linux-cpu-driver"&gt;
&lt;h2&gt;Bug reproduced and then identified in the Linux CPU driver&lt;/h2&gt;
&lt;p&gt;Two days ago, I ran a very simple &amp;quot;timeit&amp;quot; microbenchmark to try to bisect a
performance regression in Python 3.6 on &lt;tt class="docutils literal"&gt;functools.partial&lt;/tt&gt;. Again, suddenly,
the microbenchmark became 2x faster!&lt;/p&gt;
&lt;p&gt;But this time, I found something: I noticed that running or stopping &lt;tt class="docutils literal"&gt;cpupower
monitor&lt;/tt&gt; and/or &lt;tt class="docutils literal"&gt;turbostat&lt;/tt&gt; can &amp;quot;enable&amp;quot; or &amp;quot;disable&amp;quot; the bug.&lt;/p&gt;
&lt;p&gt;After a lot of tests, I understood that running the benchmark with turbostat
&amp;quot;disables&amp;quot; the bug, whereas running &amp;quot;cpupower monitor&amp;quot; while running a
benchmark enables the bug.&lt;/p&gt;
&lt;p&gt;I reported the bug in the Fedora bug tracker, on the component kernel:
&lt;a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1378529"&gt;intel_pstate C0 bug on isolated CPUs with the performance governor and
NOHZ_FULL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It seems like the bug is related to CPU isolation and NOHZ_FULL. The NOHZ_FULL
option is able to fully disable the scheduler clock interruption  on isolated
CPUs. I understood the the &lt;tt class="docutils literal"&gt;intel_pstate&lt;/tt&gt; driver uses a callback on the
scheduler to update the Pstate of the CPU. According to an Intel engineer, the
&lt;tt class="docutils literal"&gt;intel_pstate&lt;/tt&gt; driver was never tested with CPU isolation.&lt;/p&gt;
&lt;p&gt;The issue is not fully analyzed yet, but at least I succeeded to write a list
of commands to reproduce it with a success rate of 100% :-) Moreover, the Intel
engineer suggested to add an extra parameter to the Linux kernel command
(&lt;tt class="docutils literal"&gt;rcu_nocbs=3,7&lt;/tt&gt;) line which works around the issue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This article describes how I found and then identified a bug in the Linux
driver of my CPU.&lt;/p&gt;
&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The maximum speedup of Turbo Boost is 20%&lt;/li&gt;
&lt;li&gt;Overheating on a dekstop PC can decrease the CPU frequency to its minimum
(half of the maximum in my case) which imply a slowdown of 50%&lt;/li&gt;
&lt;li&gt;A bug in the Linux CPU driver changes suddenly the CPU frequency from its
minimum to maximum (or the opposite) which means a speedup of 50%
(or slowdown of 50%)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;To get stable benchmarks, the safest fix for all these issues is probably to
set the CPU frequency of the CPUs used by benchmarks to the minimum.&lt;/strong&gt;
It seems like nothing can reduce the frequency of a CPU below its minimum.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When running benchmarks, raw timings and CPU performance don't matter. Only
comparisons between benchmark results and stable performances matter.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category><category term="cpu"></category></entry><entry><title>Intel CPUs: P-state, C-state, Turbo Boost, CPU frequency, etc.</title><link href="https://haypo.github.io/intel-cpus.html" rel="alternate"></link><published>2016-07-15T12:00:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-07-15:intel-cpus.html</id><summary type="html">&lt;p&gt;Ten years ago, most computers were desktop computers designed for best
performances and their CPU frequency was fixed. Nowadays, most devices are
embedded and use &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Low-power_electronics"&gt;low power consumption&lt;/a&gt; processors like ARM
CPUs. The power consumption now matters more than performance peaks.&lt;/p&gt;
&lt;p&gt;Intel CPUs evolved from a single core to multiple physical cores in the same
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/CPU_socket"&gt;package&lt;/a&gt; and got new features:
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Hyper-threading"&gt;Hyper-threading&lt;/a&gt; to run two
threads on the same physical core and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_Turbo_Boost"&gt;Turbo Boost&lt;/a&gt; to maximum performances.
CPU cores can be completely turned off (CPU HALT, frequency of 0) temporarily to
reduce the power consumption, and the frequency of cores changes regulary
depending on many factors like the workload and temperature. The power
consumption is now an important part in the design of modern CPUs.&lt;/p&gt;
&lt;p&gt;Warning! This article is a summary of what I learnt last weeks from random
articles. It may be full of mistakes, don't hesitate to report them, so I can
enhance the article! It's hard to find simple articles explaining performances
of modern Intel CPUs, so I tried to write mine.&lt;/p&gt;
&lt;div class="section" id="tools-used-in-this-article"&gt;
&lt;h2&gt;Tools used in this article&lt;/h2&gt;
&lt;p&gt;This article mentions various tools. Commands to install them on Fedora 24:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;dnf install &lt;span class="pre"&gt;-y&lt;/span&gt; &lt;span class="pre"&gt;util-linux&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;lscpu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;dnf install &lt;span class="pre"&gt;-y&lt;/span&gt; &lt;span class="pre"&gt;kernel-tools&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://linux.die.net/man/1/cpupower"&gt;cpupower&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;turbostat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;sudo dnf install &lt;span class="pre"&gt;-y&lt;/span&gt; &lt;span class="pre"&gt;msr-tools&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;rdmsr&lt;/li&gt;
&lt;li&gt;wrmsr&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other interesting tools, not used in this article: i7z (sadly no more
maintained), lshw, dmidecode, sensors.&lt;/p&gt;
&lt;p&gt;The sensors tool is supposed to report the current CPU voltage, but it doesn't
provide this information on my computers. At least, it gives the temperature of
different components, but also the speed of fans.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="example-of-intel-cpus"&gt;
&lt;h2&gt;Example of Intel CPUs&lt;/h2&gt;
&lt;div class="section" id="my-laptop-cpu-proc-cpuinfo"&gt;
&lt;h3&gt;My laptop CPU: /proc/cpuinfo&lt;/h3&gt;
&lt;p&gt;On Linux, the most common way to retrieve information on the CPU is to read
&lt;tt class="docutils literal"&gt;/proc/cpuinfo&lt;/tt&gt;. Example on my laptop:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ cat /proc/cpuinfo
processor  : 0
vendor_id  : GenuineIntel
model name : Intel(R) Core(TM) i7-3520M CPU &amp;#64; 2.90GHz
cpu MHz    : 1200.214
...

processor  : 1
vendor_id  : GenuineIntel
model name : Intel(R) Core(TM) i7-3520M CPU &amp;#64; 2.90GHz
cpu MHz    : 3299.882
...
&lt;/pre&gt;
&lt;p&gt;&amp;quot;i7-3520M&amp;quot; CPU is a model designed for Mobile Platforms (see the &amp;quot;M&amp;quot; suffix).
It was built in 2012 and is the third generation of the Intel i7
microarchitecture: &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ivy_Bridge_(microarchitecture)"&gt;Ivy Bridge&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The CPU has two physical cores, I disabled HyperThreading in the BIOS.&lt;/p&gt;
&lt;p&gt;The first strange thing is that the CPU announces &amp;quot;2.90 GHz&amp;quot; but Linux reports
1.2 GHz on the first core, and 3.3 GHz on the second core. 3.3 GHz is greater
than 2.9 GHz!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="my-desktop-cpu-cpu-topology-with-lscpu"&gt;
&lt;h3&gt;My desktop CPU: CPU topology with lscpu&lt;/h3&gt;
&lt;p&gt;cpuinfo:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
smithers$ cat /proc/cpuinfo
processor   : 0
physical id : 0
core id     : 0
...
model name  : Intel(R) Core(TM) i7-2600 CPU &amp;#64; 3.40GHz
cpu cores   : 4
...

processor   : 1
physical id : 0
core id     : 1
...

(...)

processor   : 7
physical id : 0
core id     : 3
...
&lt;/pre&gt;
&lt;p&gt;The CPU i7-2600 is the 2nd generation: &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Sandy_Bridge"&gt;Sandy Bridge microarchitecture&lt;/a&gt;. There are 8 logical cores and 4
physical cores (so with Hyper-threading).&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;lscpu&lt;/tt&gt; renders a short table which helps to understand the CPU topology:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
smithers$ lscpu -a -e
CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
0   0    0      0    0:0:0:0       yes    3800.0000 1600.0000
1   0    0      1    1:1:1:0       yes    3800.0000 1600.0000
2   0    0      2    2:2:2:0       yes    3800.0000 1600.0000
3   0    0      3    3:3:3:0       yes    3800.0000 1600.0000
4   0    0      0    0:0:0:0       yes    3800.0000 1600.0000
5   0    0      1    1:1:1:0       yes    3800.0000 1600.0000
6   0    0      2    2:2:2:0       yes    3800.0000 1600.0000
7   0    0      3    3:3:3:0       yes    3800.0000 1600.0000
&lt;/pre&gt;
&lt;p&gt;There are 8 logical CPUs (&lt;tt class="docutils literal"&gt;CPU &lt;span class="pre"&gt;0..7&lt;/span&gt;&lt;/tt&gt;), all on the same node (&lt;tt class="docutils literal"&gt;NODE 0&lt;/tt&gt;) and
the same socket (&lt;tt class="docutils literal"&gt;SOCKET 0&lt;/tt&gt;).  There are only 4 physical cores (&lt;tt class="docutils literal"&gt;CORE
&lt;span class="pre"&gt;0..3&lt;/span&gt;&lt;/tt&gt;). For example, the physical core &lt;tt class="docutils literal"&gt;2&lt;/tt&gt; is made of the two logical CPUs:
&lt;tt class="docutils literal"&gt;2&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;6&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Using the &lt;tt class="docutils literal"&gt;L1d:L1i:L2:L3&lt;/tt&gt; column, we can see that each pair of two logical
cores share the same physical core caches for levels 1 (L1 data, L1
instruction) and 2 (L2).  All physical cores share the same cache level 3 (L3).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="p-states"&gt;
&lt;h2&gt;P-states&lt;/h2&gt;
&lt;p&gt;A new CPU driver &lt;tt class="docutils literal"&gt;intel_pstate&lt;/tt&gt; was added to the Linux kernel 3.9 (April
2009). First, it only supported SandyBridge CPUs (2nd generation), Linux 3.10
extended it to Ivybridge generation CPUs (3rd gen), and so on and so forth.&lt;/p&gt;
&lt;p&gt;This driver supports recent features and thermal control of modern Intel CPUs.
Its name comes from P-states.&lt;/p&gt;
&lt;p&gt;The processor P-state is the capability of running the processor at different
voltage and/or frequency levels. Generally, P0 is the highest state resulting
in maximum performance, while P1, P2, and so on, will save power but at some
penalty to CPU performance.&lt;/p&gt;
&lt;p&gt;It is possible to force the legacy CPU driver (&lt;tt class="docutils literal"&gt;acpi_cpufreq&lt;/tt&gt;) using
&lt;tt class="docutils literal"&gt;intel_pstate=disable&lt;/tt&gt; option in the kernel command line.&lt;/p&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/cpu-freq/intel-pstate.txt"&gt;Documentation of the intel-pstate driver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://plus.google.com/+ArjanvandeVen/posts/dLn9T4ehywL"&gt;Some basics on CPU P states on Intel processors&lt;/a&gt; (2013) by Arjan
van de Ven (Intel)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://events.linuxfoundation.org/sites/events/files/slides/LinuxConEurope_2015.pdf"&gt;Balancing Power and Performance in the Linux Kernel&lt;/a&gt;
talk at LinuxCon Europe 2015 by Kristen Accardi (Intel)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://software.intel.com/en-us/blogs/2008/05/29/what-exactly-is-a-p-state-pt-1"&gt;What exactly is a P-state? (Pt. 1)&lt;/a&gt;
(2008) by Taylor K. (Intel)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="idle-states-c-states"&gt;
&lt;h2&gt;Idle states: C-states&lt;/h2&gt;
&lt;p&gt;C-states are idle power saving states, in contrast to P-states, which are
execution power saving states.&lt;/p&gt;
&lt;p&gt;During a P-state, the processor is still executing instructions, whereas during
a C-state (other than C0), the processor is idle, meaning that nothing is
executing.&lt;/p&gt;
&lt;p&gt;C-states:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;C0 is the operational state, meaning that the CPU is doing useful work&lt;/li&gt;
&lt;li&gt;C1 is the first idle state&lt;/li&gt;
&lt;li&gt;C2 is the second idle state: The external I/O Controller Hub blocks
interrupts to the processor.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When a logical processor is idle (C-state except of C0), its frequency is
typically 0 (HALT).&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;cpupower &lt;span class="pre"&gt;idle-info&lt;/span&gt;&lt;/tt&gt; command lists supported C-states:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ cpupower idle-info
CPUidle driver: intel_idle
CPUidle governor: menu
analyzing CPU 0:

Number of idle states: 6
Available idle states: POLL C1-IVB C1E-IVB C3-IVB C6-IVB C7-IVB
...
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;cpupower monitor&lt;/tt&gt; shows statistics on C-states:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
smithers$ sudo cpupower monitor -m Idle_Stats
    |Idle_Stats
CPU | POLL | C1-S | C1E- | C3-S | C6-S
   0|  0,00|  0,19|  0,09|  0,58| 96,23
   4|  0,00|  0,00|  0,00|  0,00| 99,90
   1|  0,00|  2,34|  0,00|  0,00| 97,63
   5|  0,00|  0,00|  0,17|  0,00| 98,02
   2|  0,00|  0,00|  0,00|  0,00|  0,00
   6|  0,00|  0,00|  0,00|  0,00|  0,00
   3|  0,00|  0,00|  0,00|  0,00|  0,00
   7|  0,00|  0,00|  0,00|  0,00| 49,97
&lt;/pre&gt;
&lt;p&gt;See also: &lt;a class="reference external" href="https://software.intel.com/en-us/articles/power-management-states-p-states-c-states-and-package-c-states"&gt;Power Management States: P-States, C-States, and Package C-States&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;Turbo Boost&lt;/h2&gt;
&lt;p&gt;In 2005, Intel introduced &lt;a class="reference external" href="https://en.wikipedia.org/wiki/SpeedStep"&gt;SpeedStep&lt;/a&gt;, a serie of dynamic frequency
scaling technologies to reduce the power consumption of laptop CPUs. Turbo
Boost is an enhancement of these technologies, now also used on desktop and
server CPUs.&lt;/p&gt;
&lt;p&gt;Turbo Boost allows to run one or many CPU cores to higher P-states than usual.
The maximum P-state is constrained by the following factors:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The number of active cores (in C0 or C1 state)&lt;/li&gt;
&lt;li&gt;The estimated current consumption of the processor (Imax)&lt;/li&gt;
&lt;li&gt;The estimated power consumption (TDP - Thermal Design Power) of processor&lt;/li&gt;
&lt;li&gt;The temperature of the processor&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on my laptop:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ cat /proc/cpuinfo
model name : Intel(R) Core(TM) i7-3520M CPU &amp;#64; 2.90GHz
...

selma$ sudo cpupower frequency-info
analyzing CPU 0:
  driver: intel_pstate
  ...
  boost state support:
    Supported: yes
    Active: yes
    3400 MHz max turbo 4 active cores
    3400 MHz max turbo 3 active cores
    3400 MHz max turbo 2 active cores
    3600 MHz max turbo 1 active cores
&lt;/pre&gt;
&lt;p&gt;The CPU base frequency is 2.9 GHz. If more than one physical cores is &amp;quot;active&amp;quot;
(busy), their frequency can be increased up to 3.4 GHz. If only 1 physical core
is active, its frequency can be increased up to 3.6 GHz.&lt;/p&gt;
&lt;p&gt;In this example, Turbo Boost is supported and active.&lt;/p&gt;
&lt;p&gt;See also the &lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/cpu-freq/boost.txt"&gt;Linux cpu-freq documentation on CPU boost&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="turbo-boost-msr"&gt;
&lt;h3&gt;Turbo Boost MSR&lt;/h3&gt;
&lt;p&gt;The bit 38 of the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Model-specific_register"&gt;Model-specific register
(MSR)&lt;/a&gt; &lt;tt class="docutils literal"&gt;0x1a0&lt;/tt&gt; can
be used to check if the Turbo Boost is enabled:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ sudo rdmsr -f 38:38 0x1a0
0
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;0&lt;/tt&gt; means that Turbo Boost is enabled, whereas &lt;tt class="docutils literal"&gt;1&lt;/tt&gt; means disabled (no
turbo). (The &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-f&lt;/span&gt; 38:38&lt;/tt&gt; option asks to only display the bit 38.)&lt;/p&gt;
&lt;p&gt;If the command doesn't work, you may have to load the &lt;tt class="docutils literal"&gt;msr&lt;/tt&gt; kernel module:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo modprobe msr
&lt;/pre&gt;
&lt;p&gt;Note: I'm not sure that all Intel CPU uses the same MSR.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="intel-state-no-turbo"&gt;
&lt;h3&gt;intel_state/no_turbo&lt;/h3&gt;
&lt;p&gt;Turbo Boost can also be disabled at runtime in the &lt;tt class="docutils literal"&gt;intel_pstate&lt;/tt&gt; driver.&lt;/p&gt;
&lt;p&gt;Check if Turbo Boost is enabled:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ cat /sys/devices/system/cpu/intel_pstate/no_turbo
0
&lt;/pre&gt;
&lt;p&gt;where &lt;tt class="docutils literal"&gt;0&lt;/tt&gt; means that Turbo Boost is enabled. Disable Turbo Boost:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ echo 1|sudo tee /sys/devices/system/cpu/intel_pstate/no_turbo
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="cpu-flag-ida"&gt;
&lt;h3&gt;CPU flag &amp;quot;ida&amp;quot;&lt;/h3&gt;
&lt;p&gt;It looks like the Turbo Boost status (supported or not) can also be read by the
CPUID(6): &amp;quot;Thermal/Power Management&amp;quot;. It gives access to the flag &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_Dynamic_Acceleration"&gt;Intel
Dynamic Acceleration (IDA)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;ida&lt;/tt&gt; flag can also be seen in CPU flags of &lt;tt class="docutils literal"&gt;/proc/cpuinfo&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="read-the-cpu-frequency"&gt;
&lt;h2&gt;Read the CPU frequency&lt;/h2&gt;
&lt;p&gt;General information using &lt;tt class="docutils literal"&gt;cpupower &lt;span class="pre"&gt;frequency-info&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ cpupower -c 0 frequency-info
analyzing CPU 0:
  driver: intel_pstate
  ...
  hardware limits: 1.20 GHz - 3.60 GHz
  ...
&lt;/pre&gt;
&lt;p&gt;The frequency of CPUs is between 1.2 GHz and 3.6 GHz (the base frequency is
2.9 GHz on this CPU).&lt;/p&gt;
&lt;div class="section" id="get-the-frequency-of-cpus-turbostat"&gt;
&lt;h3&gt;Get the frequency of CPUs: turbostat&lt;/h3&gt;
&lt;p&gt;It looks like the most reliable way to get a relialistic estimation of the CPUs
frequency is to use the tool &lt;tt class="docutils literal"&gt;turbostat&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ sudo turbostat
     CPU Avg_MHz   Busy% Bzy_MHz TSC_MHz
       -     224    7.80    2878    2893
       0     448   15.59    2878    2893
       1       0    0.01    2762    2893
     CPU Avg_MHz   Busy% Bzy_MHz TSC_MHz
       -     139    5.65    2469    2893
       0     278   11.29    2469    2893
       1       0    0.01    2686    2893
    ...
&lt;/pre&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;Avg_MHz&lt;/tt&gt;: average frequency, based on APERF&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;Busy%&lt;/tt&gt;: CPU usage in percent&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;Bzy_MHz&lt;/tt&gt;: busy frequency, based on MPERF&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;TSC_MHz&lt;/tt&gt;: fixed frequency, TSC stands for &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Time_Stamp_Counter"&gt;Time Stamp Counter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;APERF (average) and MPERF (maximum) are MSR registers that can provide feedback
on current CPU frequency.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="other-tools-to-get-the-cpu-frequency"&gt;
&lt;h3&gt;Other tools to get the CPU frequency&lt;/h3&gt;
&lt;p&gt;It looks like the following tools are less reliable to estimate the CPU
frequency.&lt;/p&gt;
&lt;p&gt;cpuinfo:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ grep MHz /proc/cpuinfo
cpu MHz : 1372.289
cpu MHz : 3401.042
&lt;/pre&gt;
&lt;p&gt;In April 2016, Len Brown proposed a patch modifying cpuinfo to use APERF and
MPERF MSR to estimate the CPU frequency: &lt;a class="reference external" href="https://lkml.org/lkml/2016/4/1/7"&gt;x86: Calculate MHz using APERF/MPERF
for cpuinfo and scaling_cur_freq&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;tsc&lt;/tt&gt; clock source logs the CPU frequency in kernel logs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ dmesg|grep 'MHz processor'
[    0.000000] tsc: Detected 2893.331 MHz processor
&lt;/pre&gt;
&lt;p&gt;cpupower frequency-info:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ for core in $(seq 0 1); do sudo cpupower -c $core frequency-info|grep 'current CPU'; done
  current CPU frequency: 3.48 GHz (asserted by call to hardware)
  current CPU frequency: 3.40 GHz (asserted by call to hardware)
&lt;/pre&gt;
&lt;p&gt;cpupower monitor:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
selma$ sudo cpupower monitor -m 'Mperf'
    |Mperf
CPU | C0   | Cx   | Freq
   0|  4.77| 95.23|  1924
   1|  0.01| 99.99|  1751
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Modern Intel CPUs use various technologies to provide best performances without
killing the power consumption. It became harder to monitor and understand CPU
performances, than with older CPUs, since the performance now depends on much
more factors.&lt;/p&gt;
&lt;p&gt;It also becomes common to get an integrated graphics processor (IGP) in the
same package, which makes the exact performance even more complex to predict,
since the IGP produces heat and so has an impact on the CPU P-state.&lt;/p&gt;
&lt;p&gt;I should also explain that P-state are &amp;quot;voted&amp;quot; between CPU cores, but I didn't
understand this part. I'm not sure that understanding the exact algorithm
matters much. I tried to not give too much information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="annex-amt-and-the-me-power-management-coprocessor"&gt;
&lt;h2&gt;Annex: AMT and the ME (power management coprocessor)&lt;/h2&gt;
&lt;p&gt;Computers with Intel vPro technology includes &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_Active_Management_Technology"&gt;Intel Active Management
Technology (AMT)&lt;/a&gt;: &amp;quot;hardware
and firmware technology for remote out-of-band management of personal
computers&amp;quot;. AMT has many features which includes power management.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_Active_Management_Technology#Hardware"&gt;Management Engine (ME)&lt;/a&gt;
is the hardware part: an isolated and protected coprocessor, embedded as a
non-optional part in all current (as of 2015) Intel chipsets. The coprocessor
is a special 32-bit ARC microprocessor (RISC architecture) that's physically
located inside the PCH chipset (or MCH on older chipsets). The coprocessor can
for example be found on Intel MCH chipsets Q35 and Q45.&lt;/p&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://boingboing.net/2016/06/15/intel-x86-processors-ship-with.html"&gt;Intel x86s hide another CPU that can take over your machine (you can't
audit it)&lt;/a&gt; for
more information on the coprocessor.&lt;/p&gt;
&lt;p&gt;More recently, the Intel Xeon Phi CPU (2016) also includes a coprocessor for
power management. I didn't understand if it is the same coprocessor or not.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category><category term="cpu"></category></entry><entry><title>Visualize the system noise using perf and CPU isolation</title><link href="https://haypo.github.io/perf-visualize-system-noise-with-cpu-isolation.html" rel="alternate"></link><published>2016-06-16T13:30:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-06-16:perf-visualize-system-noise-with-cpu-isolation.html</id><summary type="html">&lt;p&gt;I developed a new &lt;a class="reference external" href="http://perf.readthedocs.io/"&gt;perf module&lt;/a&gt; designed to run
stable benchmarks, give fine control on benchmark parameters and compute
statistics on results. With such tool, it becomes simple to &lt;em&gt;visualize&lt;/em&gt;
sources of noise. The CPU isolation will be used to visualize the system noise.
Running a benchmark on isolated CPUs isolates it from the system noise.&lt;/p&gt;
&lt;div class="section" id="isolate-cpus"&gt;
&lt;h2&gt;Isolate CPUs&lt;/h2&gt;
&lt;p&gt;My computer has 4 physical CPU cores. I isolated half of them using
&lt;tt class="docutils literal"&gt;isolcpus=2,3&lt;/tt&gt; parameter of the Linux kernel. I modified manually the command
line in GRUB to add this parameter.&lt;/p&gt;
&lt;p&gt;Check that CPUs are isolated:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat /sys/devices/system/cpu/isolated
2-3
&lt;/pre&gt;
&lt;p&gt;The CPU supports HyperThreading, but I disabled it in the BIOS.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="run-a-benchmark"&gt;
&lt;h2&gt;Run a benchmark&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;perf&lt;/tt&gt; module automatically detects and uses isolated CPU cores. I will
use the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--affinity=0,1&lt;/span&gt;&lt;/tt&gt; option to force running the benchmark on the CPUs
which are not isolated.&lt;/p&gt;
&lt;p&gt;Microbenchmark with and without CPU isolation:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m perf.timeit --json-file=timeit_isolcpus.json --verbose -s 'x=1; y=2' 'x+y'
Pin process to isolated CPUs: 2-3
.........................
Median +- std dev: 36.6 ns +- 0.1 ns (25 runs x 3 samples x 10^7 loops; 1 warmup)

$ python3 -m perf.timeit --affinity=0,1 --json-file=timeit_no_isolcpus.json --verbose -s 'x=1; y=2' 'x+y'
Pin process to CPUs: 0-1
.........................
Median +- std dev: 36.7 ns +- 1.3 ns (25 runs x 3 samples x 10^7 loops; 1 warmup)
&lt;/pre&gt;
&lt;p&gt;My computer was not 100% idle, I was using it while the benchmarks were
running.&lt;/p&gt;
&lt;p&gt;The median is almost the same (36.6 ns and 36.7 ns). The first major difference
is the standard deviation: it is much larger without CPU isolation: 0.1 ns =&amp;gt;
1.3 ns (13x larger).&lt;/p&gt;
&lt;p&gt;Just in case, check manually CPU affinity in metadata:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m perf show timeit_isolcpus.json --metadata | grep cpu
- cpu_affinity: 2-3 (isolated)
- cpu_count: 4
- cpu_model_name: Intel(R) Core(TM) i7-2600 CPU &amp;#64; 3.40GHz

$ python3 -m perf show timeit_no_isolcpus.json --metadata | grep cpu_affinity
- cpu_affinity: 0-1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="statistics"&gt;
&lt;h2&gt;Statistics&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;perf stats&lt;/tt&gt; command computes statistics on the distribution of samples:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m perf stats timeit_isolcpus.json
Number of samples: 75

Minimum: 36.5 ns (-0.1%)
Median +- std dev: 36.6 ns +- 0.1 ns (36.5 ns .. 36.7 ns)
Maximum: 36.7 ns (+0.4%)

$ python3 -m perf stats timeit_no_isolcpus.json
Number of samples: 75

Minimum: 36.5 ns (-0.5%)
Median +- std dev: 36.7 ns +- 1.3 ns (35.4 ns .. 38.0 ns)
Maximum: 43.0 ns (+17.0%)
&lt;/pre&gt;
&lt;p&gt;The minimum is the same. The second major difference is the maximum: it is much
larger without CPU isolation: 36.7 ns (+0.4%) =&amp;gt; 43.0 ns (+17.0%).&lt;/p&gt;
&lt;p&gt;The difference between the maximum and the median is 63x larger without CPU
isolation: 0.1 ns (&lt;tt class="docutils literal"&gt;36.7 - 36.6&lt;/tt&gt;) =&amp;gt; 6.3 ns (&lt;tt class="docutils literal"&gt;43.0 - 36.7&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;Depending on the system load, a single sample of the microbenchmark is up to
17% slower (maximum of 43.0 ns with a median of 36.7 ns) without CPU isolation.
The difference is smaller with CPU isolation: only 0.4% slower (for the
maximum, and 0.1% faster for the minimum).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="histogram"&gt;
&lt;h2&gt;Histogram&lt;/h2&gt;
&lt;p&gt;Another way to analyze the distribution of samples is to render an histogram:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m perf hist --bins=8 timeit_isolcpus.json timeit_no_isolcpus.json
[ timeit_isolcpus ]
36.1 ns: 75 ################################################
36.9 ns:  0 |
37.7 ns:  0 |
38.5 ns:  0 |
39.3 ns:  0 |
40.1 ns:  0 |
40.9 ns:  0 |
41.7 ns:  0 |
42.5 ns:  0 |

[ timeit_no_isolcpus ]
36.1 ns: 52 ################################################
36.9 ns: 13 ############
37.7 ns:  1 #
38.5 ns:  4 ####
39.3 ns:  2 ##
40.1 ns:  0 |
40.9 ns:  1 #
41.7 ns:  0 |
42.5 ns:  2 ##
&lt;/pre&gt;
&lt;p&gt;I choose the number of bars to get a small histogram and to get all samples of
the first benchmark on the same bar. With 8 bars, each bar is a range of 0.8
ns.&lt;/p&gt;
&lt;p&gt;The last major difference is the shape of these histogram. Without CPU
isolation, there is a &amp;quot;long tail&amp;quot; at the right of the median: &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Outlier"&gt;outliers&lt;/a&gt; in the range [37.7 ns; 42.5 ns].
The outliers come from the &amp;quot;noise&amp;quot; caused by the multitasking system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;perf&lt;/tt&gt; module provides multiple tools to analyze the distribution of
benchmark samples. Three tools show a major difference without CPU isolation
compared to results with CPU isolation:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Standard deviation: 13x larger without isolation&lt;/li&gt;
&lt;li&gt;Maximum: difference to median 63x larger without isolation&lt;/li&gt;
&lt;li&gt;Shape of the histogram: long tail at the right of the median&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It explains why CPU isolation helps to make benchmarks more stable.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="benchmark"></category></entry><entry><title>My journey to stable benchmark, part 3 (average)</title><link href="https://haypo.github.io/journey-to-stable-benchmark-average.html" rel="alternate"></link><published>2016-05-23T23:00:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-05-23:journey-to-stable-benchmark-average.html</id><summary type="html">&lt;a class="reference external image-reference" href="https://www.flickr.com/photos/stanzim/11100202065/"&gt;&lt;img alt="Fog" src="https://haypo.github.io/images/fog.jpg" /&gt;&lt;/a&gt;
&lt;p&gt;&lt;em&gt;Stable benchmarks are so close, but ...&lt;/em&gt;&lt;/p&gt;
&lt;div class="section" id="address-space-layout-randomization"&gt;
&lt;h2&gt;Address Space Layout Randomization&lt;/h2&gt;
&lt;p&gt;When I started to work on removing the noise of the system, I was told that
disabling &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Address_space_layout_randomization"&gt;Address Space Layout Randomization (ASLR)&lt;/a&gt; makes
benchmarks more stable.&lt;/p&gt;
&lt;p&gt;I followed this advice without trying to understand it. We will see in this
article that it was a bad idea, but I had to hit other issues to really
understand the root issue with disabling ASLR.&lt;/p&gt;
&lt;p&gt;Example of command to see the effect of ASLR, the first number of the output is
the start address of the heap memory:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python -c 'import os; os.system(&amp;quot;grep heap /proc/%s/maps&amp;quot; % os.getpid())'
55e6a716c000-55e6a7235000 rw-p 00000000 00:00 0                          [heap]
&lt;/pre&gt;
&lt;p&gt;Heap address of 3 runs with ASLR enabled (random):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;55e6a716c000&lt;/li&gt;
&lt;li&gt;561c218eb000&lt;/li&gt;
&lt;li&gt;55e6f628f000&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disable ASLR:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo bash -c 'echo 0 &amp;gt;| /proc/sys/kernel/randomize_va_space'
&lt;/pre&gt;
&lt;p&gt;Heap addresses of 3 runs with ASLR disabled (all the same):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;555555756000&lt;/li&gt;
&lt;li&gt;555555756000&lt;/li&gt;
&lt;li&gt;555555756000&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: To reenable ASLR, it's better to use the value 2, the value 1 only
partially enables the feature:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo bash -c 'echo 2 &amp;gt;| /proc/sys/kernel/randomize_va_space'
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="python-randomized-hash-function"&gt;
&lt;h2&gt;Python randomized hash function&lt;/h2&gt;
&lt;p&gt;With &lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-system.html"&gt;system tuning  (part 1)&lt;/a&gt;, a
&lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-deadcode.html"&gt;Python compiled with PGO (part 2)&lt;/a&gt;
and ASLR disabled, I still I failed to get the same result when running
manually &lt;tt class="docutils literal"&gt;bm_call_simple.py&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;On Python 3, the hash function is now randomized by default: &lt;a class="reference external" href="http://bugs.python.org/issue13703"&gt;issue #13703&lt;/a&gt;. The problem is that for a
microbenchmark, the number of hash collisions of an &amp;quot;hot&amp;quot; dictionary has a
non-negligible impact on performances.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;PYTHONHASHSEED&lt;/tt&gt; environment variable can be used to get a fixed hash
function. Example with the patch:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ PYTHONHASHSEED=1 taskset -c 1 ./python bm_call_simple.py -n 1
0.198
$ PYTHONHASHSEED=2 taskset -c 1 ./python bm_call_simple.py -n 1
0.201
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1
0.207
$ PYTHONHASHSEED=4 taskset -c 1 ./python bm_call_simple.py -n 1
0.187
$ PYTHONHASHSEED=5 taskset -c 1 ./python bm_call_simple.py -n 1
0.180
&lt;/pre&gt;
&lt;p&gt;Timings of the reference python:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ PYTHONHASHSEED=1 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.204
$ PYTHONHASHSEED=2 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.206
$ PYTHONHASHSEED=3 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.195
$ PYTHONHASHSEED=4 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.192
$ PYTHONHASHSEED=5 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.187
&lt;/pre&gt;
&lt;p&gt;The minimums is 180 ms for the reference and 186 ms for the patch. The patched
Python is 3% faster, yeah!&lt;/p&gt;
&lt;p&gt;Wait. What if we only test PYTHONHASHSEED from 1 to 3? In this case, the
minimum is 195 ms for the reference and 198 ms for the patch. The patched
Python becomes 2% slower, oh no!&lt;/p&gt;
&lt;p&gt;Faster? Slower? Who is right?&lt;/p&gt;
&lt;p&gt;Maybe I should write a script to find a &lt;tt class="docutils literal"&gt;PYTHONHASHSEED&lt;/tt&gt; value for which my
patch is always faster :-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="command-line-and-environment-variables"&gt;
&lt;h2&gt;Command line and environment variables&lt;/h2&gt;
&lt;p&gt;Well, let's say that we will use a fixed PYTHONHASHSEED value. Anyway, my
patch doesn't touch the hash function. So it doesn't matter.&lt;/p&gt;
&lt;p&gt;While running benchmarks, I noticed differences when running the benchmark from
a different directory:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cd /home/haypo/prog/python/fastcall
$ PYTHONHASHSEED=3 taskset -c 1 pgo/python ../benchmarks/performance/bm_call_simple.py -n 1
0.215

$ cd /home/haypo/prog/python/benchmarks
$ PYTHONHASHSEED=3 taskset -c 1 ../fastcall/pgo/python ../benchmarks/performance/bm_call_simple.py -n 1
0.203

$ cd /home/haypo/prog/python
$ PYTHONHASHSEED=3 taskset -c 1 fastcall/pgo/python benchmarks/performance/bm_call_simple.py -n 1
0.200
&lt;/pre&gt;
&lt;p&gt;In fact, a different command line is enough so get different results (added
arguments are ignored):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1
0.201
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1
0.198
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3
0.203
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3 arg4 arg5
0.206
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3 arg4 arg5 arg6
0.210
&lt;/pre&gt;
&lt;p&gt;I also noticed minor differences when the environment changes (added variables
are ignored):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py -n 1
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 VAR1=1 VAR2=2 VAR3=3 VAR4=4 ./python bm_call_simple.py -n 1
0.202
$ taskset -c 1 env -i PYTHONHASHSEED=3 VAR1=1 VAR2=2 VAR3=3 VAR4=4 VAR5=5 ./python bm_call_simple.py -n 1
0.198
&lt;/pre&gt;
&lt;p&gt;Using &lt;tt class="docutils literal"&gt;strace&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;ltrace&lt;/tt&gt;, I saw the memory addresses are different when
something (command line, env var, etc.) changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="average-and-standard-deviation"&gt;
&lt;h2&gt;Average and standard deviation&lt;/h2&gt;
&lt;p&gt;Basically, it looks like a lot of &amp;quot;external factors&amp;quot; have an impact on the
exact memory addresses, even if ASRL is disabled and PYTHONHASHSEED is set. I
started to think how to get &lt;em&gt;exactly&lt;/em&gt; the same command line, the same
environment (easy), the same current directory (easy), etc. The problem is that
it's just not possible to control all external factors (having an effect on the
exact memory addresses).&lt;/p&gt;
&lt;p&gt;Maybe I was plain wrong from the beginning and ASLR must be enabled,
as the default on Linux:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.198
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.202
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.199
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.207
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.200
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.201
&lt;/pre&gt;
&lt;p&gt;These results look &amp;quot;random&amp;quot;. Yes, they are. It's exactly the purpose of ASLR.&lt;/p&gt;
&lt;p&gt;But how can we compare performances if results are random? Take the minimum?&lt;/p&gt;
&lt;p&gt;No! You must never (ever again) use the minimum for benchmarking! Compute the
average and some statistics like the standard deviation:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3
Python 3.4.3
&amp;gt;&amp;gt;&amp;gt; timings=[0.198, 0.202, 0.199, 0.207, 0.200, 0.201]
&amp;gt;&amp;gt;&amp;gt; import statistics
&amp;gt;&amp;gt;&amp;gt; statistics.mean(timings)
0.2011666666666667
&amp;gt;&amp;gt;&amp;gt; statistics.stdev(timings)
0.0031885210782848245
&lt;/pre&gt;
&lt;p&gt;On this example, the average is 201 ms +/- 3 ms. IMHO the standard deviation is
quite small (reliable) which means that my benchmark is stable. To get a good
distribution, it's better to have many samples. It looks like at least 25
processes are needed. Each process tests a different memory layout and a
different hash function.&lt;/p&gt;
&lt;p&gt;Result of 5 runs, each run uses 25 processes (ASLR enabled, random hash
function):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Average: 205.2 ms +/- 3.0 ms (min: 201.1 ms, max: 214.9 ms)&lt;/li&gt;
&lt;li&gt;Average: 205.6 ms +/- 3.3 ms (min: 201.4 ms, max: 216.5 ms)&lt;/li&gt;
&lt;li&gt;Average: 206.0 ms +/- 3.9 ms (min: 201.1 ms, max: 215.3 ms)&lt;/li&gt;
&lt;li&gt;Average: 205.7 ms +/- 3.6 ms (min: 201.5 ms, max: 217.8 ms)&lt;/li&gt;
&lt;li&gt;Average: 206.4 ms +/- 3.5 ms (min: 201.9 ms, max: 214.9 ms)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While memory layout and hash functions are random again, the result looks
&lt;em&gt;less&lt;/em&gt; random, and so more reliable, than before!&lt;/p&gt;
&lt;p&gt;With ASLR enabled, the effect of the environment variables, command line and
current directory is negligible on the (average) result.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-average-solves-issues-with-uniform-random-noises"&gt;
&lt;h2&gt;The average solves issues with uniform random noises&lt;/h2&gt;
&lt;p&gt;The user will run the application with default system settings which means
ASLR enabled and Python hash function randomized. Running a benchmark in one
specific environment is a mistake because it is not representative of the
performance in practice.&lt;/p&gt;
&lt;p&gt;Computing the average and standard deviation &amp;quot;fixes&amp;quot; the issue with hash
randomization. It's much better to use random hash functions and compute the
average, than using a fixed hash function (setting &lt;tt class="docutils literal"&gt;PYTHONHASHSEED&lt;/tt&gt; variable
to a value).&lt;/p&gt;
&lt;p&gt;Oh wow, already 3 big articles explaing how to get stable benchmarks. Please
tell me that it was the last one!  Nope, more is coming...&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="annex-why-only-n1"&gt;
&lt;h2&gt;Annex: why only -n1?&lt;/h2&gt;
&lt;p&gt;In this article, I ran &lt;tt class="docutils literal"&gt;bm_call_simple.py&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-n&lt;/span&gt; 1&lt;/tt&gt; with only run one
iteration.&lt;/p&gt;
&lt;p&gt;Usually, a single iteration is not reliable at all, at least 50 iterations are
needed. But thanks to system tuning, compilation with PGO, ASRL disabled and
&lt;tt class="docutils literal"&gt;PYTHONHASHSEED&lt;/tt&gt; set, a single iteration is enough.&lt;/p&gt;
&lt;p&gt;Example of 3 runs, each with 3 iterations:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py -n 3
0.201
0.201
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py -n 3
0.201
0.201
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py -n 3
0.201
0.201
0.201
&lt;/pre&gt;
&lt;p&gt;Always the same timing!&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category></entry><entry><title>My journey to stable benchmark, part 2 (deadcode)</title><link href="https://haypo.github.io/journey-to-stable-benchmark-deadcode.html" rel="alternate"></link><published>2016-05-22T22:00:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-05-22:journey-to-stable-benchmark-deadcode.html</id><summary type="html">&lt;a class="reference external image-reference" href="https://www.flickr.com/photos/uw67/16875152403/"&gt;&lt;img alt="Snail" src="https://haypo.github.io/images/snail.jpg" /&gt;&lt;/a&gt;
&lt;p&gt;With &lt;a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-system.html"&gt;the system tuning (part 1)&lt;/a&gt;, I
expected to get very stable benchmarks and so I started to benchmark seriously
my &lt;a class="reference external" href="https://bugs.python.org/issue26814"&gt;FASTCALL branch&lt;/a&gt; of CPython (a new
calling convention avoiding temporary tuples).&lt;/p&gt;
&lt;p&gt;I was disappointed to get many slowdowns in the CPython benchmark suite. I
started to analyze why my change introduced performance regressions.&lt;/p&gt;
&lt;p&gt;I took my overall patch and slowly reverted more and more code to check which
changes introduced most of the slowdowns.&lt;/p&gt;
&lt;p&gt;I focused on the &lt;tt class="docutils literal"&gt;call_simple&lt;/tt&gt; benchmark which does only one thing: call
Python functions which do nothing.  Making Python function calls slower would
be a big and inacceptable mistake of my work.&lt;/p&gt;
&lt;div class="section" id="linux-perf"&gt;
&lt;h2&gt;Linux perf&lt;/h2&gt;
&lt;p&gt;I started to learn how to use the great &lt;a class="reference external" href="https://perf.wiki.kernel.org/index.php/Main_Page"&gt;Linux perf&lt;/a&gt; tool to analyze why
&lt;tt class="docutils literal"&gt;call_simple&lt;/tt&gt; was slower. I tried to find a major difference between my
reference python and the patched python.&lt;/p&gt;
&lt;p&gt;I analyzed cache misses on L1 instruction and data caches.  I analyzed stallen
CPU cycles. I analyzed all memory events, branch events, etc. Basically, I tried
all perf events and spent a lot of time to run benchmarks multiple times.&lt;/p&gt;
&lt;p&gt;By the way, I strongly suggest to use &lt;tt class="docutils literal"&gt;perf stat&lt;/tt&gt; using the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--repeat&lt;/span&gt;&lt;/tt&gt;
command line option to get an average on multiple runs and see the standard
deviation. It helps to get more reliable numbers. I even wrote a Python script
implementing &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--repeat&lt;/span&gt;&lt;/tt&gt; (run perf multiple times, parse the output), before
seeing that it was already a builtin feature!&lt;/p&gt;
&lt;p&gt;Use &lt;tt class="docutils literal"&gt;perf list&lt;/tt&gt; to list all available (pre-defined) events.&lt;/p&gt;
&lt;p&gt;After many days, I decided to give up with perf.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cachegrind"&gt;
&lt;h2&gt;Cachegrind&lt;/h2&gt;
&lt;a class="reference external image-reference" href="http://valgrind.org/"&gt;&lt;img alt="Logo of the Valgrind project" src="https://haypo.github.io/images/valgrind.png" /&gt;&lt;/a&gt;
&lt;p&gt;&lt;a class="reference external" href="http://valgrind.org/"&gt;Valgrind&lt;/a&gt; is a great tool known to detect memory
leaks, but it also contains gems like the &lt;a class="reference external" href="http://valgrind.org/docs/manual/cg-manual.html"&gt;Cachegrind tool&lt;/a&gt; which &lt;em&gt;simulates&lt;/em&gt; the
CPU caches.&lt;/p&gt;
&lt;p&gt;I used Cachegrind with the nice &lt;a class="reference external" href="http://kcachegrind.sourceforge.net/"&gt;Kcachegrind GUI&lt;/a&gt;. Sadly, I also failed to see anything
obvious in cache misses between the reference python and the patched python.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="strace-and-ltrace"&gt;
&lt;h2&gt;strace and ltrace&lt;/h2&gt;
&lt;img alt="strace and ltrace" src="https://haypo.github.io/images/strace_ltrace.png" /&gt;
&lt;p&gt;I also tried &lt;tt class="docutils literal"&gt;strace&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;ltrace&lt;/tt&gt; tools to try to see a difference in the
execution of the reference and the patched pythons. I saw different memory
addresses, but no major difference which can explain a difference of the
timing.&lt;/p&gt;
&lt;p&gt;Morever, the hotcode simply does not call any syscall nor library
function. It's pure CPU-bound code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="compiler-options"&gt;
&lt;h2&gt;Compiler options&lt;/h2&gt;
&lt;a class="reference external image-reference" href="https://gcc.gnu.org/"&gt;&lt;img alt="GCC logo" class="align-right" src="https://haypo.github.io/images/gcc.png" /&gt;&lt;/a&gt;
&lt;p&gt;I used &lt;a class="reference external" href="https://gcc.gnu.org/"&gt;GCC&lt;/a&gt; to build to code. Just in case, I tried
LLVM compiler, but it didn't &amp;quot;fix&amp;quot; the issue.&lt;/p&gt;
&lt;p&gt;I also tried different optimization levels: &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-O0&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-O1&lt;/span&gt;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-O2&lt;/span&gt;&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-O3&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;I read that the exact address of functions can have an impact on the CPU L1
cache: &lt;a class="reference external" href="https://stackoverflow.com/questions/19470873/why-does-gcc-generate-15-20-faster-code-if-i-optimize-for-size-instead-of-speed"&gt;Why does gcc generate 15-20% faster code if I optimize for size instead
of speed?&lt;/a&gt;.
I tried various values of the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-falign-functions=N&lt;/span&gt;&lt;/tt&gt; option (1, 2, 6, 12).&lt;/p&gt;
&lt;p&gt;I also tried &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-fomit-pointer&lt;/span&gt;&lt;/tt&gt; (omit frame pointer) to record the callgraph with &lt;tt class="docutils literal"&gt;perf record&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;I also tried &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-flto&lt;/span&gt;&lt;/tt&gt;: Link Time Optimization (LTO).&lt;/p&gt;
&lt;p&gt;These compiler options didn't fix the issue.&lt;/p&gt;
&lt;p&gt;The truth is out there.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; See also &lt;a class="reference external" href="https://lwn.net/Articles/534735/"&gt;Rethinking optimization for size&lt;/a&gt; article on Linux Weekly News (LWN):
&lt;em&gt;&amp;quot;Such an option has obvious value if one is compiling for a
space-constrained environment like a small device. But it turns out that, in
some situations, optimizing for space can also produce faster code.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="when-cpython-performance-depends-on-dead-code"&gt;
&lt;h2&gt;When CPython performance depends on dead code&lt;/h2&gt;
&lt;p&gt;I continued to revert changes. At the end, my giant patch was reduced to very
few changes only adding code which was never called (at least, I was sure
that it was not called in the &lt;tt class="docutils literal"&gt;call_simple&lt;/tt&gt; benchmark).&lt;/p&gt;
&lt;p&gt;Let me rephase: &lt;em&gt;adding dead code&lt;/em&gt; makes Python slower. What?&lt;/p&gt;
&lt;p&gt;A colleague suggested me to remove the body (replace it with &lt;tt class="docutils literal"&gt;return;&lt;/tt&gt;) of
added function: the code became faster. Ok, now I'm completely lost. To be
clear, I don't expect that adding dead code would have &lt;em&gt;any&lt;/em&gt; impact on the
performance.&lt;/p&gt;
&lt;p&gt;My email &lt;a class="reference external" href="https://mail.python.org/pipermail/speed/2016-April/000341.html"&gt;When CPython performance depends on dead code...&lt;/a&gt; explains how
to reproduce the issue and contains many information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="solution-pgo"&gt;
&lt;h2&gt;Solution: PGO&lt;/h2&gt;
&lt;p&gt;The solution is called Profiled Guided Optimization, &amp;quot;PGO&amp;quot;. Python build system
supports it in a single command: &lt;tt class="docutils literal"&gt;make &lt;span class="pre"&gt;profile-opt&lt;/span&gt;&lt;/tt&gt;. It profiles the
execution of the Python test suite.&lt;/p&gt;
&lt;p&gt;Using PGO, adding dead code has no more impact on the performance.&lt;/p&gt;
&lt;p&gt;With system tuning and PGO compilation, benchmarks must now be stable this
time, no? ... No, sorry, not yet. We will see more sources of noise in
following articles ;-)&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category></entry><entry><title>My journey to stable benchmark, part 1 (system)</title><link href="https://haypo.github.io/journey-to-stable-benchmark-system.html" rel="alternate"></link><published>2016-05-21T16:50:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-05-21:journey-to-stable-benchmark-system.html</id><summary type="html">&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;In the CPython development, it became common to require the result of the
&lt;a class="reference external" href="https://hg.python.org/benchmarks"&gt;CPython benchmark suite&lt;/a&gt; (&amp;quot;The Grand
Unified Python Benchmark Suite&amp;quot;) to evaluate the effect of an optimization
patch. The minimum requirement is to not introduce performance regressions.&lt;/p&gt;
&lt;p&gt;I used the CPython benchmark suite and I had many bad surprises when trying to
analyze (understand) results. A change expected to be faster makes some
benchmarks slower without any obvious reason. At least, the change is expected
to be faster on some specific benchmarks, but have no impact on the other
benchmarks. The slowdown is usually between 5% and 10% slower. I am not
confortable with any kind of slowdown.&lt;/p&gt;
&lt;p&gt;Many benchmarks look unstable. The problem is to trust the overall report.
Some developers started to say that they learnt to ignore some benchmarks known
to be unstable.&lt;/p&gt;
&lt;p&gt;It's not the first time that I am totally disappointed by microbenchmark
results, so I decided to analyze completely the issue and go as deep as
possible to really understand the problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-get-stable-benchmarks-on-a-busy-linux-system"&gt;
&lt;h2&gt;How to get stable benchmarks on a busy Linux system&lt;/h2&gt;
&lt;p&gt;A common advice to get stable benchmark is to stay away the keyboard
(&amp;quot;freeze!&amp;quot;) and stop all other applications to only run one application, the
benchmark.&lt;/p&gt;
&lt;p&gt;Well, I'm working on a single computer and the full CPython benchmark suite
take up to 2 hours in rigorous mode. I just cannot stop working during 2 hours
to wait for the result of the benchmark. I like running benchmarks locally. It
is convenient to run benchmarks on the same computer used to develop.&lt;/p&gt;
&lt;p&gt;The goal here is to &amp;quot;remove the noise of the system&amp;quot;. Get the same result on a
busy system than an idle system. My simple &lt;a class="reference external" href="https://bitbucket.org/haypo/misc/src/tip/bin/system_load.py"&gt;system_load.py&lt;/a&gt; program can be
used to increase the system load. For example, run &lt;tt class="docutils literal"&gt;system_load.py 10&lt;/tt&gt; in a
terminal to get at least a system load of 10 (busy system) and run the
benchmark in a different terminal. Use CTRL+c to stop &lt;tt class="docutils literal"&gt;system_load.py&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cpu-isolation"&gt;
&lt;h2&gt;CPU isolation&lt;/h2&gt;
&lt;p&gt;In 2016, it is common to get a CPU with multiple physical cores. For example,
my Intel CPU has 4 physical cores and 8 logical cores thanks to
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Hyper-threading"&gt;Hyper-Threading&lt;/a&gt;. It is
possible to configure the Linux kernel to not schedule processes on some CPUs
using the &amp;quot;CPU isolation&amp;quot; feature. It is the &lt;tt class="docutils literal"&gt;isolcpus&lt;/tt&gt; parameter of the
Linux command line, the value is a list of CPUs. Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
isolcpus=2,3,6,7
&lt;/pre&gt;
&lt;p&gt;Check with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat /sys/devices/system/cpu/isolated
2-3,6-7
&lt;/pre&gt;
&lt;p&gt;If you have Hyper-Threading, you must isolate the two logicial cores of each
isolated physical core. You can use the &lt;tt class="docutils literal"&gt;lscpu &lt;span class="pre"&gt;--all&lt;/span&gt; &lt;span class="pre"&gt;--extended&lt;/span&gt;&lt;/tt&gt; command to
identify physical cores. Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ lscpu -a -e
CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
0   0    0      0    0:0:0:0       yes    5900,0000 1600,0000
1   0    0      1    1:1:1:0       yes    5900,0000 1600,0000
2   0    0      2    2:2:2:0       yes    5900,0000 1600,0000
3   0    0      3    3:3:3:0       yes    5900,0000 1600,0000
4   0    0      0    0:0:0:0       yes    5900,0000 1600,0000
5   0    0      1    1:1:1:0       yes    5900,0000 1600,0000
6   0    0      2    2:2:2:0       yes    5900,0000 1600,0000
7   0    0      3    3:3:3:0       yes    5900,0000 1600,0000
&lt;/pre&gt;
&lt;p&gt;The physical core &lt;tt class="docutils literal"&gt;0&lt;/tt&gt; (CORE column) is made of two logical cores (CPU
column): &lt;tt class="docutils literal"&gt;0&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;4&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nohz-mode"&gt;
&lt;h2&gt;NOHZ mode&lt;/h2&gt;
&lt;p&gt;By default, the Linux kernel uses a scheduling-clock which interrupts the
running application &lt;tt class="docutils literal"&gt;HZ&lt;/tt&gt; times per second to run the scheduler. &lt;tt class="docutils literal"&gt;HZ&lt;/tt&gt; is
usually between 100 and 1000: time slice between 1 ms and 10 ms.&lt;/p&gt;
&lt;p&gt;Linux supports a &lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/timers/NO_HZ.txt"&gt;NOHZ mode&lt;/a&gt; which is able to
disable the scheduling-clock when the system is idle to reduce the power
consumption. Linux 3.10 introduces a &lt;a class="reference external" href="https://lwn.net/Articles/549580/"&gt;full ticketless mode&lt;/a&gt;, NOHZ full, which is able to disable the
scheduling-clock when only one application is running on a CPU.&lt;/p&gt;
&lt;p&gt;NOHZ full is disabled by default. It can be enabled with the &lt;tt class="docutils literal"&gt;nohz_full&lt;/tt&gt;
parameter of the Linux command line, the value is a list of CPUs. Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nohz_full=2,3,6,7
&lt;/pre&gt;
&lt;p&gt;Check with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cat /sys/devices/system/cpu/nohz_full
2-3,6-7
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="interrupts-irq"&gt;
&lt;h2&gt;Interrupts (IRQ)&lt;/h2&gt;
&lt;p&gt;The Linux kernel can also be configured to not run &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Interrupt_request_%28PC_architecture%29"&gt;interruptions (IRQ)&lt;/a&gt;
handlers on some CPUs using &lt;tt class="docutils literal"&gt;/proc/irq/default_smp_affinity&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;/proc/irq/&amp;lt;number&amp;gt;/smp_affinity&lt;/span&gt;&lt;/tt&gt; files. The value is not a list of CPUs but
a bitmask.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;/proc/interrupts&lt;/tt&gt; file can be read to see the number of interruptions
per CPU.&lt;/p&gt;
&lt;p&gt;Read the &lt;a class="reference external" href="https://www.kernel.org/doc/Documentation/IRQ-affinity.txt"&gt;Linux SMP IRQ affinity&lt;/a&gt; documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="example-of-effect-of-cpu-isolation-on-a-microbenchmark"&gt;
&lt;h2&gt;Example of effect of CPU isolation on a microbenchmark&lt;/h2&gt;
&lt;p&gt;Example with Linux parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
isolcpus=2,3,6,7 nohz_full=2,3,6,7
&lt;/pre&gt;
&lt;p&gt;Microbenchmark on an idle system (without CPU isolation):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m timeit 'sum(range(10**7))'
10 loops, best of 3: 229 msec per loop
&lt;/pre&gt;
&lt;p&gt;Result on a busy system using &lt;tt class="docutils literal"&gt;system_load.py 10&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;find /&lt;/tt&gt; commands
running in other terminals:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m timeit 'sum(range(10**7))'
10 loops, best of 3: 372 msec per loop
&lt;/pre&gt;
&lt;p&gt;The microbenchmark is 56% slower because of the high system load!&lt;/p&gt;
&lt;p&gt;Result on the same busy system but using isolated CPUs. The &lt;tt class="docutils literal"&gt;taskset&lt;/tt&gt; command
allows to pin an application to specific CPUs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ taskset -c 1,3 python3 -m timeit 'sum(range(10**7))'
10 loops, best of 3: 230 msec per loop
&lt;/pre&gt;
&lt;p&gt;Just to check, new run without CPU isolation:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ python3 -m timeit 'sum(range(10**7))'
10 loops, best of 3: 357 msec per loop
&lt;/pre&gt;
&lt;p&gt;The result with CPU isolation on a busy system is the same than the result an
idle system! CPU isolation removes most of the noise of the system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Great job Linux!&lt;/p&gt;
&lt;p&gt;Ok! Now, the benchmark is super stable, no? ...  Sorry, no, it's not stable yet.
I found a lot of other sources of &amp;quot;noise&amp;quot;.  We will see them in the following
articles ;-)&lt;/p&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="benchmark"></category></entry><entry><title>Status of Python 3 in OpenStack Mitaka</title><link href="https://haypo.github.io/openstack_mitaka_python3.html" rel="alternate"></link><published>2016-03-02T14:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-03-02:openstack_mitaka_python3.html</id><summary type="html">&lt;p&gt;Now that most OpenStack services have reached feature freeze for the Mitaka
cycle (November 2015-April 2016), it's time to look back on the progress made
for Python 3 support.&lt;/p&gt;
&lt;p&gt;Previous status update: &lt;a class="reference external" href="http://techs.enovance.com/7807/python-3-status-openstack-liberty"&gt;Python 3 Status in OpenStack Liberty&lt;/a&gt;
(September 2015).&lt;/p&gt;
&lt;div class="section" id="services-ported-to-python-3"&gt;
&lt;h2&gt;Services ported to Python 3&lt;/h2&gt;
&lt;p&gt;13 services were ported to Python 3 during the Mitaka cycle:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Cinder&lt;/li&gt;
&lt;li&gt;Congress&lt;/li&gt;
&lt;li&gt;Designate&lt;/li&gt;
&lt;li&gt;Glance&lt;/li&gt;
&lt;li&gt;Heat&lt;/li&gt;
&lt;li&gt;Horizon&lt;/li&gt;
&lt;li&gt;Manila&lt;/li&gt;
&lt;li&gt;Mistral&lt;/li&gt;
&lt;li&gt;Octavia&lt;/li&gt;
&lt;li&gt;Searchlight&lt;/li&gt;
&lt;li&gt;Solum&lt;/li&gt;
&lt;li&gt;Watcher&lt;/li&gt;
&lt;li&gt;Zaqar&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat contributed to the Cinder, Designate, Glance and Horizon service
porting efforts.&lt;/p&gt;
&lt;p&gt;&amp;quot;Ported to Python 3&amp;quot; means that all unit tests pass on Python 3.4 which is
verified by a voting gate job. It is not enough to run applications in
production with Python 3. Integration and functional tests are not run on
Python 3 yet. See the section dedicated to these tests below.&lt;/p&gt;
&lt;p&gt;See the &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Python3"&gt;Python 3 wiki page&lt;/a&gt; for the
current status of the OpenStack port to Python 3; especially the list of
services ported to Python 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="services-not-ported-yet"&gt;
&lt;h2&gt;Services not ported yet&lt;/h2&gt;
&lt;p&gt;It's become easier to list services which are not compatible with Python 3 than
listing services already ported to Python 3!&lt;/p&gt;
&lt;p&gt;9 services still need to be ported:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Work-in-progress:&lt;ul&gt;
&lt;li&gt;Magnum: 83% (959 unit tests/1,161)&lt;/li&gt;
&lt;li&gt;Cue: 81% (208 unit tests/257)&lt;/li&gt;
&lt;li&gt;Nova: 74% (10,859 unit tests/14,726)&lt;/li&gt;
&lt;li&gt;Barbican: 34% (392 unit tests/1168)&lt;/li&gt;
&lt;li&gt;Murano: 29% (133 unit tests/455)&lt;/li&gt;
&lt;li&gt;Keystone: 27% (1200 unit tests/4455)&lt;/li&gt;
&lt;li&gt;Swift: 0% (3 unit tests/4,435)&lt;/li&gt;
&lt;li&gt;Neutron-LBaaS: 0% (1 unit test/806)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Port not started yet:&lt;ul&gt;
&lt;li&gt;Trove: no python34 gate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat contributed Python 3 patches to Cue, Neutron-LBaaS, Swift and Trove
during the Mitaka cycle.&lt;/p&gt;
&lt;p&gt;Trove developers are ready to start the port at the beginning of the next cycle
(Newton). The py34 test environment was blocked by the MySQL-Python dependency (it
was not possible to build the test environment), but this dependency is now
skipped on Python 3. Later, it will be &lt;a class="reference external" href="https://review.openstack.org/#/c/225915/"&gt;replaced with PyMySQL&lt;/a&gt; on Python 2 and Python 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-issues-in-eventlet"&gt;
&lt;h2&gt;Python 3 issues in Eventlet&lt;/h2&gt;
&lt;p&gt;Four Python 3 issues were fixed in Eventlet:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/eventlet/eventlet/issues/295"&gt;Issue #295: Python 3: wsgi doesn't handle correctly partial write of
socket send() when using writelines()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PR #275: &lt;a class="reference external" href="https://github.com/eventlet/eventlet/pull/275"&gt;Issue #274: Fix GreenSocket.recv_into()&lt;/a&gt;.
Issue: &lt;a class="reference external" href="https://github.com/eventlet/eventlet/issues/274"&gt;On Python 3, sock.makefile('rb').readline() doesn't handle blocking
errors correctly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PR #257: &lt;a class="reference external" href="https://github.com/eventlet/eventlet/pull/257"&gt;Fix GreenFileIO.readall() for regular file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/eventlet/eventlet/issues/248"&gt;Issue #248: eventlet.monkey_patch() on Python 3.4 makes stdout
non-blocking&lt;/a&gt;: pull
request &lt;a class="reference external" href="https://github.com/eventlet/eventlet/pull/250"&gt;Fix GreenFileIO.write()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="next-milestone-functional-and-integration-tests"&gt;
&lt;h2&gt;Next Milestone: Functional and integration tests&lt;/h2&gt;
&lt;p&gt;The next major milestone will be to run functional and integration tests on
Python 3.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;functional tests are restricted to one component (ex: only Glance)&lt;/li&gt;
&lt;li&gt;integration tests, like Tempest, test the integration of multiple components&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is now possible to install some packages on Python 3 in DevStack using
&lt;tt class="docutils literal"&gt;USE_PYTHON3&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;PYTHON3_VERSION&lt;/tt&gt; variables: &lt;a class="reference external" href="https://review.openstack.org/#/c/181165/"&gt;Enable optional Python 3
support&lt;/a&gt;. It means that it is
possible to run tests with some services running on Python 3, and the remaining
services on Python 2.&lt;/p&gt;
&lt;p&gt;The port to Python 3 of Glance, Heat and Neutron functional and integration
tests have already started.&lt;/p&gt;
&lt;p&gt;For Glance, 159 functional tests already pass on Python 3.4.&lt;/p&gt;
&lt;p&gt;Heat:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;project-config: &lt;a class="reference external" href="https://review.openstack.org/#/c/228194/"&gt;Add python34 integration test job for Heat&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;heat: &lt;a class="reference external" href="https://review.openstack.org/#/c/188033/"&gt;py34: integration tests&lt;/a&gt;
(WIP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Neutron: the &lt;a class="reference external" href="https://review.openstack.org/#/c/231897/"&gt;Add the functional-py34 and dsvm-functional-py34 targets to
tox.ini&lt;/a&gt; change was merged, but a
gate job hasn't been added for it yet.&lt;/p&gt;
&lt;p&gt;Another pending project is to fix issues specific to Python 3.5, but the gate
doesnt use Python 3.5 yet. There are some minor issues, probably easy to fix.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-port-remaining-code"&gt;
&lt;h2&gt;How to port remaining code?&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Python3"&gt;Python 3 wiki page&lt;/a&gt; contains
a lot of information about adding Python 3 support to Python 2 code.&lt;/p&gt;
&lt;p&gt;Join us in the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;#openstack-python3&lt;/span&gt;&lt;/tt&gt; IRC channel on Freenode to discuss
Python 3!&lt;/p&gt;
&lt;/div&gt;
</summary><category term="openstack"></category><category term="python3"></category></entry><entry><title>Fast _PyAccu, _PyUnicodeWriter and_PyBytesWriter APIs to produce strings in CPython</title><link href="https://haypo.github.io/pybyteswriter.html" rel="alternate"></link><published>2016-03-01T16:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-03-01:pybyteswriter.html</id><summary type="html">&lt;p&gt;This article described the _PyBytesWriter and _PyUnicodeWriter private APIs of
CPython. These APIs are design to optimize code producing strings when the
ouput size is not known in advance.&lt;/p&gt;
&lt;p&gt;I created the _PyUnicodeWriter API to reply to complains that Python 3 was much
slower than Python 2, especially with the new Unicode implementation (PEP 393).&lt;/p&gt;
&lt;div class="section" id="pyaccu-api"&gt;
&lt;h2&gt;_PyAccu API&lt;/h2&gt;
&lt;p&gt;Issue #12778: In 2011, Antoine Pitrou found a performance issue in the JSON
serializer when serializing many small objects: it used way too much memory for
temporary objects compared to the final output string.&lt;/p&gt;
&lt;p&gt;The JSON serializer used a list of strings and joined all strings at the end of
create a final output string. Pseudocode:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def serialize():
    pieces = [serialize(item) for item in self]
    return ''.join(pieces)
&lt;/pre&gt;
&lt;p&gt;Antoine introduced an accumulator compacting the temporary list of &amp;quot;small&amp;quot;
strings and put the result in a second list of &amp;quot;large&amp;quot; strings. At the end, the
list of &amp;quot;large&amp;quot; strings was also compacted to build the final output string.
Pseudo-code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def serialize():
    small = []
    large = []
    for item in self:
        small.append(serialize(item))
        if len(small) &amp;gt; 10000:
            large.append(''.join(small))
            small.clear()
    if small
        large.append(''.join(small))
    return ''.join(large)
&lt;/pre&gt;
&lt;p&gt;The threshold of 10,000  strings is justified by this comment:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/* Each item in a list of unicode objects has an overhead (in 64-bit
 * builds) of:
 *   - 8 bytes for the list slot
 *   - 56 bytes for the header of the unicode object
 * that is, 64 bytes.  100000 such objects waste more than 6MB
 * compared to a single concatenated string.
 */
&lt;/pre&gt;
&lt;p&gt;Issue #12911: Antoine Pitrou found a similar performance issue in repr(list),
and so proposed to convert its accumular code into a new private _PyAccu API.
He added the _PyAccu API to Python 2.7.5 and 3.2.3. Title of te repr(list)
change: &amp;quot;Fix memory consumption when calculating the repr() of huge tuples or
lists&amp;quot;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-pyunicodewriter-api"&gt;
&lt;h2&gt;The _PyUnicodeWriter API&lt;/h2&gt;
&lt;div class="section" id="inefficient-implementation-of-the-pep-393"&gt;
&lt;h3&gt;Inefficient implementation of the PEP 393&lt;/h3&gt;
&lt;p&gt;In 2010, Python 3.3 got a completly new Unicode implementation, the Python type
&lt;tt class="docutils literal"&gt;str&lt;/tt&gt;, with the PEP 393. The implementation of the PEP was the topic of a
Google Summer of Code 2011 with the student Torsten Becker menthored by Martin
v. Lwis (author of the PEP). The project was successful: the PEP 393 was
implemented, it worked!&lt;/p&gt;
&lt;p&gt;The first implementation of the PEP 393 used a lot of 32-bit character buffers
(&lt;tt class="docutils literal"&gt;Py_UCS4&lt;/tt&gt;) which uses a lot of memory and requires expensive conversion to
8-bit (&lt;tt class="docutils literal"&gt;Py_UCS1&lt;/tt&gt;, ASCII and Latin1) or 16-bit (&lt;tt class="docutils literal"&gt;Py_UCS2&lt;/tt&gt;, BMP) characters.&lt;/p&gt;
&lt;p&gt;The new internal structures for Unicode strings are now very complex and
require to be smart when building a new string to avoid memory copies. I
created the _PyUnicodeWriter API to try to reduce expensive memory copies, and
even completly avoid memory copies in best cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="design-of-the-pyunicodewriter-api"&gt;
&lt;h3&gt;Design of the _PyUnicodeWriter API&lt;/h3&gt;
&lt;p&gt;According to benchmarks, creating a &lt;tt class="docutils literal"&gt;Py_UCS1*&lt;/tt&gt; buffer and then expand it
to &lt;tt class="docutils literal"&gt;Py_UCS2*&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;Py_UCS4*&lt;/tt&gt; is more efficient, since &lt;tt class="docutils literal"&gt;Py_UCS1*&lt;/tt&gt; is the
most common format.&lt;/p&gt;
&lt;p&gt;Python &lt;tt class="docutils literal"&gt;str&lt;/tt&gt; type is used for a wide range of usages. For example, it is used
for the name of variable names in the Python language itself. Variable names
are almost always ASCII.&lt;/p&gt;
&lt;p&gt;The worst case for _PyUnicodeWriter is when a long &lt;tt class="docutils literal"&gt;Py_UCS1*&lt;/tt&gt; buffer must be
converted to &lt;tt class="docutils literal"&gt;Py_UCS2*&lt;/tt&gt;, and then converted to &lt;tt class="docutils literal"&gt;Py_UCS4*&lt;/tt&gt;. Each conversion
is expensive: need to allocate a second memory block and convert characters to
the new format.&lt;/p&gt;
&lt;p&gt;_PyUnicodeWriter features:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Optional overallocation: overallocate the buffer by 50% on Windows and 25%
on Linux. The ratio changes depending on the OS, it is a raw heuristic to get
the best performances depending on the &lt;tt class="docutils literal"&gt;malloc()&lt;/tt&gt; memory allocator.&lt;/li&gt;
&lt;li&gt;The buffer can be a shared read-only string if the buffer was only created
from a single string. Micro-optimization for &lt;tt class="docutils literal"&gt;&amp;quot;%s&amp;quot; % str&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The API allows to disable overallocation before the last write. For example,
&lt;tt class="docutils literal"&gt;&amp;quot;%s%s&amp;quot; % ('abc', 'def')&lt;/tt&gt; disables the overallocation before writing
&lt;tt class="docutils literal"&gt;'def'&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;The _PyUnicodeWriter was introduced by the issue #14716 (change 7be716a47e9d):&lt;/p&gt;
&lt;blockquote&gt;
Close #14716: str.format() now uses the new &amp;quot;unicode writer&amp;quot; API instead
of the PyAccu API. For example, it makes str.format() from 25% to 30%
faster on Linux.&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="fast-path-for-ascii"&gt;
&lt;h3&gt;Fast-path for ASCII&lt;/h3&gt;
&lt;p&gt;The cool and &lt;em&gt;unexpected&lt;/em&gt; side-effect of the _PyUnicodeWriter is that many
intermediate operations got a fast-path for &lt;tt class="docutils literal"&gt;Py_UCS1*&lt;/tt&gt;, especially for ASCII
strings. For example, padding a number with spaces on &lt;tt class="docutils literal"&gt;'%10i' % 123&lt;/tt&gt; is
implemented with &lt;tt class="docutils literal"&gt;memset()&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Formating a floating point number uses the &lt;tt class="docutils literal"&gt;PyOS_double_to_string()&lt;/tt&gt; function
which creates an ASCII buffer. If the writer buffer uses Py_UCS1, a
&lt;tt class="docutils literal"&gt;memcpy()&lt;/tt&gt; is enough to copy the formatted number.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="avoid-temporary-buffers"&gt;
&lt;h3&gt;Avoid temporary buffers&lt;/h3&gt;
&lt;p&gt;Since the beginning, I had the idea of avoiding temporary buffers thanks
to an unified API to handle a &amp;quot;Unicode buffer&amp;quot;. Slowly, I spread my changes
to all functions producing Unicode strings.&lt;/p&gt;
&lt;p&gt;The obvious target were &lt;tt class="docutils literal"&gt;str % args&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;str.format(args)&lt;/tt&gt;. Both
instructions use very different code, but it was possible to share a few
functions especially the code to format integers in bases 2 (binary), 8
(octal), 10 (decimal) and 16 (hexadecimal).&lt;/p&gt;
&lt;p&gt;The function formatting an integer computes the exact size of the output,
requests a number of characters and then write characters. The characters are
written directly in the writer buffer. No temporary memory block is needed
anymore, and moreover no Py_UCS conversion is need: &lt;tt class="docutils literal"&gt;_PyLong_Format()&lt;/tt&gt; writes
directly characters into the character format (PyUCS1, Py_UCS2 or Py_UCS4) of
the buffer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performance-compared-to-python-2"&gt;
&lt;h3&gt;Performance compared to Python 2&lt;/h3&gt;
&lt;p&gt;The PEP 393 uses a complex storage for strings, so the exact performances
now depends on the character set used in the benchmark. For benchmarks using
a character set different than ASCII, the result are more tricky to understand.&lt;/p&gt;
&lt;p&gt;To compare performances with Python 2, I focused my benchmarks on ASCII.  I
compared Python 3 str with Python 2 unicode, but also sometimes to Python 2 str
(bytes). On ASCII, Python 3.3 was as fast as Python 2, or even faster on some
very specific cases, but these cases are probably artificial and never seen in
real applications.&lt;/p&gt;
&lt;p&gt;In the best case, Python 3 str (Unicode) was faster than Python 2 bytes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="pybyteswriter-api-first-try-big-fail"&gt;
&lt;h2&gt;_PyBytesWriter API: first try, big fail&lt;/h2&gt;
&lt;p&gt;Since Python was &lt;em&gt;much&lt;/em&gt; faster with _PyUnicodeWriter, I expected to get good
speedup with a similar API for bytes. The graal would be to share code for
bytes and Unicode (Spoiler alert! I reached this goal, but only for a single
function: format an integer to decimal).&lt;/p&gt;
&lt;p&gt;My first attempt of a _PyBytesWriter API was in 2013: &lt;a class="reference external" href="https://bugs.python.org/issue17742"&gt;Issue #17742: Add
_PyBytesWriter API&lt;/a&gt;. But quickly, I
noticed with microbenchmarks that my change made Python slower! I spent hours
to understand why GCC produced less efficient machine code. When I started to
dig the &amp;quot;strict aliasing&amp;quot; optimization issue, I realized that I reached a
deadend.&lt;/p&gt;
&lt;p&gt;Extract of the _PyBytesWriter structure:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
typedef struct {
    /* Current position in the buffer */
    char *str;

    /* Start of the buffer */
    char *start;

    /* End of the buffer */
    char *end;

    ...
} _PyBytesWriter;
&lt;/pre&gt;
&lt;p&gt;The problem is that GCC emited less efficient machine code for the C code (see
my &lt;a class="reference external" href="https://bugs.python.org/issue17742#msg187595"&gt;msg187595&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
while (collstart++&amp;lt;collend)
    *writer.str++ = '?';
&lt;/pre&gt;
&lt;p&gt;For the &lt;tt class="docutils literal"&gt;writer.str++&lt;/tt&gt; instruction, the new pointer value is written
immediatly in the structure. The pointer value is read again at each iteration.
So we have 1 LOAD and 1 STORE per iteration.&lt;/p&gt;
&lt;p&gt;GCC emits better code for the original C code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
while (collstart++&amp;lt;collend)
    *str++ = '?';
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;str&lt;/tt&gt; variable is stored in a register and the new value of &lt;tt class="docutils literal"&gt;str&lt;/tt&gt; is
only written &lt;em&gt;once&lt;/em&gt;, at the end of loop (instead of writing it at each
iteration). The pointer value is &lt;em&gt;only read once&lt;/em&gt; before the loop. So we have 0
LOAD and 0 STORE (related to the pointer value) in the loop body.&lt;/p&gt;
&lt;p&gt;It looks like an aliasing issue, but I didn't find how to say to GCC that the
new value of &lt;tt class="docutils literal"&gt;writer.str&lt;/tt&gt; can be written only once at the end of the loop. I
tried the &lt;tt class="docutils literal"&gt;__restrict__&lt;/tt&gt; keyword: the LOAD (get the pointer value) was moved
out of the loop. But the STORE was still in the loop body.&lt;/p&gt;
&lt;p&gt;I wrote to gcc-help: &lt;a class="reference external" href="https://gcc.gnu.org/ml/gcc-help/2013-04/msg00192.html"&gt;Missed optimization when using a structure&lt;/a&gt;, but I didn't get any
reply. I just gave up.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pybyteswriter-api-new-try-the-good-one"&gt;
&lt;h2&gt;_PyBytesWriter API: new try, the good one&lt;/h2&gt;
&lt;p&gt;In 2015, I created the &lt;a class="reference external" href="https://bugs.python.org/issue25318"&gt;Issue #25318: Add _PyBytesWriter API to optimize
Unicode encoders&lt;/a&gt;. I redesigned the API
to avoid the aliasing issue.&lt;/p&gt;
&lt;p&gt;The new _PyBytesWriter doesn't contain the &lt;tt class="docutils literal"&gt;char*&lt;/tt&gt; pointers anymore: they are
now local variables in functions. Instead, functions of API requires two
parameters: the bytes writer and a &lt;tt class="docutils literal"&gt;char*&lt;/tt&gt; parameter. Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PyObject * _PyBytesWriter_Finish(_PyBytesWriter *writer, char *str)
&lt;/pre&gt;
&lt;p&gt;The idea is to keep &lt;tt class="docutils literal"&gt;char*&lt;/tt&gt; pointers in functions to keep the most efficient
machine code in loops. The compiler doesn't have to compute complex aliasing
rules to decide if a CPU register can be used or not.&lt;/p&gt;
&lt;p&gt;_PyBytesWriter features:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Optional overallocation: overallocate the buffer by 25% on Windows and 50%
on Linux. Same idea than _PyUnicodeWriter.&lt;/li&gt;
&lt;li&gt;Support &lt;tt class="docutils literal"&gt;bytes&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;bytearray&lt;/tt&gt; type as output format to avoid an expensive
memory copy from &lt;tt class="docutils literal"&gt;bytes&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;bytearray&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Small buffer of 512 bytes allocated on the stack to avoid the need of a
buffer allocated on the heap, before creating the final
&lt;tt class="docutils literal"&gt;bytes&lt;/tt&gt;/&lt;tt class="docutils literal"&gt;bytearray&lt;/tt&gt; object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A _PyBytesWriter structure must always be allocated on the stack (to get fast
memory allocation of the smaller buffer).&lt;/p&gt;
&lt;p&gt;While _PyUnicodeWriter has a 5 functions and 1 macro to write a single
character, write strings, write a substring, etc. _PyBytesWriter has a single
_PyBytesWriter_WriteBytes() function to write a string, since all other writes
are done directly with regular C code on &lt;tt class="docutils literal"&gt;char*&lt;/tt&gt; pointers.&lt;/p&gt;
&lt;p&gt;The API itself doesn't make the code faster. Disabling overallocation on the
last write and the usage of the small buffer allocated on the stack may be
faster.&lt;/p&gt;
&lt;p&gt;In Python 3.6, I optimized error handlers on various codecs: ASCII, Latin1
and UTF-8. For example, the UTF-8 encoder is now up to 75 times as fast for
error handlers: &lt;tt class="docutils literal"&gt;ignore&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;replace&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;surrogateescape&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;surrogatepass&lt;/tt&gt;. The &lt;tt class="docutils literal"&gt;bytes % int&lt;/tt&gt; instruction became between 30% and 50%
faster on a microbenchmark.&lt;/p&gt;
&lt;p&gt;Later, I replaced &lt;tt class="docutils literal"&gt;char*&lt;/tt&gt; type with &lt;tt class="docutils literal"&gt;void*&lt;/tt&gt; to avoid compiler warnings
in functions using &lt;tt class="docutils literal"&gt;Py_UCS1*&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;unsigned char*&lt;/tt&gt;, unsigned types.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>My contributions to CPython during 2015 Q4</title><link href="https://haypo.github.io/contrib-cpython-2015q4.html" rel="alternate"></link><published>2016-03-01T15:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-03-01:contrib-cpython-2015q4.html</id><summary type="html">&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2015 Q4
(october, november, december):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2015-10-01&amp;quot;):date(&amp;quot;2015-12-31&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 100 non-merge commits + 25 merge commits (total: 125 commits).&lt;/p&gt;
&lt;p&gt;As usual, I pushed changes of various contributors and helped them to polish
their change.&lt;/p&gt;
&lt;p&gt;I fighted against a recursion error, a regression introduced by my recent work
on the Python test suite.&lt;/p&gt;
&lt;p&gt;I focused on optimizing the bytes type during this quarter. It started with the
issue #24870 opened by &lt;strong&gt;INADA Naoki&lt;/strong&gt; who works on PyMySQL: decoding bytes
using the surrogateescape error handler was the bottleneck of this benchmark.
For me, it was an opportunity for a new attempt to implement a fast &amp;quot;bytes
writer API&amp;quot;.&lt;/p&gt;
&lt;p&gt;I pushed my first change related to &lt;a class="reference external" href="http://faster-cpython.readthedocs.org/fat_python.html"&gt;FAT Python&lt;/a&gt;! Fix parser and AST:
fill lineno and col_offset of &amp;quot;arg&amp;quot; node when compiling AST from Python
objects.&lt;/p&gt;
&lt;p&gt;Previous report: &lt;a class="reference external" href="https://haypo.github.io/contrib-cpython-2015q3.html"&gt;My contributions to CPython during 2015 Q3&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="recursion-error"&gt;
&lt;h2&gt;Recursion error&lt;/h2&gt;
&lt;div class="section" id="the-bug-issue-25274"&gt;
&lt;h3&gt;The bug: issue #25274&lt;/h3&gt;
&lt;p&gt;During the previous quarter, I refactored Lib/test/regrtest.py huge file (1,600
lines) into a new Lib/test/libregrtest/ library (8 files). The problem is that
test_sys started to crash with &amp;quot;Fatal Python error: Cannot recover from stack
overflow&amp;quot; on test_recursionlimit_recovery(). The regression was introduced by a
change on regrtest which indirectly added one more Python frame in the code
executing test_sys.&lt;/p&gt;
&lt;p&gt;CPython has a limit on the depth of a call stack: &lt;tt class="docutils literal"&gt;sys.getrecursionlimit()&lt;/tt&gt;,
1000 by default. The limit is a weak protection against overflow of the C
stack. Weak because it only counts Python frames, intermediate C functions may
allocate a lot of memory on the stack.&lt;/p&gt;
&lt;p&gt;When we reach the limit, an &amp;quot;overflow&amp;quot; flag is set, but we still allow up to
limit+50 frames, because handling a RecursionError may need a few more frames.
The overflow flag is cleared when the stack level goes below a &amp;quot;low-water
mark&amp;quot;.&lt;/p&gt;
&lt;p&gt;After the regrtest change, test_recursionlimit_recovery() was called at stack
level 36. Before, it was called at level 35. The test triggers a RecursionError.
The problem is that we never goes again below the low-water mark, so the
overflow flag is never cleared.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-fix"&gt;
&lt;h3&gt;The fix&lt;/h3&gt;
&lt;p&gt;Another problem is that the function used to compute the &amp;quot;low-level mark&amp;quot; was
not monotonic:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if limit &amp;gt; 100:
    low_water_mark = limit - 50
else:
    low_water_mark = 3 * limit // 4
&lt;/pre&gt;
&lt;p&gt;The gap occurs near a limit of 100 frames:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;limit = 99 =&amp;gt; low_level_mark = 74&lt;/li&gt;
&lt;li&gt;limit = 100 =&amp;gt; low_level_mark = 75&lt;/li&gt;
&lt;li&gt;limit = 101 =&amp;gt; low_level_mark = 51&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The formula was replaced with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
if limit &amp;gt; 200:
    low_water_mark = limit - 50
else:
    low_water_mark = 3 * limit // 4
&lt;/pre&gt;
&lt;p&gt;The fix (&lt;a class="reference external" href="https://hg.python.org/cpython/rev/eb0c76442cee"&gt;change eb0c76442cee&lt;/a&gt;) modified the
&lt;tt class="docutils literal"&gt;sys.setrecursionlimit()&lt;/tt&gt; function to raise a &lt;tt class="docutils literal"&gt;RecursionError&lt;/tt&gt; exception if
the new limit is too low depending on the &lt;em&gt;current&lt;/em&gt; stack depth.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="optimizations"&gt;
&lt;h2&gt;Optimizations&lt;/h2&gt;
&lt;p&gt;As usual for performance, Serhiy Storchaka was very helpful on reviews, to run
independant benchmarks, etc.&lt;/p&gt;
&lt;p&gt;Optimizations on the &lt;tt class="docutils literal"&gt;bytes&lt;/tt&gt; type, ASCII, Latin1 and UTF-8 codecs:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #25318: Add _PyBytesWriter API. Add a new private API to optimize
Unicode encoders. It uses a small buffer of 512 bytes allocated on the stack
and supports configurable overallocation.&lt;/li&gt;
&lt;li&gt;Use _PyBytesWriter API for UCS1 (ASCII and Latin1) and UTF-8 encoders. Enable
overallocation for the UTF-8 encoder with error handlers.&lt;/li&gt;
&lt;li&gt;unicode_encode_ucs1(): initialize collend to collstart+1 to not check the
current character twice, we already know that it is not ASCII.&lt;/li&gt;
&lt;li&gt;Issue #25267: The UTF-8 encoder is now up to 75 times as fast for error
handlers: &lt;tt class="docutils literal"&gt;ignore&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;replace&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;surrogateescape&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;surrogatepass&lt;/tt&gt;.
Patch co-written with &lt;strong&gt;Serhiy Storchaka&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Issue #25301: The UTF-8 decoder is now up to 15 times as fast for error
handlers: &lt;tt class="docutils literal"&gt;ignore&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;replace&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;surrogateescape&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Issue #25318: Optimize backslashreplace and xmlcharrefreplace error handlers
in UTF-8 encoder. Optimize also backslashreplace error handler for ASCII and
Latin1 encoders.&lt;/li&gt;
&lt;li&gt;Issue #25349: Optimize bytes % args using the new private _PyBytesWriter API&lt;/li&gt;
&lt;li&gt;Optimize error handlers of ASCII and Latin1 encoders when the replacement
string is pure ASCII: use _PyBytesWriter_WriteBytes(), don't check individual
character.&lt;/li&gt;
&lt;li&gt;Issue #25349: Optimize bytes % int. Formatting is between 30% and 50% faster
on a microbenchmark.&lt;/li&gt;
&lt;li&gt;Issue #25357: Add an optional newline paramer to binascii.b2a_base64().
base64.b64encode() uses it to avoid a memory copy.&lt;/li&gt;
&lt;li&gt;Issue #25353: Optimize unicode escape and raw unicode escape encoders: use
the new _PyBytesWriter API.&lt;/li&gt;
&lt;li&gt;Rewrite PyBytes_FromFormatV() using _PyBytesWriter API&lt;/li&gt;
&lt;li&gt;Issue #25399: Optimize bytearray % args. Most formatting operations are now
between 2.5 and 5 times faster.&lt;/li&gt;
&lt;li&gt;Issue #25401: Optimize bytes.fromhex() and bytearray.fromhex(): they are now
between 2x and 3.5x faster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="changes"&gt;
&lt;h2&gt;Changes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #25003: On Solaris 11.3 or newer, os.urandom() now uses the getrandom()
function instead of the getentropy() function. The getentropy() function is
blocking to generate very good quality entropy, os.urandom() doesn't need
such high-quality entropy.&lt;/li&gt;
&lt;li&gt;Issue #22806: Add &lt;tt class="docutils literal"&gt;python &lt;span class="pre"&gt;-m&lt;/span&gt; test &lt;span class="pre"&gt;--list-tests&lt;/span&gt;&lt;/tt&gt; command to list tests.&lt;/li&gt;
&lt;li&gt;Issue #25670: Remove duplicate getattr() in ast.NodeTransformer&lt;/li&gt;
&lt;li&gt;Issue #25557: Refactor _PyDict_LoadGlobal(). Don't fallback to
PyDict_GetItemWithError() if the hash is unknown: compute the hash instead.
Add also comments to explain the _PyDict_LoadGlobal() optimization.&lt;/li&gt;
&lt;li&gt;Issue #25868: Try to make test_eintr.test_sigwaitinfo() more reliable
especially on slow buildbots&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="changes-specific-to-python-2-7"&gt;
&lt;h2&gt;Changes specific to Python 2.7&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Closes #25742: locale.setlocale() now accepts a Unicode string for its second
parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="bugfixes"&gt;
&lt;h2&gt;Bugfixes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Fix regrtest --coverage on Windows&lt;/li&gt;
&lt;li&gt;Fix pytime on OpenBSD&lt;/li&gt;
&lt;li&gt;More fixes for test_eintr on FreeBSD&lt;/li&gt;
&lt;li&gt;Close #25373: Fix regrtest --slow with interrupted test&lt;/li&gt;
&lt;li&gt;Issue #25555: Fix parser and AST: fill lineno and col_offset of &amp;quot;arg&amp;quot; node
when compiling AST from Python objects. First contribution related
to FAT Python ;-)&lt;/li&gt;
&lt;li&gt;Issue #25696: Fix installation of Python on UNIX with make -j9.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>My contributions to CPython during 2015 Q3</title><link href="https://haypo.github.io/contrib-cpython-2015q3.html" rel="alternate"></link><published>2016-02-18T01:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-02-18:contrib-cpython-2015q3.html</id><summary type="html">&lt;p&gt;A few years ago, someone asked me: &amp;quot;Why do you contribute to CPython? Python is
perfect, there are no more bugs, right?&amp;quot;. The article list most of my
contributions to CPython during 2015 Q3 (july, august, september). It gives an
idea of which areas of Python are not perfect yet :-)&lt;/p&gt;
&lt;p&gt;My contributions to &lt;a class="reference external" href="https://www.python.org/"&gt;CPython&lt;/a&gt; during 2015 Q3
(july, august, september):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
hg log -r 'date(&amp;quot;2015-07-01&amp;quot;):date(&amp;quot;2015-09-30&amp;quot;)' --no-merges -u Stinner
&lt;/pre&gt;
&lt;p&gt;Statistics: 153 non-merge commits + 75 merge commits (total: 228 commits).&lt;/p&gt;
&lt;p&gt;The major event in Python of this quarter was the release of Python 3.5.0.&lt;/p&gt;
&lt;p&gt;As usual, I helped various contributors to refine their changes and I pushed
their final changes.&lt;/p&gt;
&lt;div class="section" id="freebsd-kernel-bug"&gt;
&lt;h2&gt;FreeBSD kernel bug&lt;/h2&gt;
&lt;p&gt;It took me a while to polish the implementation of the &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0475/"&gt;PEP 475 (retry syscall
on EINTR)&lt;/a&gt; especially its unit
test &lt;tt class="docutils literal"&gt;test_eintr&lt;/tt&gt;. The unit test is supposed to test Python, but as usual,
it also tests indirectly the operating system.&lt;/p&gt;
&lt;p&gt;I spent some days investigating a random hang on the FreeBSD buildbots: &lt;a class="reference external" href="https://bugs.python.org/issue25122"&gt;issue
#25122&lt;/a&gt;. I quickly found the guilty test
(test_eintr.test_open), but it took me a while to understand that it was a
kernel bug in the FIFO driver. Hopefully at the end, I was able to reproduce
the bug with a short C program in my FreeBSD VM. It is the best way to ask a
fix upstream.&lt;/p&gt;
&lt;p&gt;My &lt;a class="reference external" href="https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=203162"&gt;FreeBSD bug report #203162&lt;/a&gt; (&amp;quot;when close(fd)
on a fifo fails with EINTR, the file descriptor is not really closed&amp;quot;) was
quickly fixed. The FreeBSD team is reactive!&lt;/p&gt;
&lt;p&gt;I like free softwares because it's possible to investigate bugs deep in the
code, and it's usually quick to get a fix.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="timestamp-rounding-issue"&gt;
&lt;h2&gt;Timestamp rounding issue&lt;/h2&gt;
&lt;p&gt;Even if the &lt;a class="reference external" href="http://bugs.python.org/issue23517"&gt;issue #23517&lt;/a&gt; is well defined
and simple to fix, it took me days (weeks?) to understand exactly how
timestamps are supposed to be rounded and agree on the &amp;quot;right&amp;quot; rounding method.
Alexander Belopolsky reminded me the important property:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(datetime(1970,1,1) + timedelta(seconds=t)) == datetime.utcfromtimestamp(t)
&lt;/pre&gt;
&lt;p&gt;Tim Peters helped me to understand why Python rounds to nearest with ties going
away from zero (ROUND_HALF_UP) in &lt;tt class="docutils literal"&gt;round(float)&lt;/tt&gt; and other functions. At
the first look, the rounding method doesn't look natural nor logical:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; round(0.5)
0
&amp;gt;&amp;gt;&amp;gt; round(1.5)
2
&lt;/pre&gt;
&lt;p&gt;See my previous article on the _PyTime API for the long story of rounding
methods between Python 3.2 and Python 3.6.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="enhancements"&gt;
&lt;h2&gt;Enhancements&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;type_call() now detect C bugs in type __new__() and __init__() methods.&lt;/li&gt;
&lt;li&gt;Issue #25220: Enhancements of the test runner: add more info when regrtest runs
tests in parallel, fix some features of regrtest, add functional tests to
test_regrtest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="optimizations"&gt;
&lt;h2&gt;Optimizations&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Issue #25227: Optimize ASCII and latin1 encoders with the &lt;tt class="docutils literal"&gt;surrogateescape&lt;/tt&gt;
error handler: the encoders are now up to 3 times as fast.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="changes"&gt;
&lt;h2&gt;Changes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Polish the implementation of the PEP 475 (retry syscall on EINTR)&lt;/li&gt;
&lt;li&gt;Work on the &amp;quot;What's New in Python 3.5&amp;quot; document: add my changes
(PEP 475, socket timeout, os.urandom)&lt;/li&gt;
&lt;li&gt;Work on asyncio: fix ResourceWarning warnings, fixes specific to Windows&lt;/li&gt;
&lt;li&gt;test_time: rewrite rounding tests of the private pytime API&lt;/li&gt;
&lt;li&gt;Issue #24707: Remove an assertion in monotonic clock. Don't check anymore at
runtime that the monotonic clock doesn't go backward.  Yes, it happens! It
occurs sometimes each month on a Debian buildbot slave running in a VM.&lt;/li&gt;
&lt;li&gt;test_eintr: replace os.fork() with subprocess (fork+exec) to make the test
more reliable&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="changes-specific-to-python-2-7"&gt;
&lt;h2&gt;Changes specific to Python 2.7&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Backport python-gdb.py changes: enhance py-bt command&lt;/li&gt;
&lt;li&gt;Issue #23375: Fix test_py3kwarn for modules implemented in C&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="bug-fixes"&gt;
&lt;h2&gt;Bug fixes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Closes #23247: Fix a crash in the StreamWriter.reset() of CJK codecs&lt;/li&gt;
&lt;li&gt;Issue #24732, #23834: Fix sock_accept_impl() on Windows. Regression of the
PEP 475 (retry syscall on EINTR)&lt;/li&gt;
&lt;li&gt;test_gdb: fix regex to parse the GDB version and fix ResourceWarning on error&lt;/li&gt;
&lt;li&gt;Fix test_warnings: don't modify warnings.filters to fix random failures of
the test.&lt;/li&gt;
&lt;li&gt;Issue #24891: Fix a race condition at Python startup if the file descriptor
of stdin (0), stdout (1) or stderr (2) is closed while Python is creating
sys.stdin, sys.stdout and sys.stderr objects.&lt;/li&gt;
&lt;li&gt;Issue #24684: socket.socket.getaddrinfo() now calls
PyUnicode_AsEncodedString() instead of calling the encode() method of the
host, to handle correctly custom string with an encode() method which doesn't
return a byte string. The encoder of the IDNA codec is now called directly
instead of calling the encode() method of the string.&lt;/li&gt;
&lt;li&gt;Issue #25118: Fix a regression of Python 3.5.0 in os.waitpid() on Windows.
Add an unit test on os.waitpid()&lt;/li&gt;
&lt;li&gt;Issue #25122: Fix test_eintr, kill child process on error&lt;/li&gt;
&lt;li&gt;Issue #25155: Add _PyTime_AsTimevalTime_t() function to fix a regression:
support again years after 2038.&lt;/li&gt;
&lt;li&gt;Issue #25150: Hide the private _Py_atomic_xxx symbols from the public
Python.h header to fix a compilation error with OpenMP. PyThreadState_GET()
becomes an alias to PyThreadState_Get() to avoid ABI incompatibilies.&lt;/li&gt;
&lt;li&gt;Issue #25003: On Solaris 11.3 or newer, os.urandom() now uses the getrandom()
function instead of the getentropy() function.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>History of the Python private C API _PyTime</title><link href="https://haypo.github.io/pytime.html" rel="alternate"></link><published>2016-02-17T22:00:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-02-17:pytime.html</id><summary type="html">&lt;p&gt;I added functions to the private &amp;quot;pytime&amp;quot; library to convert timestamps from/to
various formats. I expected to spend a few days, at the end I spent 3 years
(2012-2015) on them!&lt;/p&gt;
&lt;div class="section" id="python-3-3"&gt;
&lt;h2&gt;Python 3.3&lt;/h2&gt;
&lt;p&gt;In 2012, I proposed the &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0410/"&gt;PEP 410 -- Use decimal.Decimal type for timestamps&lt;/a&gt; because storing timestamps as
floating point numbers looses precision. The PEP was rejected because it
modified many functions and had a bad API. At least, os.stat() got 3 new fields
(atime_ns, mtime_ns, ctime_ns): timestamps  as a number of nanoseconds
(&lt;tt class="docutils literal"&gt;int&lt;/tt&gt;).&lt;/p&gt;
&lt;p&gt;My &lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0418/"&gt;PEP 418 -- Add monotonic time, performance counter, and process time
functions&lt;/a&gt; was accepted, Python
3.3 got a new &lt;tt class="docutils literal"&gt;time.monotonic()&lt;/tt&gt; function (and a few others). Again, I spent
much more time than I expected on a problem which looked simple at the first
look.&lt;/p&gt;
&lt;p&gt;With the &lt;a class="reference external" href="http://bugs.python.org/issue14180"&gt;issue #14180&lt;/a&gt;, I added functions
to convert timestamps to the private &amp;quot;pytime&amp;quot; API to factorize the code of
various modules. Timestamps were rounded towards +infinity (ROUND_CEILING), but
it was not a deliberate choice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-4"&gt;
&lt;h2&gt;Python 3.4&lt;/h2&gt;
&lt;p&gt;To fix correctly a performance issue in asyncio (&lt;a class="reference external" href="https://bugs.python.org/issue20311"&gt;issue20311&lt;/a&gt;), I added two rounding modes to the
pytime API: _PyTime_ROUND_DOWN (round towards zero), and _PyTime_ROUND_UP
(round away from zero). Polling for events (ex: using &lt;tt class="docutils literal"&gt;select.select()&lt;/tt&gt;) with
a non-zero timestamp must not call the underlying C level in non-blocking mode.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-5"&gt;
&lt;h2&gt;Python 3.5&lt;/h2&gt;
&lt;p&gt;When working on the &lt;a class="reference external" href="https://bugs.python.org/issue22117"&gt;issue #22117&lt;/a&gt;, I
noticed that the implementation of rounding methods was buggy for negative
timestamps. I replaced the _PyTime_ROUND_DOWN with _PyTime_ROUND_FLOOR (round
towards minus infinity), and _PyTime_ROUND_UP with _PyTime_ROUND_CEILING (round
towards infinity).&lt;/p&gt;
&lt;p&gt;This issue also introduced a new private &lt;tt class="docutils literal"&gt;_PyTime_t&lt;/tt&gt; type to support
nanosecond resolution.  The type is an opaque integer type to store timestamps.
In practice, it's a signed 64-bit integer. Since it's an integer, it's easy and
natural to compute the sum or differecence of two timestamps: &lt;tt class="docutils literal"&gt;t1 + t2&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;t2 - t1&lt;/tt&gt;. I added _PyTime_XXX() functions to create a timestamp and
_PyTime_AsXXX() functions to convert a timestamp to a different format.&lt;/p&gt;
&lt;p&gt;I had to keep three _PyTime_ObjectToXXX() functions for fromtimestamp() methods
of the datetime module. These methods must support extreme timestamps (year
1..9999), whereas _PyTime_t is &amp;quot;limited&amp;quot; to a delta of +/- 292 years (year
1678..2262).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-3-6"&gt;
&lt;h2&gt;Python 3.6&lt;/h2&gt;
&lt;p&gt;In 2015, the &lt;a class="reference external" href="http://bugs.python.org/issue23517"&gt;issue #23517&lt;/a&gt; reported that
Python 2 and Python 3 don't use the same rounding method in
datetime.datetime.fromtimestamp(): there was a difference of 1 microsecond.&lt;/p&gt;
&lt;p&gt;After a long discussion, I modified fromtimestamp() methods of the datetime
module to round to nearest with ties going away from zero (ROUND_HALF_UP), as
done in Python 2.7, as round() in all Python versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It took me three years to stabilize the API and fix all issues. Well, I didn't
spend all my days on it, but it shows that handling time is not a simple issue.&lt;/p&gt;
&lt;p&gt;At the Python level, nothing changed, timestamps are still stored as float
(except of the 3 new fieleds of os.stat()).&lt;/p&gt;
&lt;p&gt;Python 3.5 only supports timezones with fixed offset, it does not support the
locale timestamp for example. Timezones are still an hot topic: the
&lt;a class="reference external" href="https://mail.python.org/mailman/listinfo/datetime-sig"&gt;datetime-sig mailing list&lt;/a&gt; was created to
enhance timezone support in Python.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="cpython"></category></entry><entry><title>Status of the FAT Python project, January 12, 2016</title><link href="https://haypo.github.io/fat-python-status-janv12-2016.html" rel="alternate"></link><published>2016-01-12T13:42:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2016-01-12:fat-python-status-janv12-2016.html</id><summary type="html">&lt;a class="reference external image-reference" href="http://faster-cpython.readthedocs.org/fat_python.html"&gt;&lt;img alt="FAT Python project" class="align-right" src="https://haypo.github.io/images/fat_python.jpg" /&gt;&lt;/a&gt;
&lt;p&gt;Previous status: &lt;a class="reference external" href="https://haypo.github.io/fat-python-status-nov26-2015.html"&gt;Status of the FAT Python project, November 26, 2015&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;New optimizations implemented:&lt;ul&gt;
&lt;li&gt;constant propagation&lt;/li&gt;
&lt;li&gt;constant folding&lt;/li&gt;
&lt;li&gt;dead code elimination&lt;/li&gt;
&lt;li&gt;simplify iterable&lt;/li&gt;
&lt;li&gt;replace builtin __debug__ variable with its value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Major API refactoring to make the API more generic and reusable by other
projects, and maybe different use case.&lt;/li&gt;
&lt;li&gt;Work on 3 different Python Enhancement Proposals (PEP): API for pluggable
static optimizers and function specialization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The two previously known major bugs, &amp;quot;Wrong Line Numbers (and Tracebacks)&amp;quot; and
&amp;quot;exec(code, dict)&amp;quot;, are now fixed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-enhancement-proposals-pep"&gt;
&lt;h2&gt;Python Enhancement Proposals (PEP)&lt;/h2&gt;
&lt;p&gt;I proposed an API for to support function specialization and static optimizers.
I splitted changes in 3 different Python Enhancement Proposals (PEP):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0509/"&gt;PEP 509 - Add a private version to dict&lt;/a&gt;: &amp;quot;Add a new private version to
builtin &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt; type, incremented at each change, to implement fast guards
on namespaces.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0510/"&gt;PEP 510 - Specialize functions&lt;/a&gt;: &amp;quot;Add functions to the Python C
API to specialize pure Python functions: add specialized codes with guards.
It allows to implement static optimizers respecting the Python semantics.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.python.org/dev/peps/pep-0511/"&gt;PEP 511 - API for AST transformers&lt;/a&gt;: &amp;quot;Propose an API to
support AST transformers.&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The PEP 509 was sent to the python-ideas mailing list for a first round, and
then to python-dev mailing list.  The PEP 510 was sent to python-ideas to a
first round. The last PEP was not published yet, I'm still working on it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="major-api-refactor"&gt;
&lt;h2&gt;Major API refactor&lt;/h2&gt;
&lt;p&gt;The API has been deeply refactored to write the Python Enhancement Proposals.&lt;/p&gt;
&lt;p&gt;First set of changes for function specialization (PEP 510):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;astoptimizer now adds &lt;tt class="docutils literal"&gt;import fat&lt;/tt&gt; to optimized code when specialization is
used&lt;/li&gt;
&lt;li&gt;Remove the function subtype: add directly the &lt;tt class="docutils literal"&gt;specialize()&lt;/tt&gt; method to
functions&lt;/li&gt;
&lt;li&gt;Add support of any callable object to &lt;tt class="docutils literal"&gt;func.specialize()&lt;/tt&gt;, not only code
object (bytecode)&lt;/li&gt;
&lt;li&gt;Create guard objects:&lt;ul&gt;
&lt;li&gt;fat.Guard&lt;/li&gt;
&lt;li&gt;fat.GuardArgType&lt;/li&gt;
&lt;li&gt;fat.GuardBuiltins&lt;/li&gt;
&lt;li&gt;fat.GuardDict&lt;/li&gt;
&lt;li&gt;fat.GuardFunc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Add functions to create guards:&lt;ul&gt;
&lt;li&gt;fat.GuardGlobals&lt;/li&gt;
&lt;li&gt;fat.GuardTypeDict&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Move code.replace_consts() to fat.replace_consts()&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Second set of changes for AST transformers (PEP 511):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Add sys.implementation.ast_transformers and sys.implementation.optim_tag&lt;/li&gt;
&lt;li&gt;Rename sys.asthook to sys.ast_transformers&lt;/li&gt;
&lt;li&gt;Add -X fat command line option to enable the FAT mode: register the
astoptimizer in AST transformers&lt;/li&gt;
&lt;li&gt;Replace -F command line option with -o OPTIM_TAG&lt;/li&gt;
&lt;li&gt;Remove sys.flags.fat (Python flag) and Py_FatPython (C variable)&lt;/li&gt;
&lt;li&gt;Rewrite how an AST transformer is registered&lt;/li&gt;
&lt;li&gt;importlib skips .py if optim_tag is not 'opt' and required AST transformers
are missing. Raise ImportError if the .pyc file is missing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Third set of changes for dictionary versionning, updates after the first round
of the PEP 509 on python-ideas:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Remove dict.__version__ read-only property: the version is now only
accessible from the C API&lt;/li&gt;
&lt;li&gt;Change the type of the C field &lt;tt class="docutils literal"&gt;ma_version&lt;/tt&gt; from &lt;tt class="docutils literal"&gt;size_t&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;unsigned
PY_INT64_T&lt;/tt&gt; to also use 64-bit unsigned integer on 32-bit platforms. The
risk of missing a change in a guard with a 32-bit version is too high,
whereas the risk with a 64-bit version is very very low.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fourth set of changes for function specialization, updates after the first round
of the PEP 510 on python-ideas:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Remove func.specialize() and func.get_specialized() at the Python level,
replace them with C functions. Expose them again as fat.specialize(func, ...)
and fat.get_specialized(func)&lt;/li&gt;
&lt;li&gt;fat.get_specialized() now returns a list of tuples, instead of a list of dict&lt;/li&gt;
&lt;li&gt;Make fat.Guard type private: rename it to fat._Guard&lt;/li&gt;
&lt;li&gt;Add fat.PyGuard: toy to implement a guard in pure Python&lt;/li&gt;
&lt;li&gt;Guard C API: rename first_check to init and support reporting errors&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="change-log"&gt;
&lt;h2&gt;Change log&lt;/h2&gt;
&lt;p&gt;Detailed changes of the FAT Python between November 24, 2015 and January 12,
2016.&lt;/p&gt;
&lt;div class="section" id="end-of-november"&gt;
&lt;h3&gt;End of november&lt;/h3&gt;
&lt;p&gt;Major change:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Add a __version__ read-only property to dict, remove the verdict subtype of
dict. As a consequence, dictionary guards now hold a strong reference to the
dict value&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Minor changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Allocate dynamically memory for specialized code and guards, don't use fixed-size
arrays anymore&lt;/li&gt;
&lt;li&gt;astoptimizer: enhance scope detection&lt;/li&gt;
&lt;li&gt;optimize astoptimizer: don't copy a whole AST tree anymore with
copy.deepcopy(), only copy modified nodes.&lt;/li&gt;
&lt;li&gt;Add Config.max_constant_size&lt;/li&gt;
&lt;li&gt;Reenable checks on cell variables: allow cell variables if they are the same&lt;/li&gt;
&lt;li&gt;Reenable optimizations on methods calling super(), but never copy super()
builtin to constants. If super() is replaced with a string, the required free
variable (reference to the current class) is not created by the compiler&lt;/li&gt;
&lt;li&gt;Add PureBuiltin config&lt;/li&gt;
&lt;li&gt;NodeVisitor now calls generic_visit() before visit_XXX()&lt;/li&gt;
&lt;li&gt;Loop unrolling now also optimizes tuple iterators&lt;/li&gt;
&lt;li&gt;At the end of Python initialization, create a copy of the builtins dictionary
to be able later to detect if a builtin name was replaced.&lt;/li&gt;
&lt;li&gt;Implement collections.UserDict.__version__&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="december-first-half"&gt;
&lt;h3&gt;December (first half)&lt;/h3&gt;
&lt;p&gt;Major changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Implement 4 new optimizations:&lt;ul&gt;
&lt;li&gt;constant propagation&lt;/li&gt;
&lt;li&gt;constant folding&lt;/li&gt;
&lt;li&gt;replace builtin __debug__ variable with its value&lt;/li&gt;
&lt;li&gt;dead code elimination&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Add support of per module configuration using an __astoptimizer__ variable&lt;/li&gt;
&lt;li&gt;code.co_lnotab now supports negative line number delta.  Change the type of
line number delta in co_lnotab from unsigned 8-bit integer to signed 8-bit
integer. This change fixes almost all issues about line numbers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Minor changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Change .pyc magic number to 3600&lt;/li&gt;
&lt;li&gt;Remove unused fat.specialized_method() function&lt;/li&gt;
&lt;li&gt;Remove Lib/fat.py, rename Modules/_fat.c to Modules/fat.c: fat module is now
only implemented in C&lt;/li&gt;
&lt;li&gt;Fix more tests of the Python test suite&lt;/li&gt;
&lt;li&gt;A builtin guard now adds a guard on globals. Ignore also the specialization
if globals()[name] already exists.&lt;/li&gt;
&lt;li&gt;Ignore duplicated guards&lt;/li&gt;
&lt;li&gt;Implement namespace following the control flow for constant propagation&lt;/li&gt;
&lt;li&gt;Config.max_int_bits becomes a simple integer&lt;/li&gt;
&lt;li&gt;Fix bytecode compilation for tuple constants. Don't merge (0, 0) and (0.0,
0.0) constants, they are different.&lt;/li&gt;
&lt;li&gt;Call more builtin functions&lt;/li&gt;
&lt;li&gt;Optimize the optimizer: write a metaclass to discover visitors when the class
is created, not when the class is instanciated&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="december-second-half"&gt;
&lt;h3&gt;December (second half)&lt;/h3&gt;
&lt;p&gt;Major changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Implement &amp;quot;simplify iterable&amp;quot; optimization. The loop unrolling optimization
now relies on it to replace &lt;tt class="docutils literal"&gt;range(n)&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Split the function optimization in two stages: first apply optimizations
which don't require specialization, then apply optimizations which
require specialization.&lt;/li&gt;
&lt;li&gt;Replace the builtin __fat__ variable with a new sys.flags.fat flag&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Minor changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Extend optimizations to optimize more cases (more builtins, more loop
unrolling, remove more dead code, etc.)&lt;/li&gt;
&lt;li&gt;Add Config.logger attribute. astoptimize logs into sys.stderr when Python is
started in verbose mode (python3 -v)&lt;/li&gt;
&lt;li&gt;Move func.patch_constants() to code.replace_consts()&lt;/li&gt;
&lt;li&gt;Enhance marshal to fix tests: call frozenset() to get the empty frozenset
singleton&lt;/li&gt;
&lt;li&gt;Don't remove code which must raise a SyntaxError. Don't remove code
containing the continue instruction.&lt;/li&gt;
&lt;li&gt;Restrict GlobalNonlocalVisitor to the current namespace&lt;/li&gt;
&lt;li&gt;Emit logs when optimizations are skipped&lt;/li&gt;
&lt;li&gt;Use some maths to avoid optimization pow() if result is an integer and will
be larger than the configuration. For example, don't optimize 2 ** (2**100).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="january"&gt;
&lt;h3&gt;January&lt;/h3&gt;
&lt;p&gt;Major changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;astoptimizer now produces a single builtin guard with all names,
instead of a guard per name.&lt;/li&gt;
&lt;li&gt;Major API refactoring detailed in a dedicated section above&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Minor changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Start to write PEPs&lt;/li&gt;
&lt;li&gt;Dictionary guards now expect a list of names, instead of a single name, to
reduce the cost of guards.&lt;/li&gt;
&lt;li&gt;GuardFunc now uses a strong reference to the function, instead of a weak
reference to simplify the code&lt;/li&gt;
&lt;li&gt;Initialize dictionary version to 0&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="fatpython"></category></entry><entry><title>Status of the FAT Python project, November 26, 2015</title><link href="https://haypo.github.io/fat-python-status-nov26-2015.html" rel="alternate"></link><published>2015-11-26T17:30:00+01:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2015-11-26:fat-python-status-nov26-2015.html</id><summary type="html">&lt;a class="reference external image-reference" href="http://faster-cpython.readthedocs.org/fat_python.html"&gt;&lt;img alt="FAT Python project" class="align-right" src="https://haypo.github.io/images/fat_python.jpg" /&gt;&lt;/a&gt;
&lt;p&gt;Previous status: [python-dev] &lt;a class="reference external" href="https://mail.python.org/pipermail/python-dev/2015-November/142113.html"&gt;Second milestone of FAT Python&lt;/a&gt;
(Nov 4, 2015).&lt;/p&gt;
&lt;div class="section" id="documentation"&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;
&lt;p&gt;I combined the documentation of various optimizations projects into a single
documentation: &lt;a class="reference external" href="http://faster-cpython.readthedocs.org/"&gt;Faster CPython&lt;/a&gt;.
My previous optimizations projects:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://faster-cpython.readthedocs.org/old_ast_optimizer.html"&gt;&amp;quot;old&amp;quot; astoptimizer&lt;/a&gt; (now
replaced with a &amp;quot;new&amp;quot; astoptimizer included in the FAT Python)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://faster-cpython.readthedocs.org/registervm.html"&gt;registervm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://faster-cpython.readthedocs.org/readonly.html"&gt;read-only Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The FAT Python project has its own page: &lt;a class="reference external" href="http://faster-cpython.readthedocs.org/fat_python.html"&gt;FAT Python project&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="copy-builtins-to-constants-optimization"&gt;
&lt;h2&gt;Copy builtins to constants optimization&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;LOAD_GLOBAL&lt;/tt&gt; instruction is used to load a builtin function.  The
instruction requires two dictionary lookup: one in the global namespace (which
almost always fail) and then in the builtin namespaces.&lt;/p&gt;
&lt;p&gt;It's rare to replace builtins, so the idea here is to replace the dynamic
&lt;tt class="docutils literal"&gt;LOAD_GLOBAL&lt;/tt&gt; instruction with a static &lt;tt class="docutils literal"&gt;LOAD_CONST&lt;/tt&gt; instruction which
loads the function from a C array, a fast O(1) lookup.&lt;/p&gt;
&lt;p&gt;It is not possible to inject a builtin function during the compilation. Python
code objects are serialized by the marshal module which only support simple
types like integers, strings and tuples, not functions. The trick is to modify
the constants at runtime when the module is loaded. I added a new
&lt;tt class="docutils literal"&gt;patch_constants()&lt;/tt&gt; method to functions.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def log(message):
    print(message)
&lt;/pre&gt;
&lt;p&gt;This function is specialized to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def log(message):
    'LOAD_GLOBAL print'(message)
log.patch_constants({'LOAD_GLOBAL print': print})
&lt;/pre&gt;
&lt;p&gt;The specialized bytecode uses two guards on builtin and global namespaces to
disable the optimization if the builtin function is replaced.&lt;/p&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://faster-cpython.readthedocs.org/fat_python.html#copy-builtin-functions-to-constants"&gt;Copy builtin functions to constants&lt;/a&gt;
for more information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="loop-unrolling-optimization"&gt;
&lt;h2&gt;Loop unrolling optimization&lt;/h2&gt;
&lt;p&gt;A simple optimization is to &amp;quot;unroll&amp;quot; a loop to reduce the cost of loops. The
optimization generates assignement statements (for the loop index variable)
and duplicates the loop body.&lt;/p&gt;
&lt;p&gt;Example with a &lt;tt class="docutils literal"&gt;range()&lt;/tt&gt; iterator:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def func():
    for i in (1, 2, 3):
        print(i)
&lt;/pre&gt;
&lt;p&gt;The function is specialized to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def func():
    i = 1
    print(i)

    i = 2
    print(i)

    i = 3
    print(i)
&lt;/pre&gt;
&lt;p&gt;If the iterator uses the builtin &lt;tt class="docutils literal"&gt;range&lt;/tt&gt; function, two guards are
required on builtin and global namespaces.&lt;/p&gt;
&lt;p&gt;The optimization also handles tuple iterator. No guard is needed in this case
(the code is always optimized).&lt;/p&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://faster-cpython.readthedocs.org/fat_python.html#loop-unrolling"&gt;Loop unrolling&lt;/a&gt;
for more information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lot-of-enhancements-of-the-ast-optimizer"&gt;
&lt;h2&gt;Lot of enhancements of the AST optimizer&lt;/h2&gt;
&lt;p&gt;New optimizations helped to find bugs in the &lt;a class="reference external" href="https://faster-cpython.readthedocs.org/new_ast_optimizer.html"&gt;AST optimizer&lt;/a&gt;. Many fixes
and various enhancements were done in the AST optimizer.&lt;/p&gt;
&lt;p&gt;The number of lines of code more than doubled: 500 to 1200 lines.&lt;/p&gt;
&lt;p&gt;Optimization: &lt;tt class="docutils literal"&gt;copy.deepcopy()&lt;/tt&gt; is no more used to duplicate a full tree. The
new &lt;tt class="docutils literal"&gt;NodeTransformer&lt;/tt&gt; class now only copies a single node, if at least one
field is modified.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;VariableVisitor&lt;/tt&gt; class which detects local and global variables was
heavily modified. It understands much more kinds of AST node: &lt;tt class="docutils literal"&gt;For&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;AugAssign&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;AsyncFunctionDef&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;ClassDef&lt;/tt&gt;, etc. It now also detects non-local
variables (&lt;tt class="docutils literal"&gt;nonlocal&lt;/tt&gt; keyword). The scope is now limited to the current
function, it doesn't enter inside nested &lt;tt class="docutils literal"&gt;DictComp&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;FunctionDef&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;Lambda&lt;/tt&gt;, etc. These nodes create a new separated namespace.&lt;/p&gt;
&lt;p&gt;The optimizer is now able to optimize a function without guards: it's needed to
unroll a loop using a tuple as iterator.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="known-bugs"&gt;
&lt;h2&gt;Known bugs&lt;/h2&gt;
&lt;p&gt;See the &lt;a class="reference external" href="https://hg.python.org/sandbox/fatpython/file/0d30dba5fa64/TODO.rst"&gt;TODO.rst file&lt;/a&gt; for
known bugs.&lt;/p&gt;
&lt;div class="section" id="wrong-line-numbers-and-tracebacks"&gt;
&lt;h3&gt;Wrong Line Numbers (and Tracebacks)&lt;/h3&gt;
&lt;p&gt;AST nodes have &lt;tt class="docutils literal"&gt;lineno&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;col_offset&lt;/tt&gt; fields, so an AST optimizer is not
&amp;quot;supposed&amp;quot; to break line numbers. In practice, line numbers, and so tracebacks,
are completly wrong in FAT mode. The problem is probably that AST optimizer can
copy and move instructions. Line numbers are no more motononic. CPython
probably don't handle this case (negative line delta).&lt;/p&gt;
&lt;p&gt;It should be possible to fix it, but right now I prefer to focus on new
optimizations and fix other bugs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="exec-code-dict"&gt;
&lt;h3&gt;exec(code, dict)&lt;/h3&gt;
&lt;p&gt;In FAT mode, some optimizations require guards on the global namespace.
If &lt;tt class="docutils literal"&gt;exec()&lt;/tt&gt; if called with a Python &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt; for globals, an exception
is raised because &lt;tt class="docutils literal"&gt;func.specialize()&lt;/tt&gt; requires a &lt;tt class="docutils literal"&gt;fat.verdict&lt;/tt&gt; for
globals.&lt;/p&gt;
&lt;p&gt;It's not possible to convert implicitly the &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt; to a &lt;tt class="docutils literal"&gt;fat.verdict&lt;/tt&gt;,
because the &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt; is expected to be mutated, and the guards be will on
&lt;tt class="docutils literal"&gt;fat.verdict&lt;/tt&gt; not on the original &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;I worked around the bug by creating manually a &lt;tt class="docutils literal"&gt;fat.verdict&lt;/tt&gt; in FAT mode,
instead of a &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;This bug will go avoid if the versionning feature is moved directly into
the builtin &lt;tt class="docutils literal"&gt;dict&lt;/tt&gt; type (and the &lt;tt class="docutils literal"&gt;fat.verdict&lt;/tt&gt; type is removed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="optimization"></category><category term="fatpython"></category></entry><entry><title>Port your Python 2 applications to Python 3 with sixer</title><link href="https://haypo.github.io/python3-sixer.html" rel="alternate"></link><published>2015-06-16T15:00:00+02:00</published><author><name>Victor Stinner</name></author><id>tag:haypo.github.io,2015-06-16:python3-sixer.html</id><summary type="html">&lt;div class="section" id="from-2to3-to-2to6"&gt;
&lt;h2&gt;From 2to3 to 2to6&lt;/h2&gt;
&lt;p&gt;When Python 3.0 was released, the official statement was to port your
application using &lt;a class="reference external" href="https://docs.python.org/3.5/library/2to3.html"&gt;2to3&lt;/a&gt; and
drop Python 2 support. It didn't work because you had to port all libraries
first. If a library drops Python 2 support, existing applications running on
Python 2 cannot use this library anymore.&lt;/p&gt;
&lt;p&gt;This chicken-and-egg issue was solved by the creation of the &lt;a class="reference external" href="https://pythonhosted.org/six/"&gt;six module&lt;/a&gt; by &lt;a class="reference external" href="https://benjamin.pe/"&gt;Benjamin Peterson&lt;/a&gt;. Thank you so much Benjamin! Using the six module, it
is possible to write a single code base working on Python 2 and Python 3.&lt;/p&gt;
&lt;p&gt;2to3 was hacked to create the &lt;a class="reference external" href="http://python-modernize.readthedocs.org/"&gt;modernize&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/limodou/2to6"&gt;2to6&lt;/a&gt; projects to &lt;em&gt;add Python 3 support&lt;/em&gt; without
loosing Python 2 support. Problem solved!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="creation-of-the-sixer-tool"&gt;
&lt;h2&gt;Creation of the sixer tool&lt;/h2&gt;
&lt;p&gt;Problem solved? Well, not for my specific use case. I'm porting the huge
OpenStack project to Python 3. modernize and 2to6 modify a lot of things at
once, add unwanted changes (ex: add &lt;tt class="docutils literal"&gt;from __future__ import absolute_import&lt;/tt&gt;
at the top of each file), and don't respect the OpenStack coding style
(especially the &lt;a class="reference external" href="http://docs.openstack.org/developer/hacking/#imports"&gt;complex rules to sort and group Python imports&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I wrote the &lt;a class="reference external" href="https://pypi.python.org/pypi/sixer"&gt;sixer&lt;/a&gt; project to
&lt;em&gt;generate&lt;/em&gt; patches for OpenStack. The problem is that OpenStack code changes
very quickly, so it's common to have to fix conflicts the day after submiting
a change. At the beginning, it took at least one week to get Python 3 changes
merged, whereas many changes are merged every day, so being able to regenerate
patches helped a lot.&lt;/p&gt;
&lt;p&gt;I created the &lt;a class="reference external" href="https://pypi.python.org/pypi/sixer"&gt;sixer&lt;/a&gt; tool using a list
of regular expressions to replace a pattern with another. For example, it
replaces &lt;tt class="docutils literal"&gt;dict.itervalues()&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;six.itervalues(dict)&lt;/tt&gt;. The code was
very simple.  The most difficult part was to respect the OpenStack coding
style for Python imports.&lt;/p&gt;
&lt;p&gt;sixer is a success since its creationg, it helped me to fix the all obvious
Python 3 issues: replace &lt;tt class="docutils literal"&gt;unicode(x)&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;six.text_type(x)&lt;/tt&gt;, replace
&lt;tt class="docutils literal"&gt;dict.itervalues()&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;six.itervalues(dict)&lt;/tt&gt;, etc. These changes are
simple, but it's boring to have to modify manually many files. The OpenStack
Nova project has almost 1500 Python files for example.&lt;/p&gt;
&lt;p&gt;The development version of sixer supports the following operations:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;all&lt;/li&gt;
&lt;li&gt;basestring&lt;/li&gt;
&lt;li&gt;dict0&lt;/li&gt;
&lt;li&gt;dict_add&lt;/li&gt;
&lt;li&gt;iteritems&lt;/li&gt;
&lt;li&gt;iterkeys&lt;/li&gt;
&lt;li&gt;itertools&lt;/li&gt;
&lt;li&gt;itervalues&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;next&lt;/li&gt;
&lt;li&gt;raise&lt;/li&gt;
&lt;li&gt;six_moves&lt;/li&gt;
&lt;li&gt;stringio&lt;/li&gt;
&lt;li&gt;unicode&lt;/li&gt;
&lt;li&gt;urllib&lt;/li&gt;
&lt;li&gt;xrange&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="creation-of-the-sixer-test-suite"&gt;
&lt;h2&gt;Creation of the Sixer Test Suite&lt;/h2&gt;
&lt;p&gt;Slowly, I added more and more patterns to sixer. The code became too complex
to be able to check regressions manually, so I also started to write unit
tests. Now each operation has at least one unit test. Some complex operations
have four tests or more.&lt;/p&gt;
&lt;p&gt;At the beginning, tests called directly the Python function. It is fast and
convenient, but it failed to catch regressions on the command line program.
So I added tests running sixer has a blackbox: pass an input file and check
the output file. Then I added specific tests on the code parsing command line
options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-new-all-operation"&gt;
&lt;h2&gt;The new &amp;quot;all&amp;quot; operation&lt;/h2&gt;
&lt;p&gt;At the beginning, I used sixer to generate a patch for a single pattern. For
example, replace &lt;tt class="docutils literal"&gt;unicode()&lt;/tt&gt; in a whole project.&lt;/p&gt;
&lt;p&gt;Later, I started to use it differently: I fixed all Python 3 issues at once,
but only in some selected files. I did that when we reached a minimum set of
tests which pass on Python 3 to have a green py34 check on Jenkins. Then we
ported tests one by one. It's better to write short patches, they are easier
and faster to review. And the review process is the bottlebeck of the
OpenStack development process.&lt;/p&gt;
&lt;p&gt;To fix all Python 3 at once, I added an &lt;tt class="docutils literal"&gt;all&lt;/tt&gt; operation which simply applies
sequentially each operation. So &lt;tt class="docutils literal"&gt;sixer&lt;/tt&gt; can now be used as &lt;tt class="docutils literal"&gt;modernize&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;2to6&lt;/tt&gt; to fix all Python 3 issues at once in a whole project.&lt;/p&gt;
&lt;p&gt;I also added the ability to pass filenames instead of having to pass a
directory to modify all files in all subdirectories.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="new-urllib-six-moves-and-stringio-operations"&gt;
&lt;h2&gt;New urllib, six_moves and stringio operations&lt;/h2&gt;
&lt;div class="section" id="urllib"&gt;
&lt;h3&gt;urllib&lt;/h3&gt;
&lt;p&gt;I tried to keep the sixer code simple. But some changes are boring to write,
like replacing &lt;tt class="docutils literal"&gt;urllib&lt;/tt&gt; imports &lt;tt class="docutils literal"&gt;six.moves.urllib&lt;/tt&gt; imports. Python 2 has 3
modules (&lt;tt class="docutils literal"&gt;urllib&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;urllib2&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;urlparse&lt;/tt&gt;), whereas Pytohn 3 uses a
single &lt;tt class="docutils literal"&gt;urllib&lt;/tt&gt; namespace with submodules (&lt;tt class="docutils literal"&gt;urllib.request&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;urllib.parse&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;urllib.error&lt;/tt&gt;). Some Python 2 functions moved to one
submodule, whereas others moved to another submodules. It required to know
well the old and new layout.&lt;/p&gt;
&lt;p&gt;After loosing many hours to write manually patches for &lt;tt class="docutils literal"&gt;urllib&lt;/tt&gt;, I decided
to add a &lt;tt class="docutils literal"&gt;urllib&lt;/tt&gt; operation. In fact, it was so not long to implement it,
compared to the time taken to write patches manually.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stringio"&gt;
&lt;h3&gt;stringio&lt;/h3&gt;
&lt;p&gt;Handling StringIO is also a little bit tricky because String.StringIO and
String.cStringIO don't have the same performance on Python 2. Producing
patches without killing performances require to pick the right module or
symbol from six: &lt;tt class="docutils literal"&gt;six.StringIO()&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;six.moves.cStringIO.StringIO&lt;/tt&gt; for
example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="six-moves"&gt;
&lt;h3&gt;six_moves&lt;/h3&gt;
&lt;p&gt;The generic &lt;tt class="docutils literal"&gt;six_moves&lt;/tt&gt; operation replaces various Python 2 imports with
imports from &lt;tt class="docutils literal"&gt;six.moves&lt;/tt&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;BaseHTTPServer&lt;/li&gt;
&lt;li&gt;ConfigParser&lt;/li&gt;
&lt;li&gt;Cookie&lt;/li&gt;
&lt;li&gt;HTMLParser&lt;/li&gt;
&lt;li&gt;Queue&lt;/li&gt;
&lt;li&gt;SimpleHTTPServer&lt;/li&gt;
&lt;li&gt;SimpleXMLRPCServer&lt;/li&gt;
&lt;li&gt;__builtin__&lt;/li&gt;
&lt;li&gt;cPickle&lt;/li&gt;
&lt;li&gt;cookielib&lt;/li&gt;
&lt;li&gt;htmlentitydefs&lt;/li&gt;
&lt;li&gt;httplib&lt;/li&gt;
&lt;li&gt;repr&lt;/li&gt;
&lt;li&gt;xmlrpclib&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="kiss-emit-warnings-instead-of-complex-implementation"&gt;
&lt;h2&gt;KISS: emit warnings instead of complex implementation&lt;/h2&gt;
&lt;p&gt;As I wrote, I tried to keep sixer simple (KISS principle: Keep It Simple,
Stupid). I'm also lazy, I didn't try to write a perfect tool. I don't want to
spend hours on the sixer project.&lt;/p&gt;
&lt;p&gt;When it was too tricky to make a decision or to implement a pattern, sixer
emits &amp;quot;warnings&amp;quot; instead. For example, a warning is emitted on
&lt;tt class="docutils literal"&gt;def next(self):&lt;/tt&gt; to remind that a &lt;tt class="docutils literal"&gt;__next__ = next&lt;/tt&gt; alias is probably
needed on this class for Python 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The sixer tool is incomplete and generates invalid changes. For example, it
replaces patterns in comments, docstrings and strings, whereas usually these
changes don't make sense. But I'm happy because the tool helped me a lot
for to port OpenStack, it saved me hours.&lt;/p&gt;
&lt;p&gt;I hope that the tool will now be useful to others! Don't hesitate to give me
feedback.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="python3"></category><category term="sixer"></category></entry></feed>