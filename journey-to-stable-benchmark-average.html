<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>My journey to stable benchmark, part 3 (average)</title>
        <link rel="stylesheet" href="https://haypo.github.io/theme/css/main.css" />
        <link href="https://haypo.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Haypo blog 2 Atom Feed" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://haypo.github.io/">Haypo blog 2 </a></h1>
                <nav><ul>
                    <li class="active"><a href="https://haypo.github.io/category/python.html">python</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="https://haypo.github.io/journey-to-stable-benchmark-average.html" rel="bookmark"
           title="Permalink to My journey to stable benchmark, part 3 (average)">My journey to stable benchmark, part 3 (average)</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-05-23T23:00:00+02:00">
                Published: lun. 23 mai 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://haypo.github.io/author/victor-stinner.html">Victor Stinner</a>
        </address>
<p>In <a href="https://haypo.github.io/category/python.html">python</a>.</p>
<p>tags: <a href="https://haypo.github.io/tag/optimization.html">optimization</a> <a href="https://haypo.github.io/tag/benchmark.html">benchmark</a> </p>
</footer><!-- /.post-info -->      <a class="reference external image-reference" href="https://www.flickr.com/photos/stanzim/11100202065/"><img alt="Fog" src="images/fog.jpg" /></a>
<p><em>Stable benchmarks are so close, but ...</em></p>
<div class="section" id="address-space-layout-randomization">
<h2>Address Space Layout Randomization</h2>
<p>When I started to work on removing the noise of the system, I was told that
disabling <a class="reference external" href="https://en.wikipedia.org/wiki/Address_space_layout_randomization">Address Space Layout Randomization (ASLR)</a> makes
benchmarks more stable.</p>
<p>I followed this advice without trying to understand it. We will see in this
article that it was a bad idea, but I had to hit other issues to really
understand the root issue with disabling ASLR.</p>
<p>Example of command to see the effect of ASLR, the first number of the output is
the start address of the heap memory:</p>
<pre class="literal-block">
$ python -c 'import os; os.system(&quot;grep heap /proc/%s/maps&quot; % os.getpid())'
55e6a716c000-55e6a7235000 rw-p 00000000 00:00 0                          [heap]
</pre>
<p>Heap address of 3 runs with ASLR enabled (random):</p>
<ul class="simple">
<li>55e6a716c000</li>
<li>561c218eb000</li>
<li>55e6f628f000</li>
</ul>
<p>Disable ASLR:</p>
<pre class="literal-block">
sudo bash -c 'echo 0 &gt;| /proc/sys/kernel/randomize_va_space'
</pre>
<p>Heap addresses of 3 runs with ASLR disabled (all the same):</p>
<ul class="simple">
<li>555555756000</li>
<li>555555756000</li>
<li>555555756000</li>
</ul>
<p>Note: To reenable ASLR, it's better to use the value 2, the value 1 only
partially enables the feature:</p>
<pre class="literal-block">
sudo bash -c 'echo 2 &gt;| /proc/sys/kernel/randomize_va_space'
</pre>
</div>
<div class="section" id="python-randomized-hash-function">
<h2>Python randomized hash function</h2>
<p>With <a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-system.html">system tuning  (part 1)</a>, a
<a class="reference external" href="https://haypo.github.io/journey-to-stable-benchmark-deadcode.html">Python compiled with PGO (part 2)</a>
and ASLR disabled, I still I failed to get the same result when running
manually <tt class="docutils literal">bm_call_simple.py</tt>.</p>
<p>On Python 3, the hash function is now randomized by default: <a class="reference external" href="http://bugs.python.org/issue13703">issue #13703</a>. The problem is that for a
microbenchmark, the number of hash collisions of an &quot;hot&quot; dictionary has a
non-negligible impact on performances.</p>
<p>The <tt class="docutils literal">PYTHONHASHSEED</tt> environment variable can be used to get a fixed hash
function. Example with the patch:</p>
<pre class="literal-block">
$ PYTHONHASHSEED=1 taskset -c 1 ./python bm_call_simple.py -n 1
0.198
$ PYTHONHASHSEED=2 taskset -c 1 ./python bm_call_simple.py -n 1
0.201
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1
0.207
$ PYTHONHASHSEED=4 taskset -c 1 ./python bm_call_simple.py -n 1
0.187
$ PYTHONHASHSEED=5 taskset -c 1 ./python bm_call_simple.py -n 1
0.180
</pre>
<p>Timings of the reference python:</p>
<pre class="literal-block">
$ PYTHONHASHSEED=1 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.204
$ PYTHONHASHSEED=2 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.206
$ PYTHONHASHSEED=3 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.195
$ PYTHONHASHSEED=4 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.192
$ PYTHONHASHSEED=5 taskset -c 1 ./ref_python bm_call_simple.py -n 1
0.187
</pre>
<p>The minimums is 180 ms for the reference and 186 ms for the patch. The patched
Python is 3% faster, yeah!</p>
<p>Wait. What if we only test PYTHONHASHSEED from 1 to 3? In this case, the
minimum is 195 ms for the reference and 198 ms for the patch. The patched
Python becomes 2% slower, oh no!</p>
<p>Faster? Slower? Who is right?</p>
<p>Maybe I should write a script to find a <tt class="docutils literal">PYTHONHASHSEED</tt> value for which my
patch is always faster :-)</p>
</div>
<div class="section" id="command-line-and-environment-variables">
<h2>Command line and environment variables</h2>
<p>Well, let's say that we will use a fixed PYTHONHASHSEED value. Anyway, my
patch doesn't touch at the hash function. So it doesn't matter.</p>
<p>While running benchmarks, I noticed differences when running the benchmark from
a different directory:</p>
<pre class="literal-block">
$ cd /home/haypo/prog/python/fastcall
$ PYTHONHASHSEED=3 taskset -c 1 pgo/python ../benchmarks/performance/bm_call_simple.py -n 1
0.215

$ cd /home/haypo/prog/python/benchmarks
$ PYTHONHASHSEED=3 taskset -c 1 ../fastcall/pgo/python ../benchmarks/performance/bm_call_simple.py -n 1
0.203

$ cd /home/haypo/prog/python
$ PYTHONHASHSEED=3 taskset -c 1 fastcall/pgo/python benchmarks/performance/bm_call_simple.py -n 1
0.200
</pre>
<p>In fact, a different command line is enough so get different results (added
arguments are ignored):</p>
<pre class="literal-block">
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1
0.201
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1
0.198
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3
0.203
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3 arg4 arg5
0.206
$ PYTHONHASHSEED=3 taskset -c 1 ./python bm_call_simple.py -n 1 arg1 arg2 arg3 arg4 arg5 arg6
0.210
</pre>
<p>I also noticed minor differences when the environment changes (added variables
are ignored):</p>
<pre class="literal-block">
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py -n 1
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 VAR1=1 VAR2=2 VAR3=3 VAR4=4 ./python bm_call_simple.py -n 1
0.202
$ taskset -c 1 env -i PYTHONHASHSEED=3 VAR1=1 VAR2=2 VAR3=3 VAR4=4 VAR5=5 ./python bm_call_simple.py -n 1
0.198
</pre>
<p>Using <tt class="docutils literal">strace</tt> and <tt class="docutils literal">ltrace</tt>, I saw the memory addresses are different when
something (command line, env var, etc.) changes.</p>
</div>
<div class="section" id="average-and-standard-deviation">
<h2>Average and standard deviation</h2>
<p>Basically, it looks like a lot of &quot;external factors&quot; have an impact on the
exact memory addresses, even if ASRL is disabled and PYTHONHASHSEED is set. I
started to think how to get get <em>exactly</em> the same command line, the same
environment (easy), the same current directory (easy), etc. The problem is that
it's just not possible to control all external factors (having an effect on the
exact memory addresses).</p>
<p>Maybe I was plain wrong from the beginning and ASLR must be enabled,
as the default on Linux:</p>
<pre class="literal-block">
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.198
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.202
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.199
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.207
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.200
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.201
</pre>
<p>These results look &quot;random&quot;. Yes, they are. It's exactly the purpose of ASLR.</p>
<p>But how can we compare performances if results are random? Take the minimum?</p>
<p>No! You must never (ever again) use the minimum for benchmarking! Compute the
average and some statistics like the standard deviation:</p>
<pre class="literal-block">
$ python3
Python 3.4.3
&gt;&gt;&gt; timings=[0.198, 0.202, 0.199, 0.207, 0.200, 0.201]
&gt;&gt;&gt; import statistics
&gt;&gt;&gt; statistics.mean(timings)
0.2011666666666667
&gt;&gt;&gt; statistics.stdev(timings)
0.0031885210782848245
</pre>
<p>On this example, the average is 201 ms +/- 3 ms. IMHO the standard deviation is
quite small (reliable) which means that my benchmark is stable. To get a good
distribution, it's better to have many samples. It looks like at least 25
processes are needed. Each process tests a different memory layout and a
different hash function.</p>
<p>Result of 5 runs, each run uses 25 processes (ASLR enabled, random hash
function):</p>
<ul class="simple">
<li>Average: 205.2 ms +/- 3.0 ms (min: 201.1 ms, max: 214.9 ms)</li>
<li>Average: 205.6 ms +/- 3.3 ms (min: 201.4 ms, max: 216.5 ms)</li>
<li>Average: 206.0 ms +/- 3.9 ms (min: 201.1 ms, max: 215.3 ms)</li>
<li>Average: 205.7 ms +/- 3.6 ms (min: 201.5 ms, max: 217.8 ms)</li>
<li>Average: 206.4 ms +/- 3.5 ms (min: 201.9 ms, max: 214.9 ms)</li>
</ul>
<p>While memory layout and hash functions are random again, the result looks
<em>less</em> random, and so more reliable, than before!</p>
<p>With ASLR enabled, the effect of the environment variables, command line and
current directory is negligible on the (average) result.</p>
</div>
<div class="section" id="the-average-solves-issues-with-uniform-random-noises">
<h2>The average solves issues with uniform random noises</h2>
<p>The user will run the application with default system settings which means
ASLR enabled and Python hash function randomized. Running a benchmark in one
specific environment is a mistake because it is not representative of the
performance in practice.</p>
<p>Computing the average and standard deviation &quot;fixes&quot; the issue with hash
randomization. It's much better to use random hash functions and compute the
average, than using a fixed hash function (setting <tt class="docutils literal">PYTHONHASHSEED</tt> variable
to a value).</p>
<p>Oh wow, already 3 big articles explaing how to get stable benchmarks. Please
tell me that it was the last one!  Nope, more is coming...</p>
</div>
<div class="section" id="annex-why-only-n1">
<h2>Annex: why only -n1?</h2>
<p>In this article, I ran <tt class="docutils literal">bm_call_simple.py</tt> with <tt class="docutils literal"><span class="pre">-n</span> 1</tt> with only run one
iteration.</p>
<p>Usually, a single iteration is not reliable at all, at least 50 iterations are
needed. But thanks to system tuning, compilation with PGO, ASRL disabled and
<tt class="docutils literal">PYTHONHASHSEED</tt> set, a single iteration is enough.</p>
<p>Example of 3 runs, each with 3 iterations:</p>
<pre class="literal-block">
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.201
0.201
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.201
0.201
0.201
$ taskset -c 1 env -i PYTHONHASHSEED=3 ./python bm_call_simple.py
0.201
0.201
0.201
</pre>
<p>Always the same timing!</p>
</div>

    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://haypo-notes.readthedocs.org/">Haypo's Notes</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="https://haypo.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                            <li><a href="https://twitter.com/VictorStinner">Follow @VictorStinner on Twitter</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>